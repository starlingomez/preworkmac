{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyND6IlYtGtt0fTZfPvEFVah",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starlingomez/preworkmac/blob/master/JUNE25TH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TYLER ANDERSON"
      ],
      "metadata": {
        "id": "5j-8QFGw7nua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Organize the data into a DataFrame\n",
        "data = {\n",
        "    \"innings_pitched\": [7, 5.1, 6, 6.2, 5, 8, 7, 6.2, 6.1, 6],\n",
        "    \"total_batter_faced\": [27, 25, 26, 26, 23, 31, 25, 27, 28, 24],\n",
        "    \"strikeouts_per_nine_inning\": [6.4, 8.4, 4.5, 2.7, 7.2, 4.5, 5.1, 5.4, 7.1, 9],\n",
        "    \"strikeouts\": [5, 5, 3, 2, 4, 4, 4, 4, 5, 6]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the independent variables and the dependent variable\n",
        "X = df[['innings_pitched', 'total_batter_faced', 'strikeouts_per_nine_inning']].values\n",
        "y = df['strikeouts'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model with a modified learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=200, batch_size=4, verbose=1)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Output the first model prediction\n",
        "print(\"Predicted strikeout:\", y_pred.flatten()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJAdVVsB06C0",
        "outputId": "11d3ce06-9c72-409f-d5e6-647b2753cd29"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 5s 44ms/step - loss: 16.9292\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.8512\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 15.5709\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 14.9403\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 15.1990\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 14.1666\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 13.5005\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 12.8573\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 11.8693\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 12.1197\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 9.7020\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 9.7744\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 9.2057\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 7.1244\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 6.8016\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 6.4073\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 5.6743\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 5.4503\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 4.0189\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 4.7805\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 3.8431\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 3.3874\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 2.5302\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.5040\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 3.1781\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.6365\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.8614\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.6637\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 2.2911\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.2212\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.7365\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.9590\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.9596\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.8180\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.9214\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.4841\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.3276\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.7545\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.6151\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.9843\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.7656\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.7046\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 1.5163\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.1618\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.8673\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.9163\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.5810\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6128\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.9318\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.9836\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.0822\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.1293\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8373\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6766\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6365\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.1537\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.4394\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0780\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0471\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.0965\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8146\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5092\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.4992\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7239\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 1.3057\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5825\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.0204\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.5546\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4507\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.5129\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.5579\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8798\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5805\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7265\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7548\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4740\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1936\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6219\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2138\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.1056\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.8073\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.3651\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.5660\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5715\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.7464\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2887\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.2806\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4211\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6084\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8474\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4380\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0943\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.1448\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.7336\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4469\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.2312\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6836\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1438\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.2414\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4379\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.3840\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.5313\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1860\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4551\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.3083\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.3841\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.2160\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4456\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.1992\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.3423\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4072\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1093\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.2169\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.4857\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.4049\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3926\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.8549\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.2799\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.4744\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1816\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3139\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.9414\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1741\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.2908\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1498\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.2815\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2872\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2192\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2668\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1149\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4448\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.5006\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.1846\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2133\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2190\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4929\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.2465\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2805\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4066\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1541\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.2456\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1900\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.4457\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1798\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.2177\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0839\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.1048\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1707\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2635\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.2552\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.2450\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3275\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.3862\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2204\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.0653\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2797\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.3560\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2996\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2128\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1719\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3952\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.1911\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1781\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.1362\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.1124\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.3862\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3086\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4043\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.2385\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.3437\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.1169\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3066\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.3742\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.2270\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.0896\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.3323\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.2633\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.4336\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2206\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1389\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1644\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.1825\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1128\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3678\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1326\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.2275\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.1618\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1174\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.3162\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1041\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3095\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.1471\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0578\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2026\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3864\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3209\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.2336\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.1170\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2025\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1785\n",
            "1/1 [==============================] - 0s 141ms/step\n",
            "Mean Squared Error: 0.5425580419055223\n",
            "R-squared: 0.0\n",
            "Predicted strikeout: 5.8626165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SETH LUGO"
      ],
      "metadata": {
        "id": "nLOFTSxn9R4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Organize the data into a DataFrame\n",
        "data = {\n",
        "    'innings_pitched': [6.2, 6, 7, 6, 6, 7, 5.2, 8, 6.2, 7],\n",
        "    'total_batter_faced': [26, 25, 30, 26, 27, 28, 24, 29, 27, 25],\n",
        "    'strikeouts_per_nine_inning': [10.8, 6, 5.14, 7.5, 7.5, 3.86, 15.88, 13.5, 6.75, 10.29],\n",
        "    'strikeouts': [8, 4, 4, 5, 5, 3, 10, 12, 5, 8]\n",
        "}\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the independent variables and the dependent variable\n",
        "X = df[['innings_pitched', 'total_batter_faced', 'strikeouts_per_nine_inning']].values\n",
        "y = df['strikeouts'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model with a modified learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=200, batch_size=4, verbose=1)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Output the first model prediction\n",
        "print(\"Predicted strikeout:\", y_pred.flatten()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-0eSiwh9Wkk",
        "outputId": "9d25bc86-815b-4256-868c-d43b4a414d4a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 2s 9ms/step - loss: 55.4568\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 55.3127\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 53.4896\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 51.8602\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 49.9594\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 51.2991\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 48.2433\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 47.7902\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 45.9172\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 44.8969\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 43.4623\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 42.9747\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 41.1269\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 36.8322\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 37.6528\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 37.3314\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 34.6860\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 32.2127\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 32.7310\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 25.4430\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 29.8952\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 18.9091\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 21.6125\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.1353\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.6409\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.5073\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.4269\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.8791\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.5696\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.7899\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.1472\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.8544\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.2712\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.8200\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.8977\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 4.2389\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.6762\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.4801\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.6465\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5.5513\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.8225\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7678\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.4130\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0638\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.4549\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 3.7044\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.6885\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9595\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6762\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 4.5123\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.7628\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.3401\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9485\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.3104\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.1859\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8911\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.7968\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.7859\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4596\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.6689\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8616\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5508\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.1615\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.3792\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.9686\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5132\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5377\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.3198\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 3.3316\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4732\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.9090\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.7473\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 3.1767\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.1947\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 3.8943\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.3443\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.9908\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.4482\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2926\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1447\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3446\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.3782\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.3384\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.6875\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6902\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.9815\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.9676\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2138\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0678\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0949\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0331\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 3.2708\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8715\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0576\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3200\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8145\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4770\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5631\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3415\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.3205\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.9276\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0813\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3224\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.0819\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7669\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.9201\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.8483\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5240\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5565\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0812\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.2518\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7025\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9049\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5251\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.1328\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8394\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.0406\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1232\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0162\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9797\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.3951\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9502\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.0868\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.5876\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7455\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2495\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8879\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6116\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.2162\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2196\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8077\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.6141\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.1454\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.7625\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.4800\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.6251\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7753\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1410\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9424\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.4420\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.4577\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1946\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0484\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8961\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8870\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.6590\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1324\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7691\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8834\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6609\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.2024\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1450\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5576\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9115\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1563\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5236\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9973\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2613\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3441\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9246\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7092\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8105\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6693\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.5066\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7339\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.7654\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.6134\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.8808\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.3320\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.7162\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.9117\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.9239\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9927\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.5288\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.1039\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.5331\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.6137\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9712\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6404\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9008\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0639\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0965\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2843\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2560\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1801\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2835\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7006\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.1805\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.2180\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6689\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.7898\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.9381\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6217\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.3542\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3787\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4002\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.9546\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8705\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.3856\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8495\n",
            "1/1 [==============================] - 0s 443ms/step\n",
            "Mean Squared Error: 2.1491010334953273\n",
            "R-squared: -7.596404133981309\n",
            "Predicted strikeout: 3.9703352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K GIBSON"
      ],
      "metadata": {
        "id": "XxicXPNv9g8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Organize the data into a DataFrame\n",
        "data = {\n",
        "    \"innings_pitched\": [7, 6, 5.2, 6, 4, 6, 5, 6, 7],\n",
        "    \"total_batter_faced\": [24, 26, 25, 22, 18, 27, 23, 26, 27],\n",
        "    \"strikeouts_per_nine_inning\": [7.71, 10.5, 12.71, 9, 6.75, 4.5, 12.6, 6, 11.57],\n",
        "    \"strikeouts\": [6, 7, 8, 6, 3, 3, 7, 4, 9]\n",
        "}\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the independent variables and the dependent variable\n",
        "X = df[['innings_pitched', 'total_batter_faced', 'strikeouts_per_nine_inning']].values\n",
        "y = df['strikeouts'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model with a modified learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=200, batch_size=4, verbose=1)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Output the first model prediction\n",
        "print(\"Predicted strikeout:\", y_pred.flatten()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUC29UUy9TGs",
        "outputId": "e2124885-43e6-4c60-9558-0b08e006e03a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 4s 18ms/step - loss: 39.1760\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 38.6820\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 37.7973\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 37.3254\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 35.2939\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 34.1508\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 32.4564\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 31.4459\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 31.3852\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 29.6254\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 27.7726\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 26.5108\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 25.1454\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 24.6170\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 22.7092\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 20.0485\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 19.8784\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 19.3438\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.6783\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 14.2407\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 12.9239\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 9.6532\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 10.9010\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 8.3262\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 6.3666\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 3.2705\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 5.6987\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 4.0406\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 3.0733\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 5.1776\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.7750\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.0021\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.5359\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 3.1543\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.5754\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 3.1757\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.7587\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.5846\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 2.7289\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 3.1439\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 3.5420\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 1.7242\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.3341\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.8450\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.9302\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.7594\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.0060\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.1920\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.1554\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6371\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.8866\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.3097\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.4693\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.1379\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.7142\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.5482\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.1707\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6373\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.1124\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.2707\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.7759\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.7927\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.1855\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.5793\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8115\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.0054\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.1410\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.1371\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.7220\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.3856\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.7178\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.4109\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.2898\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.5322\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.7597\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.9077\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.2596\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 2.1171\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1899\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.8530\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8882\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.3279\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6439\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.8287\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.1183\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.2771\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.8555\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.5977\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 2.4667\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5150\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.0485\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.2535\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6613\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0726\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.2199\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3173\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.8632\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6199\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7908\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.6244\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6221\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.2715\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.7124\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.9255\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.8374\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.4902\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.0432\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.9860\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.6625\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.7860\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 1.4179\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7011\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1459\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.5752\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9599\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8335\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8849\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.6979\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.5943\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 1.3736\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.9655\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3564\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.5669\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.9117\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.4723\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4287\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.3957\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.4840\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3903\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.6650\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3789\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.1900\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.1941\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.5827\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.8591\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3425\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.8324\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3750\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.9069\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6796\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8253\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7284\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.6541\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4252\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6480\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9231\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7955\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9082\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5784\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9657\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.2086\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4545\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3958\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1534\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5879\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3826\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.5341\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.5012\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.2105\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3443\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6250\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5426\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2393\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.9914\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5733\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.7753\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.7043\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8847\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.2478\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3928\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.0725\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3728\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4335\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3453\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0312\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.1984\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.0623\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6846\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3138\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0620\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8870\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.8167\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7974\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.2553\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.5961\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5601\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2932\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.0151\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.8762\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4608\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6526\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.8545\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6271\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.7057\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0203\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5184\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.5600\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7834\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3424\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0612\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "Mean Squared Error: 2.2317578601411014\n",
            "R-squared: 0.008107617715066073\n",
            "Predicted strikeout: 2.473906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RANGER SUAREZ"
      ],
      "metadata": {
        "id": "e6P2u6QXBTBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Organize the data into a DataFrame\n",
        "data = {\n",
        "    'innings_pitched': [6, 6.2, 5.2, 2, 6, 7, 5, 7, 6, 8],\n",
        "    'total_batter_faced': [23, 27, 27, 6, 25, 27, 23, 25, 27, 26],\n",
        "    'strikeouts_per_nine_inning': [6, 8.1, 9.53, 9, 13.5, 12.86, 5.4, 11.57, 9, 9],\n",
        "    'strikeouts': [4, 6, 6, 2, 9, 10, 3, 9, 6, 8]\n",
        "}\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the independent variables and the dependent variable\n",
        "X = df[['innings_pitched', 'total_batter_faced', 'strikeouts_per_nine_inning']].values\n",
        "y = df['strikeouts'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model with a modified learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=200, batch_size=4, verbose=1)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Output the first model prediction\n",
        "print(\"Predicted strikeout:\", y_pred.flatten()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "K0dtTm-KBW8e",
        "outputId": "a187137d-3d61-4b32-fb95-dbe5840210d2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 1s 8ms/step - loss: 49.1957\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 48.0524\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 47.2077\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 46.0296\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 45.6495\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 44.0875\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 42.7061\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 42.0796\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 40.3397\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 40.0915\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 37.8541\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 34.7107\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 34.7921\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 32.4926\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 27.7838\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 28.2802\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 26.0513\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 24.1330\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 21.5934\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.0474\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.5781\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.9907\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.5829\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.5216\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.6387\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.5868\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.3582\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.0249\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.9530\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.9680\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0344\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.0943\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8720\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5897\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.8156\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 3.3105\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 3.5314\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5943\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.3767\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.1198\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.8914\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.8408\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.1927\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.7568\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3852\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5034\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3043\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3884\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1449\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4414\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1088\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8245\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.9577\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.8423\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.9729\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2408\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.4939\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.4736\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.0776\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.8533\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.6449\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.3756\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3812\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0412\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5419\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.1936\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.7964\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6640\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.5954\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3720\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7928\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7092\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9421\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.4411\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7121\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9299\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.8166\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6566\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7126\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.4700\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4218\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6734\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3925\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.5863\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5320\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5644\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.2265\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0619\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3385\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5062\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2720\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6568\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.3575\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9956\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7723\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2929\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4669\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2751\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.6590\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4278\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3936\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9166\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.4173\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.6828\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5705\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3701\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8184\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5941\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7490\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7916\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0067\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3161\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8954\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4295\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7553\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9516\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0527\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6247\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1453\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5739\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1445\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.9177\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1425\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1453\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3814\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6520\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6553\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4592\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.2221\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6399\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3067\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7372\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8672\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7988\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7467\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8231\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1933\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6821\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.9702\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3447\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8743\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1495\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5391\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3106\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6202\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7926\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5716\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3110\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3780\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2294\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5286\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8322\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0351\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0288\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.3334\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.9020\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6948\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.5117\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3124\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5899\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5055\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2862\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2574\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5039\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5370\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2838\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7655\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5903\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7876\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5957\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4311\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3059\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1811\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6107\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1064\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3392\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2118\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2679\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6414\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3558\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0318\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8790\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4385\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8434\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1915\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8635\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7329\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1873\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8827\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3203\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8109\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6738\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3383\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4630\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2180\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5328\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1547\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2861\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7888\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0254\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "Mean Squared Error: 0.31117910400064375\n",
            "R-squared: 0.0\n",
            "Predicted strikeout: 5.527411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REYNALDO LOPEZ"
      ],
      "metadata": {
        "id": "GzoM-FngCRKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Organize the data into a DataFrame\n",
        "data = {\n",
        "    \"innings_pitched\": [5, 6, 6, 6, 4.2, 6.1, 5, 5.1, 5, 7],\n",
        "    \"total_batter_faced\": [22, 21, 24, 24, 20, 23, 18, 26, 23, 24],\n",
        "    \"strikeouts_per_nine_inning\": [10.8, 12, 10.5, 12, 5.79, 5.68, 7.2, 8.44, 12.6, 7.71],\n",
        "    \"strikeouts\": [6, 8, 7, 8, 3, 4, 4, 5, 7, 6]\n",
        "}\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the independent variables and the dependent variable\n",
        "X = df[['innings_pitched', 'total_batter_faced', 'strikeouts_per_nine_inning']].values\n",
        "y = df['strikeouts'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model with a modified learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=200, batch_size=4, verbose=1)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Output the first model prediction\n",
        "print(\"Predicted strikeout:\", y_pred.flatten()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4pLStz8CShl",
        "outputId": "97bf313e-86ed-4367-c48a-748a6ffbcce1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 1s 13ms/step - loss: 30.5119\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 30.1733\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 28.6655\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 28.3516\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 26.4893\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 25.7968\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24.2118\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.2087\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 22.7666\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 21.5427\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 18.4345\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.2076\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.5353\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.6442\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.3131\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.1730\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.3613\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.0658\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.8461\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.3951\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.0811\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.3180\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.3534\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.7720\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8683\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8920\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9784\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0631\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.8183\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.2881\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5033\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.4468\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2541\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1776\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0395\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3369\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7115\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.7049\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5712\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.3869\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0455\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7176\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4506\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1818\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2166\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7812\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.5150\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.2800\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6407\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4482\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7463\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6088\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8705\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4343\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3534\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6720\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3290\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9634\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1405\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1734\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6960\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3938\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7557\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3260\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0410\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9717\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7518\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3038\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3863\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4859\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7711\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5955\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8430\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9736\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2177\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.2946\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.8499\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7298\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9412\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8828\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8413\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6083\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4795\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6012\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2104\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5219\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0171\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5769\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8438\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4494\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3328\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3546\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5720\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2412\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6834\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5122\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2415\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4554\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7783\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4811\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6811\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8679\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5919\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3075\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6044\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5618\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4962\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2689\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3101\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4048\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9161\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4687\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2281\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1404\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1024\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5711\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7292\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1820\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5892\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5000\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3995\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4323\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3345\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3985\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3847\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0746\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8776\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3751\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4951\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.4953\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4696\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1706\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5307\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5320\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4027\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6369\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3680\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7866\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1962\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3401\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2621\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1924\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3707\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.1507\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9371\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7007\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3346\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1238\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4388\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5158\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6568\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7227\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4802\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1082\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7213\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5992\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2946\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7441\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5256\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9679\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8081\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1505\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0271\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.5492\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1688\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3573\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5860\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3483\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7439\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1912\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8146\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4237\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1123\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5205\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2749\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3896\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2180\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2819\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3058\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1713\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4439\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7461\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5754\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9356\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1572\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8708\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4319\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0740\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5271\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3015\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6684\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3360\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2301\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1575\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6024\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2582\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4237\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2845\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2145\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7a9e6931ce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 86ms/step\n",
            "Mean Squared Error: 1.17367519030131\n",
            "R-squared: -3.6947007612052403\n",
            "Predicted strikeout: 8.303143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HUNTER GREENE"
      ],
      "metadata": {
        "id": "x7JoxsBGEjqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Organize the data into a DataFrame\n",
        "data = {\n",
        "    'innings_pitched': [6.1, 5, 6.2, 6, 6, 6.1, 7, 5, 5.2, 7],\n",
        "    'total_batter_faced': [23, 24, 28, 27, 22, 26, 27, 22, 25, 23],\n",
        "    'strikeouts_per_nine_inning': [12.79, 9, 10.8, 7.5, 7.5, 11.37, 6.43, 10.8, 7.94, 7.71],\n",
        "    'strikeouts': [9, 5, 8, 5, 5, 8, 5, 6, 5, 6]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the independent variables and the dependent variable\n",
        "X = df[['innings_pitched', 'total_batter_faced', 'strikeouts_per_nine_inning']].values\n",
        "y = df['strikeouts'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model with a modified learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=200, batch_size=4, verbose=1)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Output the first model prediction\n",
        "print(\"Predicted strikeout:\", y_pred.flatten()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e4-DuICEl4P",
        "outputId": "4ad0ff2e-7cfc-448d-e38d-9a90aa1eb529"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 1s 10ms/step - loss: 42.1375\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 40.5525\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 40.1310\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 38.1733\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 38.1955\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 34.2957\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 33.1196\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 33.1922\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 31.1237\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 28.7963\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 28.1927\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 23.8634\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 22.6563\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 23.0968\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 19.1418\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 17.0405\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.4413\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.3610\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 10.8065\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.6448\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.3763\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.4820\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 4.1963\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0229\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 3.9527\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.4216\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3482\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0859\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.4737\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.4188\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.9140\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5622\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0896\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5704\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0511\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3369\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.9480\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4823\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7973\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0604\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5180\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0583\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1675\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.1409\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.7169\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6659\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8870\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7400\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6324\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4778\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6797\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6357\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5963\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4259\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.3411\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6103\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5320\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1988\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6864\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0412\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8795\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6274\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.9485\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4045\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9281\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7503\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8320\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.1786\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4765\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.7625\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3917\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4386\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6465\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.3407\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8542\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6196\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.4135\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6413\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8848\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5794\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7680\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6564\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0872\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4024\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1714\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5233\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3878\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9307\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5979\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4119\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7155\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8290\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9506\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7202\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6181\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6304\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3110\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6135\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8796\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.6054\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1798\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3819\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2619\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4828\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5358\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.2770\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9394\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7057\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8552\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0802\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7582\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7499\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7238\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.8447\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.7726\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.2357\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7484\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9210\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8086\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9858\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7664\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0417\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8361\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0040\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0659\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8478\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1194\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0583\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5420\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3425\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4340\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5167\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1299\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5208\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6147\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3763\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7554\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8544\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7675\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3573\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2909\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9622\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0535\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1104\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8930\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2793\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3372\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0130\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3119\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2829\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3825\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4068\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4164\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3528\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7235\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2815\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3580\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8060\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5180\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5418\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2997\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6515\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0356\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6016\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8296\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0833\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6760\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6682\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4362\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3129\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3981\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5060\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2721\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0417\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0186\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4895\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.4926\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0197\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5056\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.0416\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5062\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.3508\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7522\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2958\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8397\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5124\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7182\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1806\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4240\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3227\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8476\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5388\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8695\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0254\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4802\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5994\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.7369\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4344\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6035\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7a9e6931f2e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 136ms/step\n",
            "Mean Squared Error: 0.683112740772458\n",
            "R-squared: 0.0\n",
            "Predicted strikeout: 5.6191688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BRANDON PFAADT"
      ],
      "metadata": {
        "id": "n4e9LMe-Frbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Organize the data into a DataFrame\n",
        "data = {\n",
        "    'innings_pitched': [6.1, 6, 5.1, 6, 7, 6, 7, 6, 6, 6],\n",
        "    'total_batter_faced': [25, 26, 26, 24, 28, 23, 25, 25, 29, 23],\n",
        "    'strikeouts_per_nine_inning': [0, 12, 8.44, 12, 6.43, 10.5, 11.57, 0, 6, 16.5],\n",
        "    'strikeouts': [0, 8, 5, 8, 5, 7, 9, 0, 4, 11]\n",
        "}\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the independent variables and the dependent variable\n",
        "X = df[['innings_pitched', 'total_batter_faced', 'strikeouts_per_nine_inning']].values\n",
        "y = df['strikeouts'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model with a modified learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=200, batch_size=4, verbose=1)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Output the first model prediction\n",
        "print(\"Predicted strikeout:\", y_pred.flatten()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0HZTleTEr-l",
        "outputId": "1d356b4c-2007-484c-ba38-4c12e38296c3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 3s 10ms/step - loss: 46.5678\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 45.5710\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 44.1631\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 43.9650\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 43.2004\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 42.5157\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 41.5873\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 41.0106\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 40.1214\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 38.4610\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 38.2444\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 36.9472\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 35.4045\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 34.8326\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 31.3806\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 30.5486\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 28.0969\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 25.7714\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 23.5216\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 24.3966\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 19.7214\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 19.2173\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.9444\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.2664\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.9612\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.1075\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.0738\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.3345\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.5032\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.4617\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.0219\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.1460\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.2818\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.6478\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.3627\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6011\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.4055\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7095\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3192\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 3.6731\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.5419\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0933\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.2653\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3082\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5567\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1912\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1480\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1947\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5423\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9838\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0197\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.0592\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.4146\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9907\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0638\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3801\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0001\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.5616\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4796\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.9328\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8293\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2545\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8410\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.7044\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.0912\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 7.2683\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6006\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.4818\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5513\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.5147\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.2448\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6132\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.5207\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.1430\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5752\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.7352\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.9377\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6812\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.3575\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.1622\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9024\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 2.5341\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.0126\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.1733\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.8091\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.0013\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4327\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.0847\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.6313\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8375\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.3625\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.9476\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6066\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.5882\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.5296\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.5816\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.7139\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3320\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0964\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.5268\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.8635\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 2.7932\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.3996\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.3082\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 2.6418\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.0142\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.2876\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.4028\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.9989\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4303\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3390\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4025\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.4929\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6035\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.6887\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5061\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.4430\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7595\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4889\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.4950\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0121\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.2329\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.4613\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7006\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8279\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8169\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8032\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.6268\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3223\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2702\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2185\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7507\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1398\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8893\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4115\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8474\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5719\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9515\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.2311\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.1961\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7876\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9919\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0939\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.6735\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.6936\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0128\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7342\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.3601\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1393\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6297\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7659\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3038\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2021\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6618\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.8403\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3792\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.3156\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.8978\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.7939\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.6939\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.7211\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.0438\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.8136\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.5357\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.5235\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.4277\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.3682\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5330\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.0264\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.7845\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.6090\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4445\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5327\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.6217\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4192\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.1272\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.4462\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4903\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.9783\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3527\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.7940\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.6154\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.3773\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.7361\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.7064\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.9613\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5565\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.4698\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7853\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1462\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.2069\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.8970\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2199\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.2475\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.3208\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.3621\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.2282\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.7273\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3831\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.7466\n",
            "1/1 [==============================] - 0s 185ms/step\n",
            "Mean Squared Error: 2.8036177311076074\n",
            "R-squared: 0.29909556722309816\n",
            "Predicted strikeout: 3.1414382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FLEZEN"
      ],
      "metadata": {
        "id": "E1UZ99cGIU-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Organize the data into a DataFrame\n",
        "data = {\n",
        "    'innings_pitched': [6, 3.1, 5, 5, 5, 4.2, 4, 4.2, 6, 5],\n",
        "    'total_batter_faced': [25, 20, 18, 18, 23, 21, 21, 22, 21, 20],\n",
        "    'strikeouts_per_nine_inning': [9, 5.4, 5.4, 7.2, 10.8, 3.86, 9, 9.64, 12, 7.2],\n",
        "    'strikeouts': [6, 2, 3, 4, 6, 2, 4, 5, 8, 4]\n",
        "}\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the independent variables and the dependent variable\n",
        "X = df[['innings_pitched', 'total_batter_faced', 'strikeouts_per_nine_inning']].values\n",
        "y = df['strikeouts'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model with a modified learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=200, batch_size=4, verbose=1)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Output the first model prediction\n",
        "print(\"Predicted strikeout:\", y_pred.flatten()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUlop12eIWT_",
        "outputId": "7354287c-dcaa-499e-eef5-17481f475080"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 2s 10ms/step - loss: 18.2704\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 18.1294\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 17.0590\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.6201\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 15.5569\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 16.0563\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.0458\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 13.3831\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.7255\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.7183\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.1764\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8.7252\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.3737\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.7133\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.5442\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 6.6535\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.1238\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 4.9404\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.1448\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.5532\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 3.8669\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.2678\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9714\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3138\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5773\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.4952\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.6124\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3434\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.6595\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3353\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2527\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4938\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5153\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.5329\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4673\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.9642\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3633\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9526\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8028\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.2641\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6597\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9872\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8566\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.8685\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5784\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.5202\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8671\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7547\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9799\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7967\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9085\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6640\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.7627\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6921\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1472\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5737\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3584\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5916\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7542\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5886\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6651\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9586\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0569\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.8003\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.8753\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7075\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9984\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8276\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.9717\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6636\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6312\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5115\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5619\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3152\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4915\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5659\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0227\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5672\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2663\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4341\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3813\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1497\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5701\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9334\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3671\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5558\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5238\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4925\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.9901\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4239\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3771\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6222\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7060\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.8238\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3820\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.1518\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5361\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2689\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8669\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4522\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3418\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6603\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3793\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3798\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6212\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5216\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4593\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6470\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4729\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9789\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.7794\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.1646\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5181\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3864\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6797\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7031\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6875\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7054\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2598\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4155\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3117\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3290\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3799\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5568\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2142\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3655\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.8836\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5753\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2362\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3687\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.4104\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.7512\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5288\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3008\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3235\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3301\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4023\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2878\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4338\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5085\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.1727\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5118\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3290\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3809\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3342\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4574\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7803\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4761\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2433\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.4923\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2059\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2602\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4372\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4312\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2756\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3943\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.2498\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2411\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2282\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1659\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.1042\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4305\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2868\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.3843\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2847\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.1625\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.7288\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2098\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2402\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3263\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.3299\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3112\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6529\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0610\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4815\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2896\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.3376\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5782\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1730\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.2943\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3565\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2897\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4402\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4786\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6484\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.3088\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.0947\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.3144\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3252\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2957\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3271\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2166\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3182\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1993\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4669\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2813\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4715\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3299\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5887\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2686\n",
            "1/1 [==============================] - 0s 200ms/step\n",
            "Mean Squared Error: 0.09173010474003718\n",
            "R-squared: 0.9898077661399959\n",
            "Predicted strikeout: 7.900976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "L ALLEN"
      ],
      "metadata": {
        "id": "Uam0D4RXJKF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Organize the data into a DataFrame\n",
        "data = {\n",
        "    'innings_pitched': [6, 5, 6, 1.2, 5.2, 6, 6, 2.1, 5.2, 4.2],\n",
        "    'total_batter_faced': [25, 19, 25, 13, 25, 22, 24, 15, 25, 22],\n",
        "    'strikeouts_per_nine_inning': [3, 5.4, 4.5, 5.4, 11.12, 10.5, 4.5, 7.71, 7.94, 9.64],\n",
        "    'strikeouts': [2, 3, 3, 1, 7, 7, 3, 2, 5, 5]\n",
        "}\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the independent variables and the dependent variable\n",
        "X = df[['innings_pitched', 'total_batter_faced', 'strikeouts_per_nine_inning']].values\n",
        "y = df['strikeouts'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model with a modified learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=200, batch_size=4, verbose=1)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Output the first model prediction\n",
        "print(\"Predicted strikeout:\", y_pred.flatten()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2uG_866JMqP",
        "outputId": "4783c79a-c080-499b-c77a-b741939c7205"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 1s 9ms/step - loss: 17.4476\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 16.6751\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.5391\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 15.4102\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.7470\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 14.0581\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.1726\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.7253\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.3338\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.5753\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 10.3866\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.9645\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 8.7448\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8.5715\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.8879\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.0543\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.4543\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.8593\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.3913\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.0723\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.4835\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.2530\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.4862\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3591\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8512\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2442\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8921\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6519\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6817\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3798\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4850\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7492\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7939\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5967\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3004\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8137\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9874\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7237\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4101\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7796\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4036\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1498\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4502\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4362\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7486\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3042\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3740\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0913\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0222\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5557\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3738\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4628\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4354\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4497\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1522\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1223\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5941\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8687\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2849\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2970\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.7354\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5596\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7773\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9330\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.1637\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5659\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8520\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.2003\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.4992\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5403\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3284\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2126\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5416\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2862\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1304\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1611\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4113\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2725\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4453\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3058\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3529\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6503\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4557\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2344\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7343\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6930\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9004\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8205\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5026\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3004\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3282\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6778\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3009\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4321\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3748\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3851\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3654\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4717\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.7886\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3496\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.0939\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2057\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3428\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3771\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2439\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.1659\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5544\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6024\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2093\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1241\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4824\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2708\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2699\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1202\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4656\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4910\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4114\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2233\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6820\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4634\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3312\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2860\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.5651\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6470\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4974\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5416\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2134\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2621\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3412\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2928\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3027\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2589\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3884\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2932\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2681\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5285\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2146\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2976\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.2953\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1955\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2550\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4902\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.1645\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2494\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.7329\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5390\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4800\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2406\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.1064\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1328\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4574\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8212\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4655\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0885\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0870\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3173\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2173\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3539\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2237\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.1574\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4379\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4132\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.1396\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6269\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4091\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2618\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1637\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3379\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1385\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1816\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.2754\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0957\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3791\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7427\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1802\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6407\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1507\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.2291\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2344\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1062\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.6266\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5156\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2848\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1843\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2720\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1941\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1795\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2644\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3935\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3743\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1976\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6389\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0885\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3762\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2694\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3084\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2986\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4145\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1940\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3011\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Mean Squared Error: 1.5222334613939736\n",
            "R-squared: -0.5222334613939736\n",
            "Predicted strikeout: 3.8435006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "M GORE"
      ],
      "metadata": {
        "id": "aWWmSrOfKGYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Organize the data into a DataFrame\n",
        "data = {\n",
        "    \"innings_pitched\": [5, 7, 5, 4.1, 5.1, 7, 6.1, 6, 3, 5],\n",
        "    \"total_batter_faced\": [27, 28, 22, 24, 22, 26, 23, 27, 18, 23],\n",
        "    \"strikeouts_per_nine_inning\": [12.6, 12.86, 12.6, 4.15, 16.88, 10.29, 4.26, 13.5, 12, 12.6],\n",
        "    \"strikeouts\": [7, 10, 7, 2, 10, 8, 3, 9, 4, 7]\n",
        "}\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the independent variables and the dependent variable\n",
        "X = df[['innings_pitched', 'total_batter_faced', 'strikeouts_per_nine_inning']].values\n",
        "y = df['strikeouts'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model with a modified learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=200, batch_size=4, verbose=1)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Output the first model prediction\n",
        "print(\"Predicted strikeout:\", y_pred.flatten()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFMjWtbfKN-2",
        "outputId": "7c64201f-730a-4815-99a6-1ca4d0955c53"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 2s 9ms/step - loss: 54.3864\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 55.2155\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 52.7734\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 52.1326\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 51.9169\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 50.8221\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 49.4612\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 49.1707\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 47.4560\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 46.5442\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 46.7788\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 45.2479\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 45.2979\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 44.3303\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 43.1306\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 42.6071\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 39.6900\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 37.8633\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 37.9007\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 37.3413\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 35.2616\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 33.7325\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 31.2478\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 30.3017\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 26.3710\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 24.3204\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 22.7982\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 22.1681\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 18.0143\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 15.4894\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 15.9074\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 12.8895\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 10.5708\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.9799\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 9.0563\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.6429\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.0459\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 4.4205\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5.0198\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 3.6444\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.9729\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.9260\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6805\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.8087\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.1315\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.8299\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.3492\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.5813\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.4070\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8478\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.9580\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0280\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0293\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0869\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7649\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.3258\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7870\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9578\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8803\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4214\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.8605\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.0050\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.0663\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0931\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0373\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6483\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2947\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.5224\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8522\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6351\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3709\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.7028\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9202\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0457\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4152\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8863\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0692\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.6766\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0525\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1365\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7862\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8145\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.4659\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4964\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2361\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1658\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6342\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.4253\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6861\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8887\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.2754\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5888\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5547\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6933\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2725\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2853\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5099\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5998\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3045\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9198\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2205\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9148\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6031\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.1145\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.2176\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6459\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.6279\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.2231\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.7128\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9069\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1353\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5561\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4628\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5202\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1623\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3914\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4534\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.8042\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3705\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.2932\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.7801\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7901\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9409\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4958\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9121\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8518\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2338\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0816\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5989\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2233\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.3840\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.2799\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7008\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3326\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9556\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9729\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2400\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5596\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2688\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7955\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.1442\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6786\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1917\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9356\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7388\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8666\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9523\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8678\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7310\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4876\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3468\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3872\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5697\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.8680\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4173\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6828\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9103\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.9372\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.9175\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.3837\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9804\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.1982\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2680\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.2231\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8189\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.1425\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7842\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8842\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5465\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8905\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3823\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1456\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8755\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4866\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5141\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.4563\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8267\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9464\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.4817\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1022\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.5685\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.4255\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.1623\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.5858\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.2101\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.4162\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4805\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6359\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3173\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3110\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.4057\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6359\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3909\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.7619\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.2916\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6889\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.8896\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4334\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3309\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.0371\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "Mean Squared Error: 42.925236399031746\n",
            "R-squared: -3.7694707110035273\n",
            "Predicted strikeout: 13.218204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "o6z-pcp-7ms4"
      }
    }
  ]
}