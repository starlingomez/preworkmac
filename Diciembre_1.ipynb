{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtSGjdwIQ/2lj3O68/Ue7I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starlingomez/preworkmac/blob/master/Diciembre_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKftX0AiumJP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FRANK WAGNER"
      ],
      "metadata": {
        "id": "RDLysfV2uo2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [5.4], # Changed to list\n",
        "    'avg_min_last5': [34.9], # Changed to list\n",
        "    'opp_avg_reb_allowed': [42.3], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [7], # Changed to list\n",
        "    'home_indicator': [0], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ad9a6d0-e3e9-4732-e550-7875baf92c3f",
        "id": "oiuss2gXRFDs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 83.7444 - mae: 8.6954 - val_loss: 81.5848 - val_mae: 8.6469\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.9192 - mae: 7.6607 - val_loss: 61.5898 - val_mae: 7.4253\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45.6281 - mae: 6.2029 - val_loss: 33.8999 - val_mae: 5.3470\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22.1093 - mae: 4.1127 - val_loss: 11.6776 - val_mae: 2.9054\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.3687 - mae: 2.2154 - val_loss: 5.1303 - val_mae: 1.8177\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3777 - mae: 1.9017 - val_loss: 4.4554 - val_mae: 1.6696\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9503 - mae: 1.7978 - val_loss: 4.4168 - val_mae: 1.6831\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8658 - mae: 1.7791 - val_loss: 4.4237 - val_mae: 1.6944\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0724 - mae: 1.8064 - val_loss: 4.3494 - val_mae: 1.6751\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.6494 - mae: 1.7329 - val_loss: 4.2067 - val_mae: 1.6275\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7364 - mae: 1.7298 - val_loss: 4.2973 - val_mae: 1.6538\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.4540 - mae: 1.7043 - val_loss: 4.1516 - val_mae: 1.6052\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.6810 - mae: 1.7164 - val_loss: 4.1856 - val_mae: 1.6165\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.5523 - mae: 1.7156 - val_loss: 4.1100 - val_mae: 1.5936\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5337 - mae: 1.7171 - val_loss: 4.1459 - val_mae: 1.6066\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4204 - mae: 1.6499 - val_loss: 4.0841 - val_mae: 1.5872\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5104 - mae: 1.6808 - val_loss: 4.0603 - val_mae: 1.5784\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.5226 - mae: 1.6955 - val_loss: 4.0796 - val_mae: 1.5899\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1258 - mae: 1.5904 - val_loss: 4.0461 - val_mae: 1.5767\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.3193 - mae: 1.6386 - val_loss: 4.0236 - val_mae: 1.5726\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.2377 - mae: 1.6641 - val_loss: 4.0077 - val_mae: 1.5725\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.3106 - mae: 1.6462 - val_loss: 4.0918 - val_mae: 1.5970\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.1482 - mae: 1.6016 - val_loss: 3.9851 - val_mae: 1.5630\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7162 - mae: 1.5300 - val_loss: 3.9563 - val_mae: 1.5514\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0064 - mae: 1.5984 - val_loss: 4.0353 - val_mae: 1.5790\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3391 - mae: 1.6554 - val_loss: 3.9524 - val_mae: 1.5493\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3200 - mae: 1.6501 - val_loss: 4.0198 - val_mae: 1.5768\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3750 - mae: 1.6659 - val_loss: 3.9408 - val_mae: 1.5497\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0952 - mae: 1.6221 - val_loss: 3.9792 - val_mae: 1.5644\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1231 - mae: 1.5811 - val_loss: 3.9493 - val_mae: 1.5516\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0918 - mae: 1.6088 - val_loss: 3.8814 - val_mae: 1.5336\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1414 - mae: 1.6141 - val_loss: 3.9817 - val_mae: 1.5628\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4064 - mae: 1.6655 - val_loss: 3.9233 - val_mae: 1.5505\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1621 - mae: 1.6281 - val_loss: 3.9877 - val_mae: 1.5722\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1843 - mae: 1.6337 - val_loss: 3.8493 - val_mae: 1.5208\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9309 - mae: 1.5341 - val_loss: 3.8983 - val_mae: 1.5383\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0728 - mae: 1.5892 - val_loss: 3.9397 - val_mae: 1.5539\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0371 - mae: 1.5863 - val_loss: 3.9032 - val_mae: 1.5396\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1570 - mae: 1.6139 - val_loss: 3.8595 - val_mae: 1.5241\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9535 - mae: 1.5932 - val_loss: 3.8331 - val_mae: 1.5084\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9833 - mae: 1.6013 - val_loss: 3.9009 - val_mae: 1.5405\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5575 - mae: 1.4944 - val_loss: 3.8767 - val_mae: 1.5296\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2211 - mae: 1.6191 - val_loss: 3.8533 - val_mae: 1.5257\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0797 - mae: 1.5941 - val_loss: 3.8995 - val_mae: 1.5358\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1868 - mae: 1.6319 - val_loss: 3.9132 - val_mae: 1.5443\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1509 - mae: 1.6126 - val_loss: 3.8326 - val_mae: 1.5151\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0047 - mae: 1.5731 - val_loss: 3.9305 - val_mae: 1.5467\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3371 - mae: 1.6542 - val_loss: 3.7799 - val_mae: 1.4811\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9583 - mae: 1.5828 - val_loss: 3.9270 - val_mae: 1.5396\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9897 - mae: 1.5718 - val_loss: 3.8525 - val_mae: 1.5240\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0718 - mae: 1.6071 - val_loss: 3.8521 - val_mae: 1.5214\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3829 - mae: 1.6622 - val_loss: 3.7751 - val_mae: 1.4967\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1947 - mae: 1.6161 - val_loss: 3.9132 - val_mae: 1.5478\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7252 - mae: 1.5331 - val_loss: 3.7844 - val_mae: 1.4988\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1047 - mae: 1.5932 - val_loss: 3.8662 - val_mae: 1.5304\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7428 - mae: 1.5513 - val_loss: 3.8343 - val_mae: 1.5195\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0407 - mae: 1.5856 - val_loss: 3.7255 - val_mae: 1.4801\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9025 - mae: 1.5650 - val_loss: 3.8125 - val_mae: 1.5138\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8534 - mae: 1.5766 - val_loss: 3.8372 - val_mae: 1.5164\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8662 - mae: 1.5521 - val_loss: 3.7833 - val_mae: 1.5044\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9888 - mae: 1.5615 - val_loss: 3.8804 - val_mae: 1.5341\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9724 - mae: 1.5881 - val_loss: 3.7624 - val_mae: 1.5002\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9733 - mae: 1.5706 - val_loss: 3.8470 - val_mae: 1.5249\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8790 - mae: 1.5572 - val_loss: 3.7899 - val_mae: 1.4998\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0686 - mae: 1.6003 - val_loss: 3.8184 - val_mae: 1.5231\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8016 - mae: 1.5369 - val_loss: 3.7258 - val_mae: 1.4804\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7126 - mae: 1.5262 - val_loss: 3.8317 - val_mae: 1.5206\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0751 - mae: 1.5959 - val_loss: 3.8014 - val_mae: 1.5190\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4788 - mae: 1.4728 - val_loss: 3.7546 - val_mae: 1.4988\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6882 - mae: 1.5075 - val_loss: 3.7480 - val_mae: 1.4894\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4327 - mae: 1.6604 - val_loss: 3.8425 - val_mae: 1.5353\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9322 - mae: 1.5660 - val_loss: 3.7514 - val_mae: 1.4985\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5253 - mae: 1.4737 - val_loss: 3.8055 - val_mae: 1.5057\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0971 - mae: 1.6129 - val_loss: 3.6980 - val_mae: 1.4816\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7171 - mae: 1.5048 - val_loss: 3.9235 - val_mae: 1.5543\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1986 - mae: 1.6184 - val_loss: 3.7393 - val_mae: 1.4828\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0918 - mae: 1.6106 - val_loss: 3.7715 - val_mae: 1.5122\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9140 - mae: 1.5795 - val_loss: 3.8716 - val_mae: 1.5341\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2176 - mae: 1.6150 - val_loss: 3.7022 - val_mae: 1.4771\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8673 - mae: 1.5637 - val_loss: 3.8367 - val_mae: 1.5251\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0486 - mae: 1.5557 - val_loss: 3.8008 - val_mae: 1.5166\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8978 - mae: 1.5469 - val_loss: 3.7834 - val_mae: 1.5105\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6976 - mae: 1.5455 - val_loss: 3.6942 - val_mae: 1.4856\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9565 - mae: 1.5722 - val_loss: 3.8249 - val_mae: 1.5104\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1477 - mae: 1.6108 - val_loss: 3.7984 - val_mae: 1.5168\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9672 - mae: 1.5791 - val_loss: 3.7961 - val_mae: 1.5186\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8189 - mae: 1.5596 - val_loss: 3.7255 - val_mae: 1.4802\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9009 - mae: 1.5597 - val_loss: 3.8201 - val_mae: 1.5220\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5802 - mae: 1.5157 - val_loss: 3.8500 - val_mae: 1.5277\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9290 - mae: 1.5563 - val_loss: 3.8752 - val_mae: 1.5359\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3864 - mae: 1.4519 - val_loss: 3.8219 - val_mae: 1.5321\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5195 - mae: 1.4965 - val_loss: 3.9006 - val_mae: 1.5424\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9852 - mae: 1.5652 - val_loss: 3.8313 - val_mae: 1.5226\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0013 - mae: 1.5814 - val_loss: 3.8063 - val_mae: 1.5067\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6984 - mae: 1.4999 - val_loss: 3.9653 - val_mae: 1.5593\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4191 - mae: 1.4643 - val_loss: 3.7731 - val_mae: 1.4901\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6826 - mae: 1.5124 - val_loss: 3.9900 - val_mae: 1.5783\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6225 - mae: 1.5277 - val_loss: 3.7782 - val_mae: 1.4863\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7208 - mae: 1.5025 - val_loss: 3.8990 - val_mae: 1.5393\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5178 - mae: 1.4792 - val_loss: 3.9292 - val_mae: 1.5536\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3275 - mae: 1.6382 \n",
            "Test MAE (Mean Absolute Error): 1.68\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "   Predicted     Actual\n",
            "0   7.806712   7.494001\n",
            "1  11.540154  12.394215\n",
            "2  10.383433   9.997158\n",
            "3   7.449747   8.965073\n",
            "4   7.610167  11.882369\n",
            "5  11.363566   8.595982\n",
            "6  11.036774  13.475625\n",
            "7   8.083040  11.871617\n",
            "8   6.388945   4.827736\n",
            "9   8.235040   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Predicted total rebounds for the player's next game: 8.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#paul Siakan"
      ],
      "metadata": {
        "id": "-8lyUrJPwb7c"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vziX3-HGwdYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [7.4], # Changed to list\n",
        "    'avg_min_last5': [35.5], # Changed to list\n",
        "    'opp_avg_reb_allowed': [43.3], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [6], # Changed to list\n",
        "    'home_indicator': [0], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69661157-4793-4da3-d99d-e6f98780fd74",
        "id": "7PgjMORiwdiJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 81.0279 - mae: 8.4865 - val_loss: 69.8765 - val_mae: 7.9685\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 56.6477 - mae: 7.0049 - val_loss: 40.1230 - val_mae: 5.8564\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.8655 - mae: 4.7289 - val_loss: 14.0661 - val_mae: 3.2266\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.5424 - mae: 2.6356 - val_loss: 5.4186 - val_mae: 1.8392\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.0805 - mae: 1.9649 - val_loss: 4.6175 - val_mae: 1.6627\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.1620 - mae: 1.8018 - val_loss: 4.6126 - val_mae: 1.6796\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0818 - mae: 1.7846 - val_loss: 4.5571 - val_mae: 1.6741\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7617 - mae: 1.7283 - val_loss: 4.5786 - val_mae: 1.6911\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9394 - mae: 1.7516 - val_loss: 4.4674 - val_mae: 1.6604\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9171 - mae: 1.7622 - val_loss: 4.4393 - val_mae: 1.6583\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9777 - mae: 1.7526 - val_loss: 4.3608 - val_mae: 1.6352\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6513 - mae: 1.7222 - val_loss: 4.3126 - val_mae: 1.6275\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0817 - mae: 1.7725 - val_loss: 4.3392 - val_mae: 1.6366\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6295 - mae: 1.7105 - val_loss: 4.2379 - val_mae: 1.6092\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5430 - mae: 1.6870 - val_loss: 4.2754 - val_mae: 1.6250\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6984 - mae: 1.7024 - val_loss: 4.1815 - val_mae: 1.5886\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3943 - mae: 1.6676 - val_loss: 4.2053 - val_mae: 1.6053\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5200 - mae: 1.6984 - val_loss: 4.2343 - val_mae: 1.6170\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3392 - mae: 1.6724 - val_loss: 4.1310 - val_mae: 1.5846\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5844 - mae: 1.6857 - val_loss: 4.1076 - val_mae: 1.5760\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8396 - mae: 1.7528 - val_loss: 4.1745 - val_mae: 1.6001\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1567 - mae: 1.6369 - val_loss: 4.1020 - val_mae: 1.5782\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2962 - mae: 1.6530 - val_loss: 4.1193 - val_mae: 1.5889\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2577 - mae: 1.6188 - val_loss: 4.0857 - val_mae: 1.5793\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2423 - mae: 1.6298 - val_loss: 4.0515 - val_mae: 1.5645\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2436 - mae: 1.6339 - val_loss: 4.0624 - val_mae: 1.5733\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2637 - mae: 1.6380 - val_loss: 4.0996 - val_mae: 1.5879\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4647 - mae: 1.6610 - val_loss: 4.0212 - val_mae: 1.5551\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2572 - mae: 1.6526 - val_loss: 3.9992 - val_mae: 1.5513\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4200 - mae: 1.6482 - val_loss: 4.0770 - val_mae: 1.5865\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1809 - mae: 1.6152 - val_loss: 3.9163 - val_mae: 1.5099\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2681 - mae: 1.6332 - val_loss: 4.0213 - val_mae: 1.5651\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1909 - mae: 1.6058 - val_loss: 3.9404 - val_mae: 1.5280\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1671 - mae: 1.5991 - val_loss: 4.0569 - val_mae: 1.5862\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2519 - mae: 1.6474 - val_loss: 3.9245 - val_mae: 1.5155\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0664 - mae: 1.5725 - val_loss: 4.0520 - val_mae: 1.5861\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1176 - mae: 1.6029 - val_loss: 3.9699 - val_mae: 1.5404\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1400 - mae: 1.6323 - val_loss: 3.9789 - val_mae: 1.5541\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2493 - mae: 1.6084 - val_loss: 3.9526 - val_mae: 1.5394\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0037 - mae: 1.5939 - val_loss: 4.0251 - val_mae: 1.5708\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0698 - mae: 1.5931 - val_loss: 3.9363 - val_mae: 1.5305\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9405 - mae: 1.5681 - val_loss: 3.9035 - val_mae: 1.5289\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1851 - mae: 1.6242 - val_loss: 3.9877 - val_mae: 1.5551\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1493 - mae: 1.6517 - val_loss: 3.9265 - val_mae: 1.5334\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8885 - mae: 1.5756 - val_loss: 3.9350 - val_mae: 1.5400\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2634 - mae: 1.6391 - val_loss: 3.9146 - val_mae: 1.5390\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0077 - mae: 1.6040 - val_loss: 3.9733 - val_mae: 1.5458\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0258 - mae: 1.5888 - val_loss: 3.9700 - val_mae: 1.5568\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1983 - mae: 1.6157 - val_loss: 3.9089 - val_mae: 1.5291\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8571 - mae: 1.5744 - val_loss: 4.0207 - val_mae: 1.5783\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9550 - mae: 1.5764 - val_loss: 3.8712 - val_mae: 1.5182\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8485 - mae: 1.5398 - val_loss: 3.8970 - val_mae: 1.5315\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0955 - mae: 1.6094 - val_loss: 3.8492 - val_mae: 1.5084\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6514 - mae: 1.5078 - val_loss: 3.8661 - val_mae: 1.5224\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0004 - mae: 1.5925 - val_loss: 3.9519 - val_mae: 1.5560\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9805 - mae: 1.5973 - val_loss: 3.8452 - val_mae: 1.5181\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1195 - mae: 1.6255 - val_loss: 4.0062 - val_mae: 1.5661\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9993 - mae: 1.5880 - val_loss: 3.8890 - val_mae: 1.5355\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9213 - mae: 1.5616 - val_loss: 3.8681 - val_mae: 1.5215\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6498 - mae: 1.4958 - val_loss: 3.8500 - val_mae: 1.5237\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6009 - mae: 1.5006 - val_loss: 3.9447 - val_mae: 1.5437\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9262 - mae: 1.5707 - val_loss: 3.8517 - val_mae: 1.5214\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7770 - mae: 1.5459 - val_loss: 3.9956 - val_mae: 1.5736\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7655 - mae: 1.5362 - val_loss: 3.9530 - val_mae: 1.5559\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9809 - mae: 1.5554 - val_loss: 3.8570 - val_mae: 1.5320\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9879 - mae: 1.5809 - val_loss: 3.8221 - val_mae: 1.5145\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9119 - mae: 1.5607 - val_loss: 3.9935 - val_mae: 1.5748\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5238 - mae: 1.4951 - val_loss: 3.8293 - val_mae: 1.5206\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9963 - mae: 1.5690 - val_loss: 3.9372 - val_mae: 1.5596\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1019 - mae: 1.6044 - val_loss: 3.8571 - val_mae: 1.5366\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5027 - mae: 1.4676 - val_loss: 4.0316 - val_mae: 1.5738\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9489 - mae: 1.5735 - val_loss: 3.9569 - val_mae: 1.5616\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5578 - mae: 1.5011 - val_loss: 3.9351 - val_mae: 1.5666\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6355 - mae: 1.4971 - val_loss: 3.8454 - val_mae: 1.5312\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8236 - mae: 1.5275 - val_loss: 3.9473 - val_mae: 1.5675\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7956 - mae: 1.5386 - val_loss: 3.9216 - val_mae: 1.5547\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7517 - mae: 1.5364 - val_loss: 3.8879 - val_mae: 1.5534\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5557 - mae: 1.4991 - val_loss: 3.8463 - val_mae: 1.5395\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9248 - mae: 1.5489 - val_loss: 3.9120 - val_mae: 1.5645\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.8769 - mae: 1.5649 - val_loss: 3.8832 - val_mae: 1.5512\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6740 - mae: 1.5254 - val_loss: 3.8949 - val_mae: 1.5527\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.7455 - mae: 1.5064 - val_loss: 3.8911 - val_mae: 1.5482\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6604 - mae: 1.4827 - val_loss: 4.0047 - val_mae: 1.5855\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.6903 - mae: 1.5092 - val_loss: 4.1590 - val_mae: 1.6235\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.3317 - mae: 1.4540 - val_loss: 3.9063 - val_mae: 1.5536\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.3829 - mae: 1.4534 - val_loss: 3.9774 - val_mae: 1.5804\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.4891 - mae: 1.4928 - val_loss: 3.9701 - val_mae: 1.5810\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.4487 - mae: 1.4666 - val_loss: 3.8562 - val_mae: 1.5431\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.3372 - mae: 1.4214 - val_loss: 3.8536 - val_mae: 1.5422\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.5170 - mae: 1.4752 - val_loss: 4.1376 - val_mae: 1.6165\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3.9180 - mae: 1.5619 - val_loss: 3.8877 - val_mae: 1.5558\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.5480 - mae: 1.4711 - val_loss: 3.8272 - val_mae: 1.5448\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.5972 - mae: 1.4801 - val_loss: 3.8849 - val_mae: 1.5579\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.5083 - mae: 1.4493 - val_loss: 4.0205 - val_mae: 1.6007\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7160 - mae: 1.5263 - val_loss: 3.8306 - val_mae: 1.5405\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3392 - mae: 1.4504 - val_loss: 4.1489 - val_mae: 1.6250\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6999 - mae: 1.5129 - val_loss: 3.8944 - val_mae: 1.5595\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9144 - mae: 1.5612 - val_loss: 4.0032 - val_mae: 1.5861\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3482 - mae: 1.4419 - val_loss: 4.1458 - val_mae: 1.6311\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8347 - mae: 1.5438 - val_loss: 3.9731 - val_mae: 1.5873\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1979 - mae: 1.6426 \n",
            "Test MAE (Mean Absolute Error): 1.65\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "   Predicted     Actual\n",
            "0   7.146369   7.494001\n",
            "1  11.025592  12.394215\n",
            "2  10.602395   9.997158\n",
            "3   7.355355   8.965073\n",
            "4   8.285747  11.882369\n",
            "5  11.339214   8.595982\n",
            "6  10.972791  13.475625\n",
            "7   8.150258  11.871617\n",
            "8   6.825389   4.827736\n",
            "9   7.713891   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Predicted total rebounds for the player's next game: 8.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#myles turner"
      ],
      "metadata": {
        "id": "ghH1iN4BgDOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6SdrJoy7gIMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [8.8], # Changed to list\n",
        "    'avg_min_last5': [31.4], # Changed to list\n",
        "    'opp_avg_reb_allowed': [43.3], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [6], # Changed to list\n",
        "    'home_indicator': [0], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c391c34e-6f3e-4122-94fc-999d202aaf62",
        "id": "KabEmY7agJym"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 82.2891 - mae: 8.6272 - val_loss: 73.3131 - val_mae: 8.1909\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 58.2764 - mae: 7.1597 - val_loss: 46.1102 - val_mae: 6.3743\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.3811 - mae: 5.3005 - val_loss: 17.5318 - val_mae: 3.7498\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.7582 - mae: 2.9730 - val_loss: 5.3831 - val_mae: 1.8711\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1871 - mae: 1.8032 - val_loss: 4.4892 - val_mae: 1.6001\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.6539 - mae: 1.8724 - val_loss: 4.5070 - val_mae: 1.5954\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2728 - mae: 1.8281 - val_loss: 4.5513 - val_mae: 1.6273\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1653 - mae: 1.7997 - val_loss: 4.4505 - val_mae: 1.6022\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0424 - mae: 1.7909 - val_loss: 4.3072 - val_mae: 1.5535\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3424 - mae: 1.6786 - val_loss: 4.3565 - val_mae: 1.6007\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7110 - mae: 1.7081 - val_loss: 4.2751 - val_mae: 1.5836\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.0264 - mae: 1.7624 - val_loss: 4.2271 - val_mae: 1.5723\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7860 - mae: 1.7454 - val_loss: 4.1837 - val_mae: 1.5747\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6587 - mae: 1.7144 - val_loss: 4.1288 - val_mae: 1.5432\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5371 - mae: 1.6781 - val_loss: 4.0974 - val_mae: 1.5504\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3183 - mae: 1.6505 - val_loss: 4.1422 - val_mae: 1.5673\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6132 - mae: 1.7143 - val_loss: 4.0155 - val_mae: 1.5220\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1632 - mae: 1.6125 - val_loss: 4.0511 - val_mae: 1.5555\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5402 - mae: 1.7116 - val_loss: 4.0030 - val_mae: 1.5356\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6569 - mae: 1.7085 - val_loss: 4.0412 - val_mae: 1.5566\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4868 - mae: 1.6873 - val_loss: 3.9728 - val_mae: 1.5314\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3713 - mae: 1.6650 - val_loss: 3.9264 - val_mae: 1.5184\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4854 - mae: 1.6762 - val_loss: 4.0142 - val_mae: 1.5561\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5141 - mae: 1.6687 - val_loss: 3.9299 - val_mae: 1.5341\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1381 - mae: 1.6143 - val_loss: 3.9211 - val_mae: 1.5324\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2665 - mae: 1.6179 - val_loss: 3.9253 - val_mae: 1.5274\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4248 - mae: 1.6788 - val_loss: 3.8704 - val_mae: 1.5215\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6563 - mae: 1.6957 - val_loss: 3.8802 - val_mae: 1.5239\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2600 - mae: 1.6295 - val_loss: 3.7837 - val_mae: 1.4874\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7790 - mae: 1.5457 - val_loss: 3.8537 - val_mae: 1.5086\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4540 - mae: 1.6754 - val_loss: 3.8373 - val_mae: 1.5199\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0398 - mae: 1.5747 - val_loss: 3.8234 - val_mae: 1.5155\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0871 - mae: 1.5870 - val_loss: 3.8153 - val_mae: 1.5109\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8558 - mae: 1.5713 - val_loss: 3.8029 - val_mae: 1.5101\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2797 - mae: 1.6462 - val_loss: 3.7212 - val_mae: 1.4882\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8010 - mae: 1.5443 - val_loss: 3.7913 - val_mae: 1.5176\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0582 - mae: 1.5882 - val_loss: 3.7705 - val_mae: 1.4994\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2788 - mae: 1.6547 - val_loss: 3.6851 - val_mae: 1.4783\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0216 - mae: 1.6094 - val_loss: 3.8347 - val_mae: 1.5389\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1785 - mae: 1.6093 - val_loss: 3.6359 - val_mae: 1.4638\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0574 - mae: 1.6040 - val_loss: 3.8706 - val_mae: 1.5454\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1431 - mae: 1.6064 - val_loss: 3.7365 - val_mae: 1.5064\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2060 - mae: 1.6261 - val_loss: 3.7143 - val_mae: 1.4949\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6839 - mae: 1.5166 - val_loss: 3.6776 - val_mae: 1.4832\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7117 - mae: 1.5206 - val_loss: 3.6859 - val_mae: 1.4941\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8832 - mae: 1.5633 - val_loss: 3.7047 - val_mae: 1.4949\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2255 - mae: 1.6437 - val_loss: 3.7142 - val_mae: 1.4972\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1854 - mae: 1.5858 - val_loss: 3.5821 - val_mae: 1.4473\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8573 - mae: 1.5760 - val_loss: 3.6985 - val_mae: 1.4966\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1347 - mae: 1.6100 - val_loss: 3.8174 - val_mae: 1.5410\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8382 - mae: 1.5614 - val_loss: 3.6556 - val_mae: 1.4825\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1172 - mae: 1.6286 - val_loss: 3.7917 - val_mae: 1.5296\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9785 - mae: 1.6025 - val_loss: 3.6193 - val_mae: 1.4701\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7975 - mae: 1.5463 - val_loss: 3.6482 - val_mae: 1.4775\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9704 - mae: 1.5696 - val_loss: 3.6212 - val_mae: 1.4612\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5698 - mae: 1.4914 - val_loss: 3.6855 - val_mae: 1.4962\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8108 - mae: 1.5290 - val_loss: 3.6416 - val_mae: 1.4749\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5204 - mae: 1.6875 - val_loss: 3.8011 - val_mae: 1.5295\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8687 - mae: 1.5759 - val_loss: 3.6585 - val_mae: 1.4883\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9262 - mae: 1.5615 - val_loss: 3.6305 - val_mae: 1.4688\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9012 - mae: 1.5586 - val_loss: 3.7493 - val_mae: 1.5149\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9659 - mae: 1.5903 - val_loss: 3.6303 - val_mae: 1.4743\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7720 - mae: 1.5344 - val_loss: 3.6093 - val_mae: 1.4698\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9839 - mae: 1.5594 - val_loss: 3.5995 - val_mae: 1.4598\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6497 - mae: 1.5033 - val_loss: 3.7770 - val_mae: 1.5195\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9111 - mae: 1.5500 - val_loss: 3.5921 - val_mae: 1.4718\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7641 - mae: 1.5195 - val_loss: 3.7260 - val_mae: 1.5116\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6803 - mae: 1.5192 - val_loss: 3.6233 - val_mae: 1.4727\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7034 - mae: 1.4991 - val_loss: 3.6852 - val_mae: 1.4932\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7736 - mae: 1.5532 - val_loss: 3.7066 - val_mae: 1.4963\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7406 - mae: 1.5183 - val_loss: 3.6331 - val_mae: 1.4732\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8023 - mae: 1.5609 - val_loss: 3.6300 - val_mae: 1.4780\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8745 - mae: 1.5511 - val_loss: 3.6460 - val_mae: 1.4807\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7629 - mae: 1.5482 - val_loss: 3.7266 - val_mae: 1.5053\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6776 - mae: 1.5115 - val_loss: 3.6477 - val_mae: 1.4827\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6051 - mae: 1.5019 - val_loss: 3.6944 - val_mae: 1.4965\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4470 - mae: 1.4524 - val_loss: 3.6606 - val_mae: 1.4842\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6184 - mae: 1.5026 - val_loss: 3.8463 - val_mae: 1.5273\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5606 - mae: 1.5038 - val_loss: 3.6032 - val_mae: 1.4720\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9930 - mae: 1.5772 - val_loss: 3.6581 - val_mae: 1.4938\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5929 - mae: 1.5083 - val_loss: 3.6744 - val_mae: 1.4951\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8218 - mae: 1.5416 - val_loss: 3.6416 - val_mae: 1.4897\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6101 - mae: 1.5278 - val_loss: 3.7103 - val_mae: 1.5012\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7277 - mae: 1.5469 - val_loss: 3.6972 - val_mae: 1.5003\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6069 - mae: 1.5078 - val_loss: 3.7680 - val_mae: 1.5188\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6754 - mae: 1.4989 - val_loss: 3.7020 - val_mae: 1.5127\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6124 - mae: 1.5023 - val_loss: 3.7650 - val_mae: 1.5182\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7725 - mae: 1.5204 - val_loss: 3.6727 - val_mae: 1.4900\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8141 - mae: 1.5396 - val_loss: 3.7444 - val_mae: 1.5113\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4542 - mae: 1.4578 - val_loss: 3.7131 - val_mae: 1.5145\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7254 - mae: 1.5148 - val_loss: 3.6781 - val_mae: 1.4989\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9487 - mae: 1.5642 - val_loss: 3.6982 - val_mae: 1.5038\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5575 - mae: 1.4915 - val_loss: 3.7979 - val_mae: 1.5293\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4409 - mae: 1.4871 - val_loss: 3.6979 - val_mae: 1.5030\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7183 - mae: 1.5543 - val_loss: 3.6917 - val_mae: 1.4999\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5872 - mae: 1.4930 - val_loss: 3.6708 - val_mae: 1.5023\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5940 - mae: 1.5153 - val_loss: 3.6997 - val_mae: 1.5077\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8174 - mae: 1.5172 - val_loss: 3.7519 - val_mae: 1.5133\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4355 - mae: 1.4890 - val_loss: 3.7747 - val_mae: 1.5218\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4384 - mae: 1.4700 - val_loss: 3.6959 - val_mae: 1.5089\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2579 - mae: 1.6503 \n",
            "Test MAE (Mean Absolute Error): 1.67\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "   Predicted     Actual\n",
            "0   7.122822   7.494001\n",
            "1  11.450759  12.394215\n",
            "2  10.178954   9.997158\n",
            "3   7.721508   8.965073\n",
            "4   8.037405  11.882369\n",
            "5  11.136523   8.595982\n",
            "6  11.038586  13.475625\n",
            "7   8.788645  11.871617\n",
            "8   6.423652   4.827736\n",
            "9   8.314388   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Predicted total rebounds for the player's next game: 9.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#karl town"
      ],
      "metadata": {
        "id": "17OXED4xxiL1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6P_H6l95xjh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [13.4], # Changed to list\n",
        "    'avg_min_last5': [36.2], # Changed to list\n",
        "    'opp_avg_reb_allowed': [44.2], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [6.8], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ca3d50b-d2e6-40d6-f1e1-cc43b4c71c14",
        "id": "RhK3yP_SxjvF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 79.1107 - mae: 8.4141 - val_loss: 73.6922 - val_mae: 8.1909\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 60.4533 - mae: 7.2407 - val_loss: 50.2420 - val_mae: 6.6190\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36.2559 - mae: 5.4142 - val_loss: 23.6788 - val_mae: 4.3614\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.8318 - mae: 3.1804 - val_loss: 7.7646 - val_mae: 2.3141\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7346 - mae: 1.8831 - val_loss: 5.0483 - val_mae: 1.7880\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2544 - mae: 1.8087 - val_loss: 4.8428 - val_mae: 1.7372\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1948 - mae: 1.8044 - val_loss: 4.7718 - val_mae: 1.7210\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0981 - mae: 1.7960 - val_loss: 4.6434 - val_mae: 1.6897\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6823 - mae: 1.7212 - val_loss: 4.5011 - val_mae: 1.6495\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0841 - mae: 1.8053 - val_loss: 4.5243 - val_mae: 1.6721\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2549 - mae: 1.8216 - val_loss: 4.3495 - val_mae: 1.6124\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7834 - mae: 1.7362 - val_loss: 4.3728 - val_mae: 1.6283\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6871 - mae: 1.6997 - val_loss: 4.3282 - val_mae: 1.6236\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5827 - mae: 1.7098 - val_loss: 4.2143 - val_mae: 1.5784\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5578 - mae: 1.7073 - val_loss: 4.3788 - val_mae: 1.6572\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6079 - mae: 1.7156 - val_loss: 4.2314 - val_mae: 1.6023\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1419 - mae: 1.6174 - val_loss: 4.2245 - val_mae: 1.6007\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6341 - mae: 1.7111 - val_loss: 4.2040 - val_mae: 1.5980\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4134 - mae: 1.6629 - val_loss: 4.0863 - val_mae: 1.5518\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3038 - mae: 1.6731 - val_loss: 4.1314 - val_mae: 1.5682\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5260 - mae: 1.6698 - val_loss: 4.0731 - val_mae: 1.5573\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5545 - mae: 1.6998 - val_loss: 4.0540 - val_mae: 1.5444\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1162 - mae: 1.6201 - val_loss: 4.0628 - val_mae: 1.5591\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5191 - mae: 1.6801 - val_loss: 4.0280 - val_mae: 1.5381\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3894 - mae: 1.6349 - val_loss: 4.0539 - val_mae: 1.5578\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4635 - mae: 1.6986 - val_loss: 4.0008 - val_mae: 1.5358\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1896 - mae: 1.5981 - val_loss: 3.9872 - val_mae: 1.5326\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3688 - mae: 1.6569 - val_loss: 4.0039 - val_mae: 1.5468\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0971 - mae: 1.5925 - val_loss: 3.9503 - val_mae: 1.5192\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7782 - mae: 1.7413 - val_loss: 3.9699 - val_mae: 1.5319\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9986 - mae: 1.5686 - val_loss: 3.9887 - val_mae: 1.5542\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0371 - mae: 1.6020 - val_loss: 3.9169 - val_mae: 1.5227\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1536 - mae: 1.6346 - val_loss: 3.9171 - val_mae: 1.5223\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0456 - mae: 1.5913 - val_loss: 3.8332 - val_mae: 1.4964\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3278 - mae: 1.6351 - val_loss: 3.9003 - val_mae: 1.5322\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4457 - mae: 1.6848 - val_loss: 3.8839 - val_mae: 1.5188\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2612 - mae: 1.6411 - val_loss: 3.8804 - val_mae: 1.5280\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8728 - mae: 1.5559 - val_loss: 3.8068 - val_mae: 1.4876\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2794 - mae: 1.6261 - val_loss: 3.7716 - val_mae: 1.4895\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4766 - mae: 1.6818 - val_loss: 3.8350 - val_mae: 1.5122\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1607 - mae: 1.6212 - val_loss: 3.8360 - val_mae: 1.5066\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1091 - mae: 1.5790 - val_loss: 3.7711 - val_mae: 1.4924\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0014 - mae: 1.5662 - val_loss: 3.8265 - val_mae: 1.5023\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8523 - mae: 1.5680 - val_loss: 3.7273 - val_mae: 1.4748\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8324 - mae: 1.5613 - val_loss: 3.8253 - val_mae: 1.5241\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7929 - mae: 1.5383 - val_loss: 3.8235 - val_mae: 1.5174\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0935 - mae: 1.5772 - val_loss: 3.7309 - val_mae: 1.4738\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1624 - mae: 1.6031 - val_loss: 3.7365 - val_mae: 1.4876\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9033 - mae: 1.5931 - val_loss: 3.6838 - val_mae: 1.4707\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0960 - mae: 1.6004 - val_loss: 3.7689 - val_mae: 1.5047\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6232 - mae: 1.5099 - val_loss: 3.7025 - val_mae: 1.4738\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8867 - mae: 1.5729 - val_loss: 3.7012 - val_mae: 1.4785\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6420 - mae: 1.5220 - val_loss: 3.7579 - val_mae: 1.4992\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6412 - mae: 1.5120 - val_loss: 3.7270 - val_mae: 1.4891\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8360 - mae: 1.5594 - val_loss: 3.8051 - val_mae: 1.5218\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0939 - mae: 1.6058 - val_loss: 3.7122 - val_mae: 1.4829\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1270 - mae: 1.6144 - val_loss: 3.7185 - val_mae: 1.4907\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8486 - mae: 1.5114 - val_loss: 3.7417 - val_mae: 1.4996\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7579 - mae: 1.5325 - val_loss: 3.6025 - val_mae: 1.4474\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8144 - mae: 1.5439 - val_loss: 3.7794 - val_mae: 1.5229\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8528 - mae: 1.5466 - val_loss: 3.6459 - val_mae: 1.4694\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8311 - mae: 1.5525 - val_loss: 3.6952 - val_mae: 1.4844\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7735 - mae: 1.5279 - val_loss: 3.6799 - val_mae: 1.4677\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7856 - mae: 1.5643 - val_loss: 3.6492 - val_mae: 1.4724\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9226 - mae: 1.5681 - val_loss: 3.7530 - val_mae: 1.5102\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1051 - mae: 1.6017 - val_loss: 3.7088 - val_mae: 1.4909\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6441 - mae: 1.5182 - val_loss: 3.6558 - val_mae: 1.4775\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0926 - mae: 1.6092 - val_loss: 3.6733 - val_mae: 1.4823\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7800 - mae: 1.5467 - val_loss: 3.7443 - val_mae: 1.5053\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3829 - mae: 1.4552 - val_loss: 3.7901 - val_mae: 1.5195\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5896 - mae: 1.5106 - val_loss: 3.7248 - val_mae: 1.4900\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4388 - mae: 1.4649 - val_loss: 3.7019 - val_mae: 1.4870\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7137 - mae: 1.5237 - val_loss: 3.7207 - val_mae: 1.4979\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7966 - mae: 1.5451 - val_loss: 3.9009 - val_mae: 1.5461\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7638 - mae: 1.5393 - val_loss: 3.6453 - val_mae: 1.4736\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7015 - mae: 1.5076 - val_loss: 3.8300 - val_mae: 1.5282\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7043 - mae: 1.5177 - val_loss: 3.7556 - val_mae: 1.5102\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6844 - mae: 1.5188 - val_loss: 3.6918 - val_mae: 1.4928\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8452 - mae: 1.5410 - val_loss: 3.7206 - val_mae: 1.4989\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3019 - mae: 1.4387 - val_loss: 3.7932 - val_mae: 1.5241\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5777 - mae: 1.4961 - val_loss: 3.7496 - val_mae: 1.5139\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4131 - mae: 1.4700 - val_loss: 3.7384 - val_mae: 1.5041\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6945 - mae: 1.5197 - val_loss: 3.8015 - val_mae: 1.5262\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4371 - mae: 1.4620 - val_loss: 3.7115 - val_mae: 1.5032\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8403 - mae: 1.5470 - val_loss: 3.8926 - val_mae: 1.5569\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5986 - mae: 1.5053 - val_loss: 3.6859 - val_mae: 1.4946\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6204 - mae: 1.4930 - val_loss: 3.7760 - val_mae: 1.5221\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4960 - mae: 1.4973 - val_loss: 3.7521 - val_mae: 1.5152\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7063 - mae: 1.5210 - val_loss: 3.7119 - val_mae: 1.4999\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6835 - mae: 1.5225 - val_loss: 3.7352 - val_mae: 1.5120\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6218 - mae: 1.5041 - val_loss: 3.7086 - val_mae: 1.5028\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5034 - mae: 1.4872 - val_loss: 3.8539 - val_mae: 1.5411\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3641 - mae: 1.4392 - val_loss: 3.7567 - val_mae: 1.5170\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5156 - mae: 1.4745 - val_loss: 3.8315 - val_mae: 1.5370\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5984 - mae: 1.5009 - val_loss: 3.8085 - val_mae: 1.5330\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4467 - mae: 1.4597 - val_loss: 3.7243 - val_mae: 1.5099\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4540 - mae: 1.5052 - val_loss: 3.7968 - val_mae: 1.5305\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5137 - mae: 1.4662 - val_loss: 3.7414 - val_mae: 1.5135\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2761 - mae: 1.4367 - val_loss: 3.7692 - val_mae: 1.5273\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6434 - mae: 1.5089 - val_loss: 3.7562 - val_mae: 1.5247\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2107 - mae: 1.6229 \n",
            "Test MAE (Mean Absolute Error): 1.65\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
            "   Predicted     Actual\n",
            "0   7.188503   7.494001\n",
            "1  11.360682  12.394215\n",
            "2   9.820944   9.997158\n",
            "3   7.563365   8.965073\n",
            "4   8.057117  11.882369\n",
            "5  11.639812   8.595982\n",
            "6  11.288486  13.475625\n",
            "7   8.242910  11.871617\n",
            "8   6.147841   4.827736\n",
            "9   8.317706   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Predicted total rebounds for the player's next game: 11.72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#jacob polt"
      ],
      "metadata": {
        "id": "WRHaq19nyqqi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pk2SWYEoysg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [12], # Changed to list\n",
        "    'avg_min_last5': [30.5], # Changed to list\n",
        "    'opp_avg_reb_allowed': [46.2], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [10], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "846afac6-46a0-4d87-d9be-26fff6746ccc",
        "id": "pVd-YBcxysvU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 81.4366 - mae: 8.5874 - val_loss: 76.0124 - val_mae: 8.3433\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 63.4361 - mae: 7.4302 - val_loss: 51.5588 - val_mae: 6.7587\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 38.1712 - mae: 5.6360 - val_loss: 24.5451 - val_mae: 4.4744\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.9790 - mae: 3.6039 - val_loss: 8.0267 - val_mae: 2.3430\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.2567 - mae: 2.1458 - val_loss: 4.7463 - val_mae: 1.7341\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.6041 - mae: 1.8501 - val_loss: 4.5710 - val_mae: 1.6678\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2925 - mae: 1.8302 - val_loss: 4.6067 - val_mae: 1.6880\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1811 - mae: 1.8005 - val_loss: 4.5399 - val_mae: 1.6742\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8301 - mae: 1.7398 - val_loss: 4.4668 - val_mae: 1.6551\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7328 - mae: 1.7208 - val_loss: 4.4038 - val_mae: 1.6292\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7254 - mae: 1.7311 - val_loss: 4.3749 - val_mae: 1.6317\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9540 - mae: 1.7650 - val_loss: 4.3362 - val_mae: 1.6199\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.6756 - mae: 1.7163 - val_loss: 4.2843 - val_mae: 1.6113\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8910 - mae: 1.7260 - val_loss: 4.2290 - val_mae: 1.5966\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4626 - mae: 1.6539 - val_loss: 4.1874 - val_mae: 1.5850\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4543 - mae: 1.6664 - val_loss: 4.2078 - val_mae: 1.5899\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4413 - mae: 1.6583 - val_loss: 4.1841 - val_mae: 1.5898\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4306 - mae: 1.6369 - val_loss: 4.1280 - val_mae: 1.5743\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5831 - mae: 1.7171 - val_loss: 4.1270 - val_mae: 1.5733\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6054 - mae: 1.7100 - val_loss: 4.1522 - val_mae: 1.5885\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3707 - mae: 1.6652 - val_loss: 4.0883 - val_mae: 1.5664\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5907 - mae: 1.6861 - val_loss: 4.0908 - val_mae: 1.5695\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4873 - mae: 1.6602 - val_loss: 4.1293 - val_mae: 1.5855\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3845 - mae: 1.6667 - val_loss: 4.0810 - val_mae: 1.5631\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0375 - mae: 1.5775 - val_loss: 4.0916 - val_mae: 1.5727\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2671 - mae: 1.6304 - val_loss: 3.9886 - val_mae: 1.5401\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2798 - mae: 1.6255 - val_loss: 4.1661 - val_mae: 1.6048\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2775 - mae: 1.6260 - val_loss: 3.9827 - val_mae: 1.5436\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3304 - mae: 1.6618 - val_loss: 4.0532 - val_mae: 1.5752\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3267 - mae: 1.6485 - val_loss: 4.0975 - val_mae: 1.5790\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1537 - mae: 1.6379 - val_loss: 4.1026 - val_mae: 1.5870\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1836 - mae: 1.6131 - val_loss: 3.9702 - val_mae: 1.5412\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7254 - mae: 1.5221 - val_loss: 4.0485 - val_mae: 1.5700\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0129 - mae: 1.5660 - val_loss: 3.9846 - val_mae: 1.5460\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1561 - mae: 1.6012 - val_loss: 4.0176 - val_mae: 1.5636\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1516 - mae: 1.6212 - val_loss: 4.0150 - val_mae: 1.5658\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8470 - mae: 1.5702 - val_loss: 3.9634 - val_mae: 1.5399\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0983 - mae: 1.5756 - val_loss: 4.0344 - val_mae: 1.5743\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1759 - mae: 1.6225 - val_loss: 3.9755 - val_mae: 1.5454\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2329 - mae: 1.6303 - val_loss: 3.9557 - val_mae: 1.5459\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5739 - mae: 1.5132 - val_loss: 4.0019 - val_mae: 1.5539\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1024 - mae: 1.6184 - val_loss: 4.0118 - val_mae: 1.5567\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0352 - mae: 1.5791 - val_loss: 3.8841 - val_mae: 1.5142\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0411 - mae: 1.5958 - val_loss: 4.0225 - val_mae: 1.5657\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1235 - mae: 1.5945 - val_loss: 3.9648 - val_mae: 1.5418\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9974 - mae: 1.6010 - val_loss: 3.9517 - val_mae: 1.5404\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8649 - mae: 1.5409 - val_loss: 4.0042 - val_mae: 1.5562\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2851 - mae: 1.6374 - val_loss: 3.9817 - val_mae: 1.5521\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8369 - mae: 1.5193 - val_loss: 3.9187 - val_mae: 1.5251\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8810 - mae: 1.5666 - val_loss: 3.9686 - val_mae: 1.5512\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0711 - mae: 1.6208 - val_loss: 3.9041 - val_mae: 1.5217\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1420 - mae: 1.6096 - val_loss: 4.0215 - val_mae: 1.5704\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9754 - mae: 1.5754 - val_loss: 3.9380 - val_mae: 1.5333\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8866 - mae: 1.5715 - val_loss: 3.9891 - val_mae: 1.5597\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7188 - mae: 1.5192 - val_loss: 3.8727 - val_mae: 1.5148\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6885 - mae: 1.5320 - val_loss: 4.0032 - val_mae: 1.5569\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8629 - mae: 1.5268 - val_loss: 3.9069 - val_mae: 1.5308\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6120 - mae: 1.4957 - val_loss: 3.9733 - val_mae: 1.5497\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8884 - mae: 1.5546 - val_loss: 3.9207 - val_mae: 1.5318\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8959 - mae: 1.5375 - val_loss: 3.9978 - val_mae: 1.5557\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7675 - mae: 1.5276 - val_loss: 3.9988 - val_mae: 1.5600\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6318 - mae: 1.4992 - val_loss: 3.9587 - val_mae: 1.5447\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7739 - mae: 1.5298 - val_loss: 4.0206 - val_mae: 1.5700\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7818 - mae: 1.5325 - val_loss: 3.9375 - val_mae: 1.5328\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9543 - mae: 1.5584 - val_loss: 4.0525 - val_mae: 1.5851\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8124 - mae: 1.5395 - val_loss: 3.8915 - val_mae: 1.5210\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7035 - mae: 1.4980 - val_loss: 4.0130 - val_mae: 1.5678\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7540 - mae: 1.5140 - val_loss: 3.9670 - val_mae: 1.5423\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8036 - mae: 1.5531 - val_loss: 4.0126 - val_mae: 1.5677\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9274 - mae: 1.5664 - val_loss: 3.9143 - val_mae: 1.5259\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8899 - mae: 1.5597 - val_loss: 4.0212 - val_mae: 1.5604\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0674 - mae: 1.5917 - val_loss: 3.9182 - val_mae: 1.5221\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5463 - mae: 1.4977 - val_loss: 4.0332 - val_mae: 1.5677\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1726 - mae: 1.5801 - val_loss: 4.0708 - val_mae: 1.5853\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0862 - mae: 1.5975 - val_loss: 3.9834 - val_mae: 1.5530\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6344 - mae: 1.5300 - val_loss: 3.9789 - val_mae: 1.5555\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1424 - mae: 1.6004 - val_loss: 4.0380 - val_mae: 1.5672\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7753 - mae: 1.5292 - val_loss: 3.9912 - val_mae: 1.5488\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5845 - mae: 1.4969 - val_loss: 4.1188 - val_mae: 1.6018\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5379 - mae: 1.4899 - val_loss: 4.0311 - val_mae: 1.5584\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0076 - mae: 1.5715 - val_loss: 3.9973 - val_mae: 1.5463\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7612 - mae: 1.4970 - val_loss: 4.0571 - val_mae: 1.5883\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6632 - mae: 1.5203 - val_loss: 4.0443 - val_mae: 1.5668\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6090 - mae: 1.4858 - val_loss: 4.0415 - val_mae: 1.5654\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8491 - mae: 1.5532 - val_loss: 4.0318 - val_mae: 1.5585\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8503 - mae: 1.5231 - val_loss: 4.1103 - val_mae: 1.5906\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3958 - mae: 1.4657 - val_loss: 4.1098 - val_mae: 1.5970\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3649 - mae: 1.4430 - val_loss: 3.9799 - val_mae: 1.5528\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5815 - mae: 1.4871 - val_loss: 4.1729 - val_mae: 1.6105\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4842 - mae: 1.4595 - val_loss: 4.1576 - val_mae: 1.6175\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7922 - mae: 1.5078 - val_loss: 4.1185 - val_mae: 1.5966\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3919 - mae: 1.4584 - val_loss: 4.0696 - val_mae: 1.5725\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4998 - mae: 1.4645 - val_loss: 4.1024 - val_mae: 1.5837\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4651 - mae: 1.4754 - val_loss: 4.3724 - val_mae: 1.6802\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6849 - mae: 1.5268 - val_loss: 4.0977 - val_mae: 1.5877\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4457 - mae: 1.4771 - val_loss: 4.1225 - val_mae: 1.6004\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6093 - mae: 1.4888 - val_loss: 4.2115 - val_mae: 1.6247\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6636 - mae: 1.4900 - val_loss: 4.1429 - val_mae: 1.6031\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5841 - mae: 1.4888 - val_loss: 4.1391 - val_mae: 1.6034\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5240 - mae: 1.4756 - val_loss: 4.1968 - val_mae: 1.6160\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4648 - mae: 1.7063 \n",
            "Test MAE (Mean Absolute Error): 1.71\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "   Predicted     Actual\n",
            "0   7.612573   7.494001\n",
            "1  11.278628  12.394215\n",
            "2  10.270394   9.997158\n",
            "3   7.461073   8.965073\n",
            "4   7.879335  11.882369\n",
            "5  11.633655   8.595982\n",
            "6  11.000381  13.475625\n",
            "7   8.030901  11.871617\n",
            "8   6.599273   4.827736\n",
            "9   8.459268   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Predicted total rebounds for the player's next game: 10.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#scottie barnes"
      ],
      "metadata": {
        "id": "jnXNCzAezcXW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D1otwNYqzcCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [9.2], # Changed to list\n",
        "    'avg_min_last5': [33.6], # Changed to list\n",
        "    'opp_avg_reb_allowed': [46.2], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [10], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a915b9-53a7-48da-86eb-a578ede6321a",
        "id": "HbDyyhERzeUB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 79.1984 - mae: 8.4058 - val_loss: 74.1941 - val_mae: 8.1990\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 60.9106 - mae: 7.2493 - val_loss: 48.3792 - val_mae: 6.4622\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.4241 - mae: 5.2408 - val_loss: 21.1255 - val_mae: 4.1053\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 14.6920 - mae: 3.2174 - val_loss: 6.7637 - val_mae: 2.1506\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.2695 - mae: 1.9828 - val_loss: 4.3941 - val_mae: 1.5921\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.1428 - mae: 1.8003 - val_loss: 4.2837 - val_mae: 1.5894\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8481 - mae: 1.7262 - val_loss: 4.2799 - val_mae: 1.5974\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8553 - mae: 1.7586 - val_loss: 4.2484 - val_mae: 1.5971\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6239 - mae: 1.7022 - val_loss: 4.1684 - val_mae: 1.5691\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5925 - mae: 1.6848 - val_loss: 4.2245 - val_mae: 1.5908\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5856 - mae: 1.7075 - val_loss: 4.1033 - val_mae: 1.5489\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7909 - mae: 1.7379 - val_loss: 4.1118 - val_mae: 1.5532\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6025 - mae: 1.6987 - val_loss: 4.0834 - val_mae: 1.5428\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.6106 - mae: 1.6894 - val_loss: 4.0537 - val_mae: 1.5481\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3399 - mae: 1.6633 - val_loss: 4.0658 - val_mae: 1.5429\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4590 - mae: 1.6688 - val_loss: 4.1080 - val_mae: 1.5722\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4066 - mae: 1.6738 - val_loss: 4.0283 - val_mae: 1.5312\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8494 - mae: 1.7467 - val_loss: 3.9927 - val_mae: 1.5311\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2154 - mae: 1.6380 - val_loss: 4.0252 - val_mae: 1.5445\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4755 - mae: 1.6836 - val_loss: 3.9386 - val_mae: 1.5078\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3789 - mae: 1.6449 - val_loss: 3.9910 - val_mae: 1.5370\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0421 - mae: 1.6178 - val_loss: 4.0054 - val_mae: 1.5453\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3548 - mae: 1.6633 - val_loss: 3.9688 - val_mae: 1.5370\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2410 - mae: 1.6095 - val_loss: 3.9884 - val_mae: 1.5415\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1232 - mae: 1.6043 - val_loss: 3.9475 - val_mae: 1.5296\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2694 - mae: 1.6633 - val_loss: 3.8713 - val_mae: 1.4883\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3731 - mae: 1.6424 - val_loss: 3.8382 - val_mae: 1.4877\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5666 - mae: 1.6706 - val_loss: 3.8791 - val_mae: 1.5044\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1188 - mae: 1.6139 - val_loss: 3.9676 - val_mae: 1.5339\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8435 - mae: 1.5579 - val_loss: 3.9121 - val_mae: 1.5225\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2792 - mae: 1.6585 - val_loss: 3.8669 - val_mae: 1.5123\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2194 - mae: 1.6301 - val_loss: 3.9178 - val_mae: 1.5336\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8105 - mae: 1.5752 - val_loss: 3.8037 - val_mae: 1.4942\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1874 - mae: 1.6375 - val_loss: 3.9022 - val_mae: 1.5274\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0270 - mae: 1.5838 - val_loss: 3.8266 - val_mae: 1.4906\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1302 - mae: 1.5968 - val_loss: 3.8554 - val_mae: 1.5145\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2003 - mae: 1.6265 - val_loss: 3.7827 - val_mae: 1.4907\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0262 - mae: 1.5721 - val_loss: 3.7955 - val_mae: 1.4982\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1838 - mae: 1.6205 - val_loss: 3.8912 - val_mae: 1.5362\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0507 - mae: 1.5909 - val_loss: 3.7678 - val_mae: 1.4742\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0995 - mae: 1.6164 - val_loss: 3.8611 - val_mae: 1.5274\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0298 - mae: 1.5977 - val_loss: 3.6908 - val_mae: 1.4565\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7274 - mae: 1.5409 - val_loss: 3.8589 - val_mae: 1.5210\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9222 - mae: 1.5840 - val_loss: 3.7792 - val_mae: 1.5028\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8787 - mae: 1.5576 - val_loss: 3.8672 - val_mae: 1.5291\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9003 - mae: 1.5765 - val_loss: 3.6982 - val_mae: 1.4794\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0266 - mae: 1.5875 - val_loss: 3.8348 - val_mae: 1.5295\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9859 - mae: 1.5970 - val_loss: 3.7262 - val_mae: 1.4779\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6190 - mae: 1.4928 - val_loss: 3.7118 - val_mae: 1.4870\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8650 - mae: 1.5179 - val_loss: 3.7830 - val_mae: 1.5056\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7863 - mae: 1.5656 - val_loss: 3.7538 - val_mae: 1.4964\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0444 - mae: 1.6097 - val_loss: 3.7654 - val_mae: 1.5092\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6853 - mae: 1.5384 - val_loss: 3.6878 - val_mae: 1.4724\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8111 - mae: 1.5407 - val_loss: 3.7606 - val_mae: 1.5122\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7890 - mae: 1.5590 - val_loss: 3.6888 - val_mae: 1.4857\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8621 - mae: 1.5638 - val_loss: 3.7002 - val_mae: 1.4966\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8675 - mae: 1.5739 - val_loss: 3.6743 - val_mae: 1.4806\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8975 - mae: 1.5884 - val_loss: 3.7977 - val_mae: 1.5378\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8998 - mae: 1.5526 - val_loss: 3.7320 - val_mae: 1.4992\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7564 - mae: 1.5491 - val_loss: 3.6728 - val_mae: 1.4922\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8714 - mae: 1.5502 - val_loss: 3.7476 - val_mae: 1.5170\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9853 - mae: 1.5644 - val_loss: 3.6942 - val_mae: 1.4919\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6682 - mae: 1.5177 - val_loss: 3.6690 - val_mae: 1.4839\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4616 - mae: 1.4730 - val_loss: 3.6767 - val_mae: 1.4900\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1351 - mae: 1.3972 - val_loss: 3.6779 - val_mae: 1.4896\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5621 - mae: 1.5097 - val_loss: 3.6796 - val_mae: 1.4917\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9776 - mae: 1.5908 - val_loss: 3.6957 - val_mae: 1.5076\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7388 - mae: 1.5325 - val_loss: 3.7086 - val_mae: 1.5120\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6069 - mae: 1.5084 - val_loss: 3.6328 - val_mae: 1.4572\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5788 - mae: 1.4798 - val_loss: 3.7421 - val_mae: 1.5282\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7113 - mae: 1.5341 - val_loss: 3.7316 - val_mae: 1.5121\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9548 - mae: 1.5849 - val_loss: 3.7257 - val_mae: 1.5166\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6380 - mae: 1.5126 - val_loss: 3.6687 - val_mae: 1.4965\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6552 - mae: 1.5202 - val_loss: 3.7862 - val_mae: 1.5424\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8031 - mae: 1.5436 - val_loss: 3.7037 - val_mae: 1.5153\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7988 - mae: 1.5415 - val_loss: 3.7109 - val_mae: 1.5131\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5086 - mae: 1.4860 - val_loss: 3.6873 - val_mae: 1.5077\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8597 - mae: 1.5520 - val_loss: 3.6981 - val_mae: 1.5103\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5557 - mae: 1.4702 - val_loss: 3.8470 - val_mae: 1.5631\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7184 - mae: 1.5576 - val_loss: 3.6414 - val_mae: 1.4670\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5377 - mae: 1.5144 - val_loss: 3.8218 - val_mae: 1.5591\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7666 - mae: 1.5123 - val_loss: 3.6590 - val_mae: 1.4959\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8834 - mae: 1.5410 - val_loss: 3.7305 - val_mae: 1.5267\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5491 - mae: 1.5059 - val_loss: 3.6806 - val_mae: 1.4989\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3147 - mae: 1.4343 - val_loss: 3.8050 - val_mae: 1.5622\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3397 - mae: 1.4414 - val_loss: 3.7255 - val_mae: 1.5275\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5500 - mae: 1.4806 - val_loss: 3.6778 - val_mae: 1.5016\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4893 - mae: 1.4753 - val_loss: 3.7132 - val_mae: 1.5227\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5608 - mae: 1.4960 - val_loss: 3.7424 - val_mae: 1.5380\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3909 - mae: 1.4675 - val_loss: 3.7405 - val_mae: 1.5296\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4174 - mae: 1.4718 - val_loss: 3.6615 - val_mae: 1.4946\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7273 - mae: 1.5278 - val_loss: 3.7739 - val_mae: 1.5454\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4543 - mae: 1.4763 - val_loss: 3.7980 - val_mae: 1.5579\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7112 - mae: 1.5541 - val_loss: 3.8516 - val_mae: 1.5743\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3364 - mae: 1.4391 - val_loss: 3.6792 - val_mae: 1.5023\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4666 - mae: 1.4584 - val_loss: 4.0948 - val_mae: 1.6506\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6002 - mae: 1.4979 - val_loss: 3.6918 - val_mae: 1.5191\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4497 - mae: 1.4772 - val_loss: 3.7557 - val_mae: 1.5233\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6433 - mae: 1.4840 - val_loss: 3.7459 - val_mae: 1.5198\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3228 - mae: 1.4363 - val_loss: 3.7192 - val_mae: 1.5209\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1872 - mae: 1.6467 \n",
            "Test MAE (Mean Absolute Error): 1.67\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "   Predicted     Actual\n",
            "0   6.955289   7.494001\n",
            "1  11.439109  12.394215\n",
            "2  10.022429   9.997158\n",
            "3   7.569746   8.965073\n",
            "4   8.192990  11.882369\n",
            "5  11.564124   8.595982\n",
            "6  11.246497  13.475625\n",
            "7   8.378902  11.871617\n",
            "8   6.508723   4.827736\n",
            "9   8.490857   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Predicted total rebounds for the player's next game: 10.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#tyler herro"
      ],
      "metadata": {
        "id": "IV_yT1_Y0ERh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rdg1uDg70F2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [6.2], # Changed to list\n",
        "    'avg_min_last5': [37.8], # Changed to list\n",
        "    'opp_avg_reb_allowed': [42.1], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [3], # Changed to list\n",
        "    'home_indicator': [0], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea875bbc-bd13-4fb0-cf76-c13c1c15390e",
        "id": "ifVORVv80GGx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 78.8275 - mae: 8.4223 - val_loss: 72.3506 - val_mae: 8.1202\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 58.7520 - mae: 7.1380 - val_loss: 46.2777 - val_mae: 6.3285\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 32.9586 - mae: 5.1077 - val_loss: 20.4086 - val_mae: 3.9861\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.2006 - mae: 3.0338 - val_loss: 7.1464 - val_mae: 2.2700\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.0603 - mae: 2.0007 - val_loss: 4.7410 - val_mae: 1.7172\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7239 - mae: 1.8997 - val_loss: 4.5799 - val_mae: 1.6757\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9329 - mae: 1.7672 - val_loss: 4.5701 - val_mae: 1.6695\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5663 - mae: 1.7094 - val_loss: 4.4448 - val_mae: 1.6235\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7538 - mae: 1.7437 - val_loss: 4.4351 - val_mae: 1.6256\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3752 - mae: 1.6667 - val_loss: 4.3964 - val_mae: 1.6235\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3766 - mae: 1.6530 - val_loss: 4.3387 - val_mae: 1.6056\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6152 - mae: 1.6863 - val_loss: 4.3144 - val_mae: 1.6045\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7391 - mae: 1.7084 - val_loss: 4.3167 - val_mae: 1.6142\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6758 - mae: 1.6955 - val_loss: 4.2337 - val_mae: 1.5847\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4010 - mae: 1.6842 - val_loss: 4.2816 - val_mae: 1.6136\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4193 - mae: 1.6643 - val_loss: 4.1763 - val_mae: 1.5686\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4769 - mae: 1.6881 - val_loss: 4.1947 - val_mae: 1.5872\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1964 - mae: 1.5951 - val_loss: 4.1210 - val_mae: 1.5594\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5567 - mae: 1.6949 - val_loss: 4.1491 - val_mae: 1.5743\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3263 - mae: 1.6547 - val_loss: 4.0979 - val_mae: 1.5635\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4006 - mae: 1.6297 - val_loss: 4.0813 - val_mae: 1.5575\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3607 - mae: 1.6372 - val_loss: 4.0802 - val_mae: 1.5644\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0513 - mae: 1.6176 - val_loss: 4.0545 - val_mae: 1.5556\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6176 - mae: 1.7039 - val_loss: 4.0118 - val_mae: 1.5382\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1982 - mae: 1.6201 - val_loss: 4.0750 - val_mae: 1.5629\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3630 - mae: 1.6470 - val_loss: 3.9615 - val_mae: 1.5382\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2805 - mae: 1.6371 - val_loss: 4.0202 - val_mae: 1.5507\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0785 - mae: 1.5659 - val_loss: 4.0154 - val_mae: 1.5486\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5651 - mae: 1.7062 - val_loss: 3.9842 - val_mae: 1.5415\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0943 - mae: 1.5996 - val_loss: 3.9853 - val_mae: 1.5507\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8807 - mae: 1.5766 - val_loss: 3.9535 - val_mae: 1.5262\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3782 - mae: 1.6605 - val_loss: 3.9153 - val_mae: 1.5253\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0518 - mae: 1.6193 - val_loss: 3.9468 - val_mae: 1.5393\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7014 - mae: 1.5176 - val_loss: 3.9378 - val_mae: 1.5405\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5633 - mae: 1.6964 - val_loss: 3.9877 - val_mae: 1.5540\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0511 - mae: 1.5688 - val_loss: 3.9057 - val_mae: 1.5319\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2448 - mae: 1.6242 - val_loss: 3.8905 - val_mae: 1.5225\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7138 - mae: 1.7056 - val_loss: 3.8860 - val_mae: 1.5120\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0813 - mae: 1.6078 - val_loss: 3.8908 - val_mae: 1.5286\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1983 - mae: 1.6260 - val_loss: 3.7877 - val_mae: 1.4847\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4347 - mae: 1.6490 - val_loss: 3.8941 - val_mae: 1.5328\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0955 - mae: 1.6136 - val_loss: 3.8633 - val_mae: 1.5201\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9785 - mae: 1.5633 - val_loss: 3.9488 - val_mae: 1.5552\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0433 - mae: 1.6001 - val_loss: 3.8819 - val_mae: 1.5310\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4390 - mae: 1.6867 - val_loss: 3.8440 - val_mae: 1.5096\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7613 - mae: 1.5451 - val_loss: 3.8637 - val_mae: 1.5230\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4105 - mae: 1.6908 - val_loss: 3.8890 - val_mae: 1.5384\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1383 - mae: 1.6114 - val_loss: 3.8105 - val_mae: 1.5019\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6990 - mae: 1.5191 - val_loss: 3.8443 - val_mae: 1.5292\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0691 - mae: 1.5601 - val_loss: 3.8841 - val_mae: 1.5417\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9388 - mae: 1.5880 - val_loss: 3.8512 - val_mae: 1.5194\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7990 - mae: 1.5484 - val_loss: 3.8639 - val_mae: 1.5280\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2086 - mae: 1.6209 - val_loss: 3.8466 - val_mae: 1.5334\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8757 - mae: 1.5600 - val_loss: 3.8455 - val_mae: 1.5261\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2144 - mae: 1.6352 - val_loss: 3.7983 - val_mae: 1.5107\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0708 - mae: 1.5707 - val_loss: 3.8570 - val_mae: 1.5305\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9815 - mae: 1.5877 - val_loss: 3.8094 - val_mae: 1.5175\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7791 - mae: 1.5566 - val_loss: 3.7820 - val_mae: 1.4998\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9753 - mae: 1.5776 - val_loss: 3.8559 - val_mae: 1.5441\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0314 - mae: 1.6267 - val_loss: 3.8504 - val_mae: 1.5381\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8573 - mae: 1.5802 - val_loss: 3.8226 - val_mae: 1.5274\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7445 - mae: 1.5326 - val_loss: 3.7520 - val_mae: 1.4918\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9831 - mae: 1.5861 - val_loss: 3.8187 - val_mae: 1.5317\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6637 - mae: 1.5083 - val_loss: 3.8097 - val_mae: 1.5207\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7708 - mae: 1.5293 - val_loss: 3.7561 - val_mae: 1.4912\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7605 - mae: 1.5466 - val_loss: 3.7309 - val_mae: 1.4917\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7635 - mae: 1.5336 - val_loss: 3.8218 - val_mae: 1.5244\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2286 - mae: 1.6223 - val_loss: 3.7569 - val_mae: 1.4915\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3228 - mae: 1.4485 - val_loss: 3.8062 - val_mae: 1.5244\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9341 - mae: 1.5622 - val_loss: 3.8783 - val_mae: 1.5482\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7953 - mae: 1.5597 - val_loss: 3.7769 - val_mae: 1.5178\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5502 - mae: 1.5101 - val_loss: 3.7978 - val_mae: 1.5220\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8868 - mae: 1.5408 - val_loss: 3.7272 - val_mae: 1.4930\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5704 - mae: 1.4891 - val_loss: 4.0691 - val_mae: 1.5974\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7850 - mae: 1.5530 - val_loss: 3.7585 - val_mae: 1.4930\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6968 - mae: 1.5090 - val_loss: 3.7702 - val_mae: 1.5204\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7740 - mae: 1.5470 - val_loss: 3.8232 - val_mae: 1.5351\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8819 - mae: 1.5743 - val_loss: 3.7738 - val_mae: 1.5134\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7668 - mae: 1.5208 - val_loss: 3.8199 - val_mae: 1.5322\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7759 - mae: 1.5200 - val_loss: 3.7807 - val_mae: 1.5170\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7201 - mae: 1.5238 - val_loss: 3.7944 - val_mae: 1.5237\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9380 - mae: 1.5676 - val_loss: 3.7144 - val_mae: 1.4838\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9414 - mae: 1.5491 - val_loss: 3.8356 - val_mae: 1.5385\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6892 - mae: 1.5401 - val_loss: 3.7603 - val_mae: 1.5041\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5478 - mae: 1.5118 - val_loss: 3.8231 - val_mae: 1.5244\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8712 - mae: 1.5649 - val_loss: 3.7832 - val_mae: 1.5227\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6580 - mae: 1.5247 - val_loss: 3.7167 - val_mae: 1.5016\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9816 - mae: 1.5939 - val_loss: 3.8386 - val_mae: 1.5346\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6060 - mae: 1.5181 - val_loss: 3.8044 - val_mae: 1.5367\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3812 - mae: 1.4699 - val_loss: 3.8329 - val_mae: 1.5279\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5253 - mae: 1.5050 - val_loss: 3.8076 - val_mae: 1.5249\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6304 - mae: 1.5144 - val_loss: 3.8455 - val_mae: 1.5349\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5848 - mae: 1.4999 - val_loss: 3.8318 - val_mae: 1.5366\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6460 - mae: 1.5036 - val_loss: 3.8478 - val_mae: 1.5588\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5282 - mae: 1.4801 - val_loss: 3.7766 - val_mae: 1.5101\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6565 - mae: 1.5027 - val_loss: 3.8520 - val_mae: 1.5376\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9132 - mae: 1.5493 - val_loss: 3.8692 - val_mae: 1.5440\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7234 - mae: 1.5302 - val_loss: 3.8263 - val_mae: 1.5334\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9012 - mae: 1.5358 - val_loss: 3.8683 - val_mae: 1.5403\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5580 - mae: 1.4920 - val_loss: 3.7351 - val_mae: 1.4966\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1622 - mae: 1.6265 \n",
            "Test MAE (Mean Absolute Error): 1.64\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "   Predicted     Actual\n",
            "0   7.207198   7.494001\n",
            "1  11.727319  12.394215\n",
            "2  10.910647   9.997158\n",
            "3   8.115129   8.965073\n",
            "4   8.023174  11.882369\n",
            "5  11.355372   8.595982\n",
            "6  11.107497  13.475625\n",
            "7   8.200107  11.871617\n",
            "8   6.618684   4.827736\n",
            "9   8.563105   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Predicted total rebounds for the player's next game: 8.90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#jarret Aallen"
      ],
      "metadata": {
        "id": "JdOvPU280tOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2HIxDeQf0v6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [10], # Changed to list\n",
        "    'avg_min_last5': [27.7], # Changed to list\n",
        "    'opp_avg_reb_allowed': [43.7], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [11], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8af222cb-0429-445e-91a2-e6f63dce5136",
        "id": "6O7nSfHV0wLP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 90.1516 - mae: 9.0376 - val_loss: 81.5998 - val_mae: 8.6763\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 70.2423 - mae: 7.9315 - val_loss: 59.5647 - val_mae: 7.3325\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 48.2121 - mae: 6.4168 - val_loss: 33.4207 - val_mae: 5.3115\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24.7314 - mae: 4.3229 - val_loss: 13.2118 - val_mae: 3.1585\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.0504 - mae: 2.3947 - val_loss: 5.9339 - val_mae: 1.9028\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.5669 - mae: 1.9899 - val_loss: 4.6996 - val_mae: 1.6520\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.4196 - mae: 1.8241 - val_loss: 4.5713 - val_mae: 1.6334\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2375 - mae: 1.8233 - val_loss: 4.5063 - val_mae: 1.6337\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7582 - mae: 1.7420 - val_loss: 4.3383 - val_mae: 1.5798\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9830 - mae: 1.7869 - val_loss: 4.3662 - val_mae: 1.6010\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1110 - mae: 1.8102 - val_loss: 4.2782 - val_mae: 1.5840\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6301 - mae: 1.7145 - val_loss: 4.2428 - val_mae: 1.5777\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0080 - mae: 1.7700 - val_loss: 4.2304 - val_mae: 1.5793\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.9378 - mae: 1.7961 - val_loss: 4.2193 - val_mae: 1.5801\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5870 - mae: 1.7005 - val_loss: 4.1971 - val_mae: 1.5780\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4859 - mae: 1.6849 - val_loss: 4.1464 - val_mae: 1.5681\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.6437 - mae: 1.7063 - val_loss: 4.1322 - val_mae: 1.5717\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6261 - mae: 1.7248 - val_loss: 4.1142 - val_mae: 1.5654\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7444 - mae: 1.7400 - val_loss: 4.0865 - val_mae: 1.5630\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6399 - mae: 1.6949 - val_loss: 4.1121 - val_mae: 1.5675\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3935 - mae: 1.6642 - val_loss: 4.0893 - val_mae: 1.5700\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3782 - mae: 1.6523 - val_loss: 4.0271 - val_mae: 1.5525\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5092 - mae: 1.6886 - val_loss: 4.0487 - val_mae: 1.5611\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1891 - mae: 1.6134 - val_loss: 4.0130 - val_mae: 1.5435\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3505 - mae: 1.6577 - val_loss: 4.0459 - val_mae: 1.5633\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7131 - mae: 1.7520 - val_loss: 3.9669 - val_mae: 1.5318\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2898 - mae: 1.6041 - val_loss: 3.9471 - val_mae: 1.5306\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0101 - mae: 1.5914 - val_loss: 3.9845 - val_mae: 1.5445\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6132 - mae: 1.7325 - val_loss: 3.9205 - val_mae: 1.5218\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4494 - mae: 1.6679 - val_loss: 3.9673 - val_mae: 1.5360\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1034 - mae: 1.5758 - val_loss: 3.9724 - val_mae: 1.5477\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2116 - mae: 1.6400 - val_loss: 3.9187 - val_mae: 1.5308\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1683 - mae: 1.6247 - val_loss: 3.9012 - val_mae: 1.5185\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9539 - mae: 1.5841 - val_loss: 3.9840 - val_mae: 1.5533\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1638 - mae: 1.6277 - val_loss: 3.8927 - val_mae: 1.5239\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1223 - mae: 1.6105 - val_loss: 3.9210 - val_mae: 1.5278\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8576 - mae: 1.5773 - val_loss: 3.8740 - val_mae: 1.5225\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0223 - mae: 1.5915 - val_loss: 3.8927 - val_mae: 1.5333\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0216 - mae: 1.5717 - val_loss: 3.8951 - val_mae: 1.5256\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0097 - mae: 1.5910 - val_loss: 3.8783 - val_mae: 1.5189\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9515 - mae: 1.5964 - val_loss: 3.9066 - val_mae: 1.5374\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8705 - mae: 1.5719 - val_loss: 3.8529 - val_mae: 1.5133\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9650 - mae: 1.5940 - val_loss: 3.9328 - val_mae: 1.5421\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3012 - mae: 1.6426 - val_loss: 3.8366 - val_mae: 1.5056\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0834 - mae: 1.6049 - val_loss: 3.9043 - val_mae: 1.5360\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0873 - mae: 1.6021 - val_loss: 3.8347 - val_mae: 1.5011\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8743 - mae: 1.5638 - val_loss: 3.8014 - val_mae: 1.5047\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1817 - mae: 1.6200 - val_loss: 3.7859 - val_mae: 1.4952\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9780 - mae: 1.5848 - val_loss: 3.8522 - val_mae: 1.5245\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1488 - mae: 1.6490 - val_loss: 3.8523 - val_mae: 1.5197\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1433 - mae: 1.6378 - val_loss: 3.7664 - val_mae: 1.4822\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3185 - mae: 1.6681 - val_loss: 3.8192 - val_mae: 1.4967\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7559 - mae: 1.5151 - val_loss: 3.8453 - val_mae: 1.5204\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8864 - mae: 1.5663 - val_loss: 3.8186 - val_mae: 1.5065\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7282 - mae: 1.5462 - val_loss: 3.8345 - val_mae: 1.5144\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2046 - mae: 1.6533 - val_loss: 3.8282 - val_mae: 1.5078\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5516 - mae: 1.5084 - val_loss: 3.9416 - val_mae: 1.5579\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0265 - mae: 1.6253 - val_loss: 3.7524 - val_mae: 1.4800\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9189 - mae: 1.5751 - val_loss: 3.8664 - val_mae: 1.5265\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8372 - mae: 1.5429 - val_loss: 3.8685 - val_mae: 1.5318\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8647 - mae: 1.5691 - val_loss: 3.7715 - val_mae: 1.4998\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1102 - mae: 1.6147 - val_loss: 3.8103 - val_mae: 1.5055\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9690 - mae: 1.5929 - val_loss: 3.7819 - val_mae: 1.4816\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7190 - mae: 1.5229 - val_loss: 3.8090 - val_mae: 1.5109\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7200 - mae: 1.5553 - val_loss: 3.8994 - val_mae: 1.5515\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7812 - mae: 1.5512 - val_loss: 3.7142 - val_mae: 1.4680\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8136 - mae: 1.5357 - val_loss: 3.8246 - val_mae: 1.5153\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7609 - mae: 1.5540 - val_loss: 3.7714 - val_mae: 1.5039\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7357 - mae: 1.5366 - val_loss: 3.8106 - val_mae: 1.5039\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7060 - mae: 1.5360 - val_loss: 3.7615 - val_mae: 1.5030\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8581 - mae: 1.5589 - val_loss: 3.8953 - val_mae: 1.5371\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9090 - mae: 1.5770 - val_loss: 3.7655 - val_mae: 1.5005\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7534 - mae: 1.5375 - val_loss: 3.7737 - val_mae: 1.4985\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9145 - mae: 1.6053 - val_loss: 3.8516 - val_mae: 1.5302\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0580 - mae: 1.6178 - val_loss: 3.7870 - val_mae: 1.4944\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8162 - mae: 1.5604 - val_loss: 3.7932 - val_mae: 1.5124\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9154 - mae: 1.5704 - val_loss: 3.7852 - val_mae: 1.5001\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7287 - mae: 1.5497 - val_loss: 3.7854 - val_mae: 1.4990\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3871 - mae: 1.4532 - val_loss: 3.8133 - val_mae: 1.5170\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8402 - mae: 1.5710 - val_loss: 3.8289 - val_mae: 1.5276\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7648 - mae: 1.5351 - val_loss: 3.7462 - val_mae: 1.4970\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6697 - mae: 1.5399 - val_loss: 3.8791 - val_mae: 1.5511\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7621 - mae: 1.5517 - val_loss: 3.7744 - val_mae: 1.5006\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8129 - mae: 1.5537 - val_loss: 3.8482 - val_mae: 1.5320\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8013 - mae: 1.5551 - val_loss: 3.8050 - val_mae: 1.5198\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5992 - mae: 1.4983 - val_loss: 3.9262 - val_mae: 1.5485\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6351 - mae: 1.5321 - val_loss: 3.8288 - val_mae: 1.5232\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9192 - mae: 1.5671 - val_loss: 3.8528 - val_mae: 1.5311\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7462 - mae: 1.5296 - val_loss: 3.7153 - val_mae: 1.4959\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0663 - mae: 1.6015 - val_loss: 3.7699 - val_mae: 1.5063\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6571 - mae: 1.5031 - val_loss: 3.7891 - val_mae: 1.5259\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7826 - mae: 1.5381 - val_loss: 3.7461 - val_mae: 1.4995\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7379 - mae: 1.5477 - val_loss: 3.8856 - val_mae: 1.5362\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5175 - mae: 1.5253 - val_loss: 3.7028 - val_mae: 1.4961\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9994 - mae: 1.5808 - val_loss: 3.8087 - val_mae: 1.5238\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6124 - mae: 1.5222 - val_loss: 3.8736 - val_mae: 1.5326\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4649 - mae: 1.4683 - val_loss: 3.7605 - val_mae: 1.5088\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8192 - mae: 1.5469 - val_loss: 3.7854 - val_mae: 1.5170\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6944 - mae: 1.5337 - val_loss: 3.8038 - val_mae: 1.5199\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5834 - mae: 1.5029 - val_loss: 3.8429 - val_mae: 1.5306\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2768 - mae: 1.6283 \n",
            "Test MAE (Mean Absolute Error): 1.67\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "   Predicted     Actual\n",
            "0   7.713855   7.494001\n",
            "1  11.596498  12.394215\n",
            "2  10.262594   9.997158\n",
            "3   7.203232   8.965073\n",
            "4   7.924744  11.882369\n",
            "5  10.845554   8.595982\n",
            "6  11.258327  13.475625\n",
            "7   8.036434  11.871617\n",
            "8   6.308374   4.827736\n",
            "9   8.400811   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Predicted total rebounds for the player's next game: 9.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#evan mobley"
      ],
      "metadata": {
        "id": "Oj1wVmNo1UiT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q-zlBXQv1WdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [10.6], # Changed to list\n",
        "    'avg_min_last5': [32.4], # Changed to list\n",
        "    'opp_avg_reb_allowed': [43.7], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [11], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb0fe2f6-789b-41a2-8798-c8d149e58dc3",
        "id": "gtotXMHp1Wtu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 82.8396 - mae: 8.5973 - val_loss: 72.5132 - val_mae: 8.0628\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 52.9847 - mae: 6.6469 - val_loss: 43.5811 - val_mae: 5.9877\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.4217 - mae: 4.6510 - val_loss: 18.2397 - val_mae: 3.6090\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.2704 - mae: 2.8179 - val_loss: 7.5162 - val_mae: 2.2154\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7577 - mae: 2.0793 - val_loss: 5.1343 - val_mae: 1.7733\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3174 - mae: 1.8374 - val_loss: 4.5908 - val_mae: 1.6681\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4490 - mae: 1.8460 - val_loss: 4.4446 - val_mae: 1.6273\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0341 - mae: 1.7899 - val_loss: 4.4459 - val_mae: 1.6303\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1003 - mae: 1.7756 - val_loss: 4.4019 - val_mae: 1.6218\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0834 - mae: 1.7751 - val_loss: 4.3013 - val_mae: 1.5947\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6682 - mae: 1.7071 - val_loss: 4.3133 - val_mae: 1.6145\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7669 - mae: 1.7076 - val_loss: 4.2644 - val_mae: 1.5974\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5430 - mae: 1.6897 - val_loss: 4.2296 - val_mae: 1.5960\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7766 - mae: 1.7596 - val_loss: 4.1898 - val_mae: 1.5791\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3544 - mae: 1.6488 - val_loss: 4.1115 - val_mae: 1.5532\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4654 - mae: 1.6855 - val_loss: 4.1268 - val_mae: 1.5642\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6425 - mae: 1.7316 - val_loss: 4.1008 - val_mae: 1.5636\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3989 - mae: 1.6642 - val_loss: 4.0344 - val_mae: 1.5432\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4392 - mae: 1.6721 - val_loss: 4.0745 - val_mae: 1.5590\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4274 - mae: 1.6910 - val_loss: 4.0156 - val_mae: 1.5425\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3954 - mae: 1.6730 - val_loss: 4.0832 - val_mae: 1.5835\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3983 - mae: 1.6650 - val_loss: 3.9754 - val_mae: 1.5411\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4853 - mae: 1.6582 - val_loss: 3.9126 - val_mae: 1.5177\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2251 - mae: 1.6369 - val_loss: 3.9807 - val_mae: 1.5462\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3196 - mae: 1.6624 - val_loss: 3.8514 - val_mae: 1.5053\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9607 - mae: 1.5708 - val_loss: 3.9141 - val_mae: 1.5358\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5345 - mae: 1.7014 - val_loss: 3.9109 - val_mae: 1.5320\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7197 - mae: 1.7076 - val_loss: 3.9159 - val_mae: 1.5366\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8479 - mae: 1.5699 - val_loss: 3.7920 - val_mae: 1.4964\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2922 - mae: 1.6218 - val_loss: 3.8633 - val_mae: 1.5214\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2464 - mae: 1.6484 - val_loss: 3.8453 - val_mae: 1.5156\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8562 - mae: 1.5765 - val_loss: 3.8161 - val_mae: 1.5122\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4088 - mae: 1.6758 - val_loss: 3.7720 - val_mae: 1.4950\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8246 - mae: 1.5524 - val_loss: 3.7631 - val_mae: 1.4939\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6255 - mae: 1.7308 - val_loss: 3.7505 - val_mae: 1.4877\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0369 - mae: 1.5756 - val_loss: 3.7766 - val_mae: 1.4962\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9940 - mae: 1.5734 - val_loss: 3.8769 - val_mae: 1.5405\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9191 - mae: 1.5915 - val_loss: 3.7637 - val_mae: 1.5002\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7546 - mae: 1.5254 - val_loss: 3.7914 - val_mae: 1.5178\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1839 - mae: 1.6173 - val_loss: 3.7497 - val_mae: 1.4816\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6489 - mae: 1.5165 - val_loss: 3.8008 - val_mae: 1.5168\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1412 - mae: 1.6126 - val_loss: 3.8815 - val_mae: 1.5458\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7711 - mae: 1.5502 - val_loss: 3.7487 - val_mae: 1.4943\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8702 - mae: 1.5830 - val_loss: 3.7942 - val_mae: 1.5298\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0917 - mae: 1.6106 - val_loss: 3.7247 - val_mae: 1.4941\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0246 - mae: 1.5940 - val_loss: 3.8364 - val_mae: 1.5358\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6416 - mae: 1.5174 - val_loss: 3.7502 - val_mae: 1.5085\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7397 - mae: 1.5420 - val_loss: 3.7747 - val_mae: 1.5190\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9348 - mae: 1.5532 - val_loss: 3.7462 - val_mae: 1.5138\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6685 - mae: 1.5333 - val_loss: 3.7596 - val_mae: 1.5192\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1657 - mae: 1.6107 - val_loss: 3.6419 - val_mae: 1.4612\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0271 - mae: 1.5693 - val_loss: 3.7042 - val_mae: 1.4899\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1181 - mae: 1.6001 - val_loss: 3.7212 - val_mae: 1.4923\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2406 - mae: 1.6483 - val_loss: 3.8169 - val_mae: 1.5289\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8375 - mae: 1.5779 - val_loss: 3.7355 - val_mae: 1.5123\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1130 - mae: 1.6277 - val_loss: 3.6569 - val_mae: 1.4739\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8839 - mae: 1.5719 - val_loss: 3.6879 - val_mae: 1.4903\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8557 - mae: 1.5413 - val_loss: 3.7069 - val_mae: 1.4976\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7919 - mae: 1.5330 - val_loss: 3.6536 - val_mae: 1.4780\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1092 - mae: 1.6142 - val_loss: 3.6953 - val_mae: 1.4990\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0856 - mae: 1.6044 - val_loss: 3.7189 - val_mae: 1.5097\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8208 - mae: 1.5650 - val_loss: 3.6077 - val_mae: 1.4570\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8100 - mae: 1.5616 - val_loss: 3.7394 - val_mae: 1.5155\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8808 - mae: 1.5724 - val_loss: 3.6566 - val_mae: 1.4805\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8557 - mae: 1.5374 - val_loss: 3.6211 - val_mae: 1.4663\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0477 - mae: 1.6034 - val_loss: 3.7973 - val_mae: 1.5412\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5208 - mae: 1.4822 - val_loss: 3.6260 - val_mae: 1.4774\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2088 - mae: 1.6209 - val_loss: 3.6554 - val_mae: 1.4885\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5676 - mae: 1.5084 - val_loss: 3.7320 - val_mae: 1.5205\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8215 - mae: 1.5555 - val_loss: 3.6206 - val_mae: 1.4674\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9676 - mae: 1.5639 - val_loss: 3.6291 - val_mae: 1.4830\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5166 - mae: 1.4692 - val_loss: 3.7916 - val_mae: 1.5326\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4206 - mae: 1.4627 - val_loss: 3.6601 - val_mae: 1.4907\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5747 - mae: 1.5145 - val_loss: 3.5493 - val_mae: 1.4558\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7703 - mae: 1.5755 - val_loss: 3.7306 - val_mae: 1.5170\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5562 - mae: 1.4871 - val_loss: 3.7136 - val_mae: 1.5156\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6761 - mae: 1.4837 - val_loss: 3.8000 - val_mae: 1.5442\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2763 - mae: 1.6417 - val_loss: 3.5840 - val_mae: 1.4609\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7558 - mae: 1.5348 - val_loss: 3.7666 - val_mae: 1.5343\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8136 - mae: 1.5418 - val_loss: 3.6538 - val_mae: 1.4835\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6626 - mae: 1.5235 - val_loss: 3.7998 - val_mae: 1.5407\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6149 - mae: 1.5189 - val_loss: 3.5774 - val_mae: 1.4561\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7156 - mae: 1.5240 - val_loss: 3.7829 - val_mae: 1.5296\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6516 - mae: 1.5111 - val_loss: 3.8478 - val_mae: 1.5583\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4831 - mae: 1.5027 - val_loss: 3.6486 - val_mae: 1.4956\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6846 - mae: 1.5184 - val_loss: 3.7288 - val_mae: 1.5162\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6783 - mae: 1.5218 - val_loss: 3.7293 - val_mae: 1.5262\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8086 - mae: 1.5211 - val_loss: 3.6290 - val_mae: 1.4815\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5755 - mae: 1.4664 - val_loss: 3.8348 - val_mae: 1.5505\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6444 - mae: 1.5237 - val_loss: 3.6126 - val_mae: 1.4813\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5746 - mae: 1.4868 - val_loss: 3.7813 - val_mae: 1.5313\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6530 - mae: 1.5043 - val_loss: 3.6507 - val_mae: 1.4906\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6190 - mae: 1.5037 - val_loss: 3.6423 - val_mae: 1.4928\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6540 - mae: 1.5288 - val_loss: 3.8874 - val_mae: 1.5650\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9559 - mae: 1.6016 - val_loss: 3.7381 - val_mae: 1.5269\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4798 - mae: 1.4653 - val_loss: 3.6600 - val_mae: 1.4873\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8935 - mae: 1.5646 - val_loss: 3.8154 - val_mae: 1.5463\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6970 - mae: 1.5022 - val_loss: 3.8143 - val_mae: 1.5358\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8455 - mae: 1.5459 - val_loss: 3.6510 - val_mae: 1.4847\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8188 - mae: 1.5298 - val_loss: 3.6899 - val_mae: 1.5097\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3228 - mae: 1.6688 \n",
            "Test MAE (Mean Absolute Error): 1.68\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
            "   Predicted     Actual\n",
            "0   7.100448   7.494001\n",
            "1  11.401175  12.394215\n",
            "2  10.559808   9.997158\n",
            "3   7.684409   8.965073\n",
            "4   8.149851  11.882369\n",
            "5  11.810498   8.595982\n",
            "6  10.962048  13.475625\n",
            "7   8.283463  11.871617\n",
            "8   6.802367   4.827736\n",
            "9   8.091693   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Predicted total rebounds for the player's next game: 10.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#jaylen william"
      ],
      "metadata": {
        "id": "nwxuJYz82mCs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KEdYXzYB2oKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [6.2], # Changed to list\n",
        "    'avg_min_last5': [30.4], # Changed to list\n",
        "    'opp_avg_reb_allowed': [44.7], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [4.8], # Changed to list\n",
        "    'home_indicator': [0], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3be8ac17-5ba4-4375-ead5-d49aaf2538d2",
        "id": "UztEl5_i2oWD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 85.7845 - mae: 8.7898 - val_loss: 75.4311 - val_mae: 8.3025\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 63.4006 - mae: 7.4263 - val_loss: 51.5162 - val_mae: 6.7446\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 39.0017 - mae: 5.6622 - val_loss: 25.0910 - val_mae: 4.5527\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 17.2395 - mae: 3.5690 - val_loss: 8.4224 - val_mae: 2.4353\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 7.5867 - mae: 2.2213 - val_loss: 4.7967 - val_mae: 1.6806\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.1158 - mae: 1.7984 - val_loss: 4.4607 - val_mae: 1.6032\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9284 - mae: 1.7433 - val_loss: 4.4298 - val_mae: 1.6049\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9950 - mae: 1.7947 - val_loss: 4.3517 - val_mae: 1.5824\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.5843 - mae: 1.6966 - val_loss: 4.2877 - val_mae: 1.5720\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7348 - mae: 1.7268 - val_loss: 4.3310 - val_mae: 1.5918\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.5856 - mae: 1.7179 - val_loss: 4.2936 - val_mae: 1.5908\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8982 - mae: 1.7485 - val_loss: 4.2535 - val_mae: 1.5811\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7834 - mae: 1.7205 - val_loss: 4.1742 - val_mae: 1.5525\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6048 - mae: 1.6936 - val_loss: 4.2168 - val_mae: 1.5745\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6489 - mae: 1.7431 - val_loss: 4.2033 - val_mae: 1.5728\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5314 - mae: 1.7041 - val_loss: 4.1511 - val_mae: 1.5650\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.4964 - mae: 1.6683 - val_loss: 4.1563 - val_mae: 1.5664\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.6322 - mae: 1.7165 - val_loss: 4.1585 - val_mae: 1.5702\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.4716 - mae: 1.6577 - val_loss: 4.1024 - val_mae: 1.5517\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7221 - mae: 1.7418 - val_loss: 4.0851 - val_mae: 1.5576\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3695 - mae: 1.6514 - val_loss: 4.0975 - val_mae: 1.5552\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5540 - mae: 1.7132 - val_loss: 4.0554 - val_mae: 1.5445\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0893 - mae: 1.6041 - val_loss: 4.0258 - val_mae: 1.5445\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7654 - mae: 1.7371 - val_loss: 4.0851 - val_mae: 1.5697\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0228 - mae: 1.5690 - val_loss: 3.9973 - val_mae: 1.5278\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4012 - mae: 1.6634 - val_loss: 4.0782 - val_mae: 1.5688\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2897 - mae: 1.6334 - val_loss: 4.0191 - val_mae: 1.5451\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0885 - mae: 1.6172 - val_loss: 3.9847 - val_mae: 1.5409\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9772 - mae: 1.5812 - val_loss: 3.9912 - val_mae: 1.5414\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0357 - mae: 1.5926 - val_loss: 3.9537 - val_mae: 1.5300\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2334 - mae: 1.6308 - val_loss: 3.9478 - val_mae: 1.5325\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2109 - mae: 1.6327 - val_loss: 3.9174 - val_mae: 1.5149\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2592 - mae: 1.6211 - val_loss: 3.9310 - val_mae: 1.5319\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1510 - mae: 1.6266 - val_loss: 3.9262 - val_mae: 1.5292\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3006 - mae: 1.6407 - val_loss: 3.9126 - val_mae: 1.5221\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2485 - mae: 1.6490 - val_loss: 3.9455 - val_mae: 1.5316\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0379 - mae: 1.5856 - val_loss: 3.8831 - val_mae: 1.5150\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2380 - mae: 1.6216 - val_loss: 3.8535 - val_mae: 1.5020\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3299 - mae: 1.6735 - val_loss: 3.9608 - val_mae: 1.5503\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2937 - mae: 1.6426 - val_loss: 3.8419 - val_mae: 1.4979\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2738 - mae: 1.6469 - val_loss: 3.8943 - val_mae: 1.5165\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0236 - mae: 1.6086 - val_loss: 3.8304 - val_mae: 1.5002\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0760 - mae: 1.5895 - val_loss: 3.9709 - val_mae: 1.5427\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1717 - mae: 1.6453 - val_loss: 3.8570 - val_mae: 1.5148\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9928 - mae: 1.5797 - val_loss: 3.8762 - val_mae: 1.5192\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1298 - mae: 1.6254 - val_loss: 3.9031 - val_mae: 1.5266\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0942 - mae: 1.6032 - val_loss: 3.7862 - val_mae: 1.4842\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1045 - mae: 1.5959 - val_loss: 3.8859 - val_mae: 1.5239\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2035 - mae: 1.6239 - val_loss: 3.8478 - val_mae: 1.5151\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0163 - mae: 1.5727 - val_loss: 3.8308 - val_mae: 1.4977\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5373 - mae: 1.5004 - val_loss: 3.8463 - val_mae: 1.5012\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6881 - mae: 1.5092 - val_loss: 3.8312 - val_mae: 1.5061\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1163 - mae: 1.6217 - val_loss: 3.7933 - val_mae: 1.4925\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9664 - mae: 1.5728 - val_loss: 3.8534 - val_mae: 1.5227\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9612 - mae: 1.5759 - val_loss: 3.7462 - val_mae: 1.4821\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7347 - mae: 1.5551 - val_loss: 3.9429 - val_mae: 1.5491\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2594 - mae: 1.6612 - val_loss: 3.7410 - val_mae: 1.4803\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8490 - mae: 1.5437 - val_loss: 3.8844 - val_mae: 1.5293\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9655 - mae: 1.5910 - val_loss: 3.8089 - val_mae: 1.5089\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.9799 - mae: 1.5867 - val_loss: 3.7856 - val_mae: 1.4893\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2746 - mae: 1.6433 - val_loss: 3.7897 - val_mae: 1.4945\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9835 - mae: 1.5831 - val_loss: 3.7661 - val_mae: 1.4874\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0280 - mae: 1.5608 - val_loss: 3.7976 - val_mae: 1.5128\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0415 - mae: 1.5906 - val_loss: 3.8371 - val_mae: 1.5108\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8857 - mae: 1.5654 - val_loss: 3.7756 - val_mae: 1.5024\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9602 - mae: 1.5725 - val_loss: 3.7354 - val_mae: 1.4812\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6766 - mae: 1.5038 - val_loss: 3.8808 - val_mae: 1.5259\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9400 - mae: 1.5720 - val_loss: 3.8143 - val_mae: 1.5128\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6325 - mae: 1.5106 - val_loss: 3.7407 - val_mae: 1.4823\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8424 - mae: 1.5385 - val_loss: 3.9182 - val_mae: 1.5422\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3189 - mae: 1.6408 - val_loss: 3.7257 - val_mae: 1.4807\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0395 - mae: 1.5792 - val_loss: 3.7675 - val_mae: 1.4957\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7026 - mae: 1.5008 - val_loss: 3.7609 - val_mae: 1.4910\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0303 - mae: 1.5817 - val_loss: 3.8527 - val_mae: 1.5264\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6748 - mae: 1.5282 - val_loss: 3.7371 - val_mae: 1.4892\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6078 - mae: 1.4878 - val_loss: 3.8030 - val_mae: 1.5095\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9219 - mae: 1.5558 - val_loss: 3.7021 - val_mae: 1.4780\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6203 - mae: 1.4990 - val_loss: 3.8622 - val_mae: 1.5232\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7449 - mae: 1.5392 - val_loss: 3.8421 - val_mae: 1.5273\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6301 - mae: 1.5292 - val_loss: 3.8863 - val_mae: 1.5341\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9643 - mae: 1.5901 - val_loss: 3.7817 - val_mae: 1.5045\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1386 - mae: 1.6022 - val_loss: 3.8448 - val_mae: 1.5316\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6997 - mae: 1.4975 - val_loss: 3.7876 - val_mae: 1.5032\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9795 - mae: 1.5925 - val_loss: 3.8043 - val_mae: 1.5103\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9025 - mae: 1.5612 - val_loss: 3.7848 - val_mae: 1.5035\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7812 - mae: 1.5332 - val_loss: 3.8325 - val_mae: 1.5298\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8564 - mae: 1.5525 - val_loss: 3.9282 - val_mae: 1.5509\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8769 - mae: 1.5741 - val_loss: 3.7805 - val_mae: 1.5090\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4355 - mae: 1.4795 - val_loss: 3.7473 - val_mae: 1.4967\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6709 - mae: 1.5215 - val_loss: 3.9248 - val_mae: 1.5500\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1742 - mae: 1.6017 - val_loss: 3.7345 - val_mae: 1.4920\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8370 - mae: 1.5359 - val_loss: 3.8853 - val_mae: 1.5360\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8204 - mae: 1.5526 - val_loss: 3.8328 - val_mae: 1.5285\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8676 - mae: 1.5445 - val_loss: 3.8423 - val_mae: 1.5218\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6677 - mae: 1.5280 - val_loss: 3.8024 - val_mae: 1.5171\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5921 - mae: 1.4887 - val_loss: 3.7859 - val_mae: 1.5089\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8002 - mae: 1.5384 - val_loss: 3.8974 - val_mae: 1.5437\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6453 - mae: 1.5128 - val_loss: 3.8060 - val_mae: 1.5201\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7491 - mae: 1.5457 - val_loss: 3.8819 - val_mae: 1.5375\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6100 - mae: 1.4836 - val_loss: 3.8225 - val_mae: 1.5259\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2343 - mae: 1.6241 \n",
            "Test MAE (Mean Absolute Error): 1.64\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
            "   Predicted     Actual\n",
            "0   7.469952   7.494001\n",
            "1  11.363538  12.394215\n",
            "2  10.076509   9.997158\n",
            "3   7.725091   8.965073\n",
            "4   7.886950  11.882369\n",
            "5  11.393025   8.595982\n",
            "6  11.184430  13.475625\n",
            "7   8.174087  11.871617\n",
            "8   6.399238   4.827736\n",
            "9   8.163045   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Predicted total rebounds for the player's next game: 7.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#anthony davies"
      ],
      "metadata": {
        "id": "CfRN5l2I3rCk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9doV8SQz3syP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [12], # Changed to list\n",
        "    'avg_min_last5': [36.1], # Changed to list\n",
        "    'opp_avg_reb_allowed': [42.5], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [14], # Changed to list\n",
        "    'home_indicator': [0], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62ee48c6-0590-4a4b-e7ce-0d78658e73db",
        "id": "bMhg_Wjl3tF3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 81.0146 - mae: 8.5025 - val_loss: 77.1382 - val_mae: 8.3400\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 63.3185 - mae: 7.3413 - val_loss: 52.7420 - val_mae: 6.6847\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 38.6604 - mae: 5.4741 - val_loss: 25.8888 - val_mae: 4.4442\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 17.3727 - mae: 3.4172 - val_loss: 9.6582 - val_mae: 2.5388\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.9233 - mae: 2.2835 - val_loss: 5.5699 - val_mae: 1.8647\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.6053 - mae: 1.9054 - val_loss: 4.9426 - val_mae: 1.7482\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7299 - mae: 1.7285 - val_loss: 4.7497 - val_mae: 1.6974\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7190 - mae: 1.7812 - val_loss: 4.6685 - val_mae: 1.6832\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8420 - mae: 1.7678 - val_loss: 4.5789 - val_mae: 1.6536\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7276 - mae: 1.7518 - val_loss: 4.5503 - val_mae: 1.6557\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4665 - mae: 1.6842 - val_loss: 4.4687 - val_mae: 1.6319\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.7229 - mae: 1.7365 - val_loss: 4.3559 - val_mae: 1.6085\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.4038 - mae: 1.7061 - val_loss: 4.4356 - val_mae: 1.6385\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.7922 - mae: 1.7454 - val_loss: 4.3260 - val_mae: 1.6009\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.6238 - mae: 1.7237 - val_loss: 4.2784 - val_mae: 1.5963\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.2622 - mae: 1.6528 - val_loss: 4.2834 - val_mae: 1.6054\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6134 - mae: 1.7438 - val_loss: 4.2994 - val_mae: 1.6094\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0337 - mae: 1.6020 - val_loss: 4.2123 - val_mae: 1.5895\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1809 - mae: 1.6230 - val_loss: 4.1983 - val_mae: 1.5860\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2810 - mae: 1.6381 - val_loss: 4.1447 - val_mae: 1.5730\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7721 - mae: 1.5384 - val_loss: 4.1077 - val_mae: 1.5667\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9562 - mae: 1.5696 - val_loss: 4.0746 - val_mae: 1.5567\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5119 - mae: 1.7101 - val_loss: 4.0126 - val_mae: 1.5328\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4651 - mae: 1.6760 - val_loss: 3.9753 - val_mae: 1.5356\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2183 - mae: 1.6647 - val_loss: 3.9665 - val_mae: 1.5275\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7252 - mae: 1.5434 - val_loss: 3.9336 - val_mae: 1.5225\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9559 - mae: 1.5778 - val_loss: 3.9715 - val_mae: 1.5435\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3248 - mae: 1.6644 - val_loss: 3.9453 - val_mae: 1.5316\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1801 - mae: 1.5928 - val_loss: 3.9269 - val_mae: 1.5281\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2667 - mae: 1.6544 - val_loss: 3.9024 - val_mae: 1.5065\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1436 - mae: 1.6406 - val_loss: 3.9046 - val_mae: 1.5161\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3608 - mae: 1.6786 - val_loss: 3.8414 - val_mae: 1.5016\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8480 - mae: 1.5301 - val_loss: 3.8698 - val_mae: 1.5160\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7463 - mae: 1.5436 - val_loss: 3.8154 - val_mae: 1.4963\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9851 - mae: 1.5858 - val_loss: 3.9708 - val_mae: 1.5425\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7754 - mae: 1.5449 - val_loss: 3.8309 - val_mae: 1.4940\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6185 - mae: 1.5273 - val_loss: 3.7897 - val_mae: 1.4880\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1018 - mae: 1.6245 - val_loss: 3.8190 - val_mae: 1.5010\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9917 - mae: 1.5934 - val_loss: 3.8881 - val_mae: 1.5134\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7143 - mae: 1.5393 - val_loss: 3.8249 - val_mae: 1.5033\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9431 - mae: 1.5728 - val_loss: 3.9003 - val_mae: 1.5178\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9174 - mae: 1.5787 - val_loss: 3.8067 - val_mae: 1.4962\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0119 - mae: 1.5796 - val_loss: 3.9144 - val_mae: 1.5422\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6231 - mae: 1.5265 - val_loss: 3.7957 - val_mae: 1.5001\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0360 - mae: 1.5766 - val_loss: 3.7825 - val_mae: 1.4940\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2154 - mae: 1.6348 - val_loss: 3.8721 - val_mae: 1.5093\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8495 - mae: 1.5617 - val_loss: 3.7837 - val_mae: 1.4999\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9269 - mae: 1.5707 - val_loss: 3.7474 - val_mae: 1.4933\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8560 - mae: 1.5422 - val_loss: 3.8865 - val_mae: 1.5191\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7884 - mae: 1.5278 - val_loss: 3.7824 - val_mae: 1.4991\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8406 - mae: 1.5625 - val_loss: 3.8066 - val_mae: 1.4930\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7631 - mae: 1.5437 - val_loss: 3.8213 - val_mae: 1.5054\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6536 - mae: 1.5172 - val_loss: 3.7414 - val_mae: 1.4979\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4342 - mae: 1.4690 - val_loss: 3.8494 - val_mae: 1.5170\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8776 - mae: 1.5556 - val_loss: 3.9342 - val_mae: 1.5342\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8753 - mae: 1.5623 - val_loss: 3.7801 - val_mae: 1.5041\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0175 - mae: 1.6022 - val_loss: 3.7207 - val_mae: 1.4941\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3921 - mae: 1.4564 - val_loss: 3.8577 - val_mae: 1.5199\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4773 - mae: 1.4830 - val_loss: 3.7969 - val_mae: 1.5034\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8728 - mae: 1.5435 - val_loss: 3.8102 - val_mae: 1.5126\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0755 - mae: 1.6216 - val_loss: 3.6677 - val_mae: 1.4879\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5308 - mae: 1.4905 - val_loss: 3.8095 - val_mae: 1.5118\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1035 - mae: 1.6030 - val_loss: 3.7668 - val_mae: 1.5120\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8242 - mae: 1.5401 - val_loss: 3.7913 - val_mae: 1.5074\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8243 - mae: 1.5674 - val_loss: 3.7835 - val_mae: 1.5087\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4808 - mae: 1.4894 - val_loss: 3.7972 - val_mae: 1.5134\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9652 - mae: 1.5692 - val_loss: 3.7090 - val_mae: 1.4904\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7683 - mae: 1.5133 - val_loss: 3.8575 - val_mae: 1.5271\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7693 - mae: 1.5507 - val_loss: 3.6768 - val_mae: 1.4853\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7260 - mae: 1.5062 - val_loss: 3.8286 - val_mae: 1.5242\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6930 - mae: 1.5235 - val_loss: 3.7119 - val_mae: 1.5027\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7299 - mae: 1.5295 - val_loss: 3.8400 - val_mae: 1.5250\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4500 - mae: 1.4738 - val_loss: 3.8071 - val_mae: 1.5227\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.2616 - mae: 1.4260 - val_loss: 3.7329 - val_mae: 1.5078\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3926 - mae: 1.4494 - val_loss: 3.8469 - val_mae: 1.5286\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2782 - mae: 1.4403 - val_loss: 3.8258 - val_mae: 1.5259\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2137 - mae: 1.4005 - val_loss: 3.7402 - val_mae: 1.5117\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7065 - mae: 1.5238 - val_loss: 3.8326 - val_mae: 1.5384\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6075 - mae: 1.5172 - val_loss: 3.9070 - val_mae: 1.5472\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4523 - mae: 1.4932 - val_loss: 3.8210 - val_mae: 1.5238\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6963 - mae: 1.5374 - val_loss: 3.7595 - val_mae: 1.5152\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4375 - mae: 1.4783 - val_loss: 4.0141 - val_mae: 1.5732\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5445 - mae: 1.4898 - val_loss: 3.7475 - val_mae: 1.5061\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4453 - mae: 1.4735 - val_loss: 3.7791 - val_mae: 1.5201\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5352 - mae: 1.4910 - val_loss: 3.8779 - val_mae: 1.5368\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4808 - mae: 1.4854 - val_loss: 3.8479 - val_mae: 1.5368\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3676 - mae: 1.4606 - val_loss: 3.8893 - val_mae: 1.5533\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5771 - mae: 1.5111 - val_loss: 3.8569 - val_mae: 1.5416\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4946 - mae: 1.4812 - val_loss: 3.7998 - val_mae: 1.5225\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5974 - mae: 1.5190 - val_loss: 3.8802 - val_mae: 1.5474\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5911 - mae: 1.4990 - val_loss: 3.9735 - val_mae: 1.5677\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8089 - mae: 1.5478 - val_loss: 3.8142 - val_mae: 1.5295\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3577 - mae: 1.4546 - val_loss: 3.8947 - val_mae: 1.5508\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2707 - mae: 1.4326 - val_loss: 3.9058 - val_mae: 1.5509\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2182 - mae: 1.4244 - val_loss: 3.7977 - val_mae: 1.5233\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1934 - mae: 1.4320 - val_loss: 3.8752 - val_mae: 1.5449\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1568 - mae: 1.4103 - val_loss: 4.0510 - val_mae: 1.5907\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5476 - mae: 1.4849 - val_loss: 3.8536 - val_mae: 1.5385\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3801 - mae: 1.4468 - val_loss: 3.9107 - val_mae: 1.5541\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.2668 - mae: 1.4401 - val_loss: 4.0013 - val_mae: 1.5773\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2230 - mae: 1.6373 \n",
            "Test MAE (Mean Absolute Error): 1.65\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "   Predicted     Actual\n",
            "0   7.190770   7.494001\n",
            "1  10.911482  12.394215\n",
            "2  10.481875   9.997158\n",
            "3   7.187763   8.965073\n",
            "4   8.089461  11.882369\n",
            "5  11.471708   8.595982\n",
            "6  10.861753  13.475625\n",
            "7   8.212832  11.871617\n",
            "8   6.485418   4.827736\n",
            "9   8.093980   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "Predicted total rebounds for the player's next game: 13.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#dalton kenect"
      ],
      "metadata": {
        "id": "KpNBbfy94efQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "omVjLh-x4g05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [5.4], # Changed to list\n",
        "    'avg_min_last5': [30], # Changed to list\n",
        "    'opp_avg_reb_allowed': [42.5], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [14], # Changed to list\n",
        "    'home_indicator': [0], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "186c152e-c136-4979-b889-5114e4da2cbe",
        "id": "g_2-mcJP4hCl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 73.9580 - mae: 8.0754 - val_loss: 65.9551 - val_mae: 7.5846\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 51.7959 - mae: 6.4816 - val_loss: 39.6452 - val_mae: 5.6649\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5075 - mae: 4.6090 - val_loss: 16.2749 - val_mae: 3.4882\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.3423 - mae: 2.6158 - val_loss: 6.9190 - val_mae: 2.2104\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8214 - mae: 2.1227 - val_loss: 4.9911 - val_mae: 1.8271\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.7599 - mae: 1.9040 - val_loss: 4.7781 - val_mae: 1.7771\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0894 - mae: 1.8127 - val_loss: 4.6176 - val_mae: 1.7274\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.4612 - mae: 1.8653 - val_loss: 4.5352 - val_mae: 1.6966\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2180 - mae: 1.8372 - val_loss: 4.4378 - val_mae: 1.6675\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7159 - mae: 1.7207 - val_loss: 4.3957 - val_mae: 1.6500\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4626 - mae: 1.8648 - val_loss: 4.3341 - val_mae: 1.6290\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6921 - mae: 1.7338 - val_loss: 4.2530 - val_mae: 1.6080\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7352 - mae: 1.7289 - val_loss: 4.2335 - val_mae: 1.6096\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5477 - mae: 1.6903 - val_loss: 4.1383 - val_mae: 1.5675\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6262 - mae: 1.6959 - val_loss: 4.1307 - val_mae: 1.5690\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5777 - mae: 1.7090 - val_loss: 4.0929 - val_mae: 1.5669\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1410 - mae: 1.6238 - val_loss: 4.1203 - val_mae: 1.5826\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7159 - mae: 1.7309 - val_loss: 4.1203 - val_mae: 1.5771\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2551 - mae: 1.6455 - val_loss: 4.1038 - val_mae: 1.5785\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4885 - mae: 1.6956 - val_loss: 3.9893 - val_mae: 1.5265\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6802 - mae: 1.7195 - val_loss: 4.0518 - val_mae: 1.5571\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5121 - mae: 1.6917 - val_loss: 3.9077 - val_mae: 1.4986\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2011 - mae: 1.6169 - val_loss: 3.9457 - val_mae: 1.5220\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6530 - mae: 1.7096 - val_loss: 3.9093 - val_mae: 1.5013\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7105 - mae: 1.7055 - val_loss: 3.9083 - val_mae: 1.5123\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2991 - mae: 1.6302 - val_loss: 3.9227 - val_mae: 1.5185\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1118 - mae: 1.6095 - val_loss: 3.8319 - val_mae: 1.4732\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3576 - mae: 1.6621 - val_loss: 3.8794 - val_mae: 1.5057\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0657 - mae: 1.6013 - val_loss: 3.8362 - val_mae: 1.4782\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0403 - mae: 1.6028 - val_loss: 3.8679 - val_mae: 1.5003\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2482 - mae: 1.6344 - val_loss: 3.7957 - val_mae: 1.4669\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9844 - mae: 1.5751 - val_loss: 3.8184 - val_mae: 1.4771\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8650 - mae: 1.5530 - val_loss: 3.8544 - val_mae: 1.5041\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3499 - mae: 1.6748 - val_loss: 3.7310 - val_mae: 1.4526\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0186 - mae: 1.6007 - val_loss: 3.9103 - val_mae: 1.5331\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0352 - mae: 1.6087 - val_loss: 3.7823 - val_mae: 1.4749\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0235 - mae: 1.5921 - val_loss: 3.7742 - val_mae: 1.4863\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0681 - mae: 1.5904 - val_loss: 3.7454 - val_mae: 1.4679\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0187 - mae: 1.5885 - val_loss: 3.8066 - val_mae: 1.4996\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1357 - mae: 1.5857 - val_loss: 3.7006 - val_mae: 1.4498\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9895 - mae: 1.6015 - val_loss: 3.8582 - val_mae: 1.5293\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2068 - mae: 1.6231 - val_loss: 3.6893 - val_mae: 1.4477\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0490 - mae: 1.5937 - val_loss: 3.7956 - val_mae: 1.4973\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2891 - mae: 1.6444 - val_loss: 3.7604 - val_mae: 1.4914\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6145 - mae: 1.6609 - val_loss: 3.7064 - val_mae: 1.4718\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0264 - mae: 1.5788 - val_loss: 3.6907 - val_mae: 1.4672\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6142 - mae: 1.5249 - val_loss: 3.7204 - val_mae: 1.4843\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9207 - mae: 1.5595 - val_loss: 3.6665 - val_mae: 1.4546\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7403 - mae: 1.5358 - val_loss: 3.6174 - val_mae: 1.4467\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1977 - mae: 1.6230 - val_loss: 3.7060 - val_mae: 1.4798\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3416 - mae: 1.6563 - val_loss: 3.5909 - val_mae: 1.4379\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7837 - mae: 1.5144 - val_loss: 3.6656 - val_mae: 1.4708\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9024 - mae: 1.5621 - val_loss: 3.6356 - val_mae: 1.4578\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0027 - mae: 1.5647 - val_loss: 3.5876 - val_mae: 1.4419\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9025 - mae: 1.5662 - val_loss: 3.6991 - val_mae: 1.4740\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7732 - mae: 1.5293 - val_loss: 3.8175 - val_mae: 1.5246\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9435 - mae: 1.5720 - val_loss: 3.5721 - val_mae: 1.4346\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8705 - mae: 1.5718 - val_loss: 3.5795 - val_mae: 1.4442\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9213 - mae: 1.5668 - val_loss: 3.6702 - val_mae: 1.4735\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8618 - mae: 1.5541 - val_loss: 3.7340 - val_mae: 1.5074\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8185 - mae: 1.5797 - val_loss: 3.6835 - val_mae: 1.4818\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9082 - mae: 1.5621 - val_loss: 3.6801 - val_mae: 1.4819\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8415 - mae: 1.5492 - val_loss: 3.6553 - val_mae: 1.4603\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7354 - mae: 1.5169 - val_loss: 3.5791 - val_mae: 1.4449\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6723 - mae: 1.5055 - val_loss: 3.7638 - val_mae: 1.5041\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9706 - mae: 1.5800 - val_loss: 3.5509 - val_mae: 1.4407\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8379 - mae: 1.5932 - val_loss: 3.7863 - val_mae: 1.5326\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9719 - mae: 1.5847 - val_loss: 3.6189 - val_mae: 1.4541\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1796 - mae: 1.6109 - val_loss: 3.7397 - val_mae: 1.4996\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8691 - mae: 1.5541 - val_loss: 3.7828 - val_mae: 1.5236\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0343 - mae: 1.5838 - val_loss: 3.6090 - val_mae: 1.4701\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7743 - mae: 1.5422 - val_loss: 3.8999 - val_mae: 1.5601\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0915 - mae: 1.6250 - val_loss: 3.5396 - val_mae: 1.4289\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7110 - mae: 1.5242 - val_loss: 3.6832 - val_mae: 1.4800\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7863 - mae: 1.5292 - val_loss: 3.6156 - val_mae: 1.4609\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7212 - mae: 1.5254 - val_loss: 3.8503 - val_mae: 1.5412\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7299 - mae: 1.5139 - val_loss: 3.6772 - val_mae: 1.4842\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0279 - mae: 1.5835 - val_loss: 3.5878 - val_mae: 1.4537\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6611 - mae: 1.5004 - val_loss: 3.6509 - val_mae: 1.4599\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8676 - mae: 1.5642 - val_loss: 3.6737 - val_mae: 1.4773\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5741 - mae: 1.4895 - val_loss: 3.6867 - val_mae: 1.4802\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6310 - mae: 1.5147 - val_loss: 3.7894 - val_mae: 1.5179\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9130 - mae: 1.5785 - val_loss: 3.6283 - val_mae: 1.4634\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4428 - mae: 1.4606 - val_loss: 3.7593 - val_mae: 1.5138\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5986 - mae: 1.4871 - val_loss: 3.6971 - val_mae: 1.4782\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8498 - mae: 1.5555 - val_loss: 3.7029 - val_mae: 1.4934\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3824 - mae: 1.4601 - val_loss: 3.6823 - val_mae: 1.4864\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3636 - mae: 1.4259 - val_loss: 3.7246 - val_mae: 1.4983\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7648 - mae: 1.5501 - val_loss: 3.6053 - val_mae: 1.4478\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0430 - mae: 1.5900 - val_loss: 3.6994 - val_mae: 1.4830\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8121 - mae: 1.5285 - val_loss: 3.6321 - val_mae: 1.4662\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7444 - mae: 1.5266 - val_loss: 3.7144 - val_mae: 1.4854\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8274 - mae: 1.5754 - val_loss: 3.8811 - val_mae: 1.5531\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8112 - mae: 1.5480 - val_loss: 3.6749 - val_mae: 1.4768\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6419 - mae: 1.5248 - val_loss: 3.7594 - val_mae: 1.5046\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7198 - mae: 1.5351 - val_loss: 3.6855 - val_mae: 1.4756\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6321 - mae: 1.5174 - val_loss: 3.8009 - val_mae: 1.5206\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7105 - mae: 1.5320 - val_loss: 3.8284 - val_mae: 1.5285\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6280 - mae: 1.5331 - val_loss: 3.6892 - val_mae: 1.4716\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7391 - mae: 1.5502 - val_loss: 3.7416 - val_mae: 1.5045\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2287 - mae: 1.6302 \n",
            "Test MAE (Mean Absolute Error): 1.65\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "   Predicted     Actual\n",
            "0   7.256253   7.494001\n",
            "1  11.607306  12.394215\n",
            "2  10.714168   9.997158\n",
            "3   8.189723   8.965073\n",
            "4   7.776502  11.882369\n",
            "5  11.253664   8.595982\n",
            "6  11.142107  13.475625\n",
            "7   7.985327  11.871617\n",
            "8   6.280949   4.827736\n",
            "9   8.767200   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Predicted total rebounds for the player's next game: 9.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#sabonis"
      ],
      "metadata": {
        "id": "3gxuS6-r4_my"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X7b1wBdl5BXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [13.8], # Changed to list\n",
        "    'avg_min_last5': [37], # Changed to list\n",
        "    'opp_avg_reb_allowed': [43.7], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [12], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f47d988-9aa2-4d21-cad2-9a259479b0fc",
        "id": "-PQPuNIZ5BjZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 82.8241 - mae: 8.6152 - val_loss: 80.9222 - val_mae: 8.5943\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 66.9752 - mae: 7.6212 - val_loss: 61.0933 - val_mae: 7.3627\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 45.6678 - mae: 6.1573 - val_loss: 35.7816 - val_mae: 5.4912\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 26.2721 - mae: 4.4786 - val_loss: 14.2247 - val_mae: 3.3063\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 10.5908 - mae: 2.6954 - val_loss: 5.5553 - val_mae: 1.9321\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.4756 - mae: 1.8526 - val_loss: 4.3248 - val_mae: 1.6256\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.4033 - mae: 1.8529 - val_loss: 4.2565 - val_mae: 1.6157\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8668 - mae: 1.7640 - val_loss: 4.2151 - val_mae: 1.6101\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0451 - mae: 1.7599 - val_loss: 4.1982 - val_mae: 1.5921\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9925 - mae: 1.7580 - val_loss: 4.1433 - val_mae: 1.5769\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7052 - mae: 1.7344 - val_loss: 4.1669 - val_mae: 1.5841\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5531 - mae: 1.6870 - val_loss: 4.0938 - val_mae: 1.5657\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7002 - mae: 1.7113 - val_loss: 4.0828 - val_mae: 1.5682\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7341 - mae: 1.6958 - val_loss: 4.0564 - val_mae: 1.5643\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0279 - mae: 1.7667 - val_loss: 4.0189 - val_mae: 1.5551\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2919 - mae: 1.6612 - val_loss: 4.0537 - val_mae: 1.5715\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4621 - mae: 1.6803 - val_loss: 4.0229 - val_mae: 1.5647\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3258 - mae: 1.6635 - val_loss: 3.9566 - val_mae: 1.5377\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4363 - mae: 1.6886 - val_loss: 4.0257 - val_mae: 1.5741\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4048 - mae: 1.6419 - val_loss: 3.9309 - val_mae: 1.5420\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1458 - mae: 1.6279 - val_loss: 3.9576 - val_mae: 1.5505\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4595 - mae: 1.6558 - val_loss: 3.9396 - val_mae: 1.5477\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2936 - mae: 1.6236 - val_loss: 4.0045 - val_mae: 1.5752\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3682 - mae: 1.6606 - val_loss: 3.9021 - val_mae: 1.5354\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4044 - mae: 1.6532 - val_loss: 3.9361 - val_mae: 1.5555\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9763 - mae: 1.5934 - val_loss: 3.9133 - val_mae: 1.5405\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3990 - mae: 1.6689 - val_loss: 3.9131 - val_mae: 1.5453\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1107 - mae: 1.6021 - val_loss: 3.8744 - val_mae: 1.5273\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9495 - mae: 1.5757 - val_loss: 3.9026 - val_mae: 1.5429\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1397 - mae: 1.6208 - val_loss: 3.8815 - val_mae: 1.5377\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7799 - mae: 1.5514 - val_loss: 3.8412 - val_mae: 1.5132\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0720 - mae: 1.5946 - val_loss: 3.9140 - val_mae: 1.5481\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8313 - mae: 1.5706 - val_loss: 3.8977 - val_mae: 1.5420\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9169 - mae: 1.5802 - val_loss: 3.8802 - val_mae: 1.5356\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1500 - mae: 1.6123 - val_loss: 3.8656 - val_mae: 1.5404\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1205 - mae: 1.6043 - val_loss: 3.8419 - val_mae: 1.5182\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8078 - mae: 1.5419 - val_loss: 3.9121 - val_mae: 1.5514\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2569 - mae: 1.6249 - val_loss: 3.8540 - val_mae: 1.5266\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1839 - mae: 1.6080 - val_loss: 3.8092 - val_mae: 1.5122\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2177 - mae: 1.6291 - val_loss: 3.8416 - val_mae: 1.5261\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7370 - mae: 1.5391 - val_loss: 3.8467 - val_mae: 1.5329\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0916 - mae: 1.6177 - val_loss: 3.8457 - val_mae: 1.5302\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1435 - mae: 1.5972 - val_loss: 3.8160 - val_mae: 1.5196\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9529 - mae: 1.5660 - val_loss: 3.7502 - val_mae: 1.4954\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9000 - mae: 1.5653 - val_loss: 3.7819 - val_mae: 1.5047\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7506 - mae: 1.5384 - val_loss: 3.7755 - val_mae: 1.5074\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0082 - mae: 1.5879 - val_loss: 3.8263 - val_mae: 1.5275\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8308 - mae: 1.5424 - val_loss: 3.7743 - val_mae: 1.5061\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8435 - mae: 1.5715 - val_loss: 3.7922 - val_mae: 1.5169\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6242 - mae: 1.4881 - val_loss: 3.8187 - val_mae: 1.5297\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0100 - mae: 1.6139 - val_loss: 3.7997 - val_mae: 1.5086\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8845 - mae: 1.5539 - val_loss: 3.8018 - val_mae: 1.5080\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9530 - mae: 1.5641 - val_loss: 3.7595 - val_mae: 1.5148\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9683 - mae: 1.5768 - val_loss: 3.7683 - val_mae: 1.5137\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6187 - mae: 1.5034 - val_loss: 3.7460 - val_mae: 1.4951\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9071 - mae: 1.5863 - val_loss: 3.7681 - val_mae: 1.5164\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6860 - mae: 1.5191 - val_loss: 3.7768 - val_mae: 1.5173\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6674 - mae: 1.5142 - val_loss: 3.7931 - val_mae: 1.5159\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0500 - mae: 1.5684 - val_loss: 3.7123 - val_mae: 1.4901\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9875 - mae: 1.5957 - val_loss: 3.8951 - val_mae: 1.5556\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8738 - mae: 1.5499 - val_loss: 3.6874 - val_mae: 1.4869\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7824 - mae: 1.5140 - val_loss: 3.8306 - val_mae: 1.5303\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5778 - mae: 1.5024 - val_loss: 3.7441 - val_mae: 1.5054\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0237 - mae: 1.5927 - val_loss: 3.8146 - val_mae: 1.5290\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9051 - mae: 1.5591 - val_loss: 3.7261 - val_mae: 1.4995\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8263 - mae: 1.5486 - val_loss: 3.7949 - val_mae: 1.5290\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7395 - mae: 1.5238 - val_loss: 3.7535 - val_mae: 1.5123\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8022 - mae: 1.5644 - val_loss: 3.7415 - val_mae: 1.5013\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9395 - mae: 1.5609 - val_loss: 3.8106 - val_mae: 1.5313\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9986 - mae: 1.5800 - val_loss: 3.8837 - val_mae: 1.5523\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1214 - mae: 1.5910 - val_loss: 3.7589 - val_mae: 1.5179\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5527 - mae: 1.4771 - val_loss: 3.8134 - val_mae: 1.5291\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7654 - mae: 1.5243 - val_loss: 3.8199 - val_mae: 1.5287\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5624 - mae: 1.5077 - val_loss: 3.7851 - val_mae: 1.5186\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8346 - mae: 1.5505 - val_loss: 3.9233 - val_mae: 1.5706\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5992 - mae: 1.5245 - val_loss: 3.7363 - val_mae: 1.5042\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4694 - mae: 1.4705 - val_loss: 3.8260 - val_mae: 1.5323\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7799 - mae: 1.5457 - val_loss: 3.7783 - val_mae: 1.5171\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4317 - mae: 1.4745 - val_loss: 3.8151 - val_mae: 1.5242\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7681 - mae: 1.5352 - val_loss: 3.8620 - val_mae: 1.5418\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6645 - mae: 1.5131 - val_loss: 3.7840 - val_mae: 1.5174\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6033 - mae: 1.5145 - val_loss: 3.8908 - val_mae: 1.5516\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7798 - mae: 1.5514 - val_loss: 3.7787 - val_mae: 1.5143\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7283 - mae: 1.5175 - val_loss: 3.9640 - val_mae: 1.5716\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4310 - mae: 1.4543 - val_loss: 3.7835 - val_mae: 1.5033\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5509 - mae: 1.4979 - val_loss: 3.9338 - val_mae: 1.5669\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7632 - mae: 1.5123 - val_loss: 3.7951 - val_mae: 1.5181\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6834 - mae: 1.4989 - val_loss: 3.8323 - val_mae: 1.5213\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7228 - mae: 1.5127 - val_loss: 4.0114 - val_mae: 1.5888\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7793 - mae: 1.5355 - val_loss: 3.8654 - val_mae: 1.5332\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6779 - mae: 1.4993 - val_loss: 3.8658 - val_mae: 1.5338\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5619 - mae: 1.4864 - val_loss: 3.9867 - val_mae: 1.5685\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6842 - mae: 1.5068 - val_loss: 3.9205 - val_mae: 1.5520\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5731 - mae: 1.4831 - val_loss: 3.8728 - val_mae: 1.5325\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7998 - mae: 1.5256 - val_loss: 3.9545 - val_mae: 1.5595\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4780 - mae: 1.4822 - val_loss: 3.8740 - val_mae: 1.5374\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1631 - mae: 1.4170 - val_loss: 4.0295 - val_mae: 1.5746\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5065 - mae: 1.4771 - val_loss: 3.9013 - val_mae: 1.5469\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7068 - mae: 1.4953 - val_loss: 3.9039 - val_mae: 1.5467\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2284 - mae: 1.4132 - val_loss: 3.9770 - val_mae: 1.5660\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4423 - mae: 1.6691 \n",
            "Test MAE (Mean Absolute Error): 1.69\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "   Predicted     Actual\n",
            "0   7.092439   7.494001\n",
            "1  11.185057  12.394215\n",
            "2  10.132985   9.997158\n",
            "3   7.563772   8.965073\n",
            "4   8.183275  11.882369\n",
            "5  11.064339   8.595982\n",
            "6  10.966451  13.475625\n",
            "7   7.875083  11.871617\n",
            "8   6.752769   4.827736\n",
            "9   8.682444   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Predicted total rebounds for the player's next game: 13.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#keegan murray"
      ],
      "metadata": {
        "id": "M1cQSX8gAepx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IJGNVsaxAeEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [7.4], # Changed to list\n",
        "    'avg_min_last5': [36.7], # Changed to list\n",
        "    'opp_avg_reb_allowed': [43.7], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [3], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ace5aeb7-a29c-480a-e9a4-4e18dccfb0b4",
        "id": "Lewp38Q2AhSz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 79.4318 - mae: 8.4392 - val_loss: 72.5045 - val_mae: 8.1291\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 60.8210 - mae: 7.2666 - val_loss: 50.4097 - val_mae: 6.6724\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 39.3803 - mae: 5.6644 - val_loss: 26.1751 - val_mae: 4.7069\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20.1478 - mae: 3.8189 - val_loss: 8.9341 - val_mae: 2.5533\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.6907 - mae: 2.2072 - val_loss: 4.8019 - val_mae: 1.6543\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.9371 - mae: 1.9577 - val_loss: 4.4880 - val_mae: 1.5736\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.1031 - mae: 1.8149 - val_loss: 4.5312 - val_mae: 1.6064\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2776 - mae: 1.8229 - val_loss: 4.4797 - val_mae: 1.6011\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.1804 - mae: 1.8082 - val_loss: 4.4103 - val_mae: 1.5853\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.3512 - mae: 1.8343 - val_loss: 4.4262 - val_mae: 1.5969\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0884 - mae: 1.7965 - val_loss: 4.3794 - val_mae: 1.5915\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.6682 - mae: 1.7130 - val_loss: 4.3570 - val_mae: 1.5883\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.9835 - mae: 1.7792 - val_loss: 4.2678 - val_mae: 1.5643\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5915 - mae: 1.6867 - val_loss: 4.2805 - val_mae: 1.5775\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6994 - mae: 1.7271 - val_loss: 4.3143 - val_mae: 1.5946\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4308 - mae: 1.7044 - val_loss: 4.3093 - val_mae: 1.6043\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5553 - mae: 1.6859 - val_loss: 4.2149 - val_mae: 1.5720\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3884 - mae: 1.6928 - val_loss: 4.2679 - val_mae: 1.5940\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2295 - mae: 1.6392 - val_loss: 4.1658 - val_mae: 1.5726\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4616 - mae: 1.6614 - val_loss: 4.2002 - val_mae: 1.5837\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1923 - mae: 1.6310 - val_loss: 4.1341 - val_mae: 1.5518\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5718 - mae: 1.6959 - val_loss: 4.1337 - val_mae: 1.5746\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5001 - mae: 1.6991 - val_loss: 4.1350 - val_mae: 1.5642\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5706 - mae: 1.6940 - val_loss: 4.2174 - val_mae: 1.5993\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1587 - mae: 1.6251 - val_loss: 4.0764 - val_mae: 1.5516\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0915 - mae: 1.6178 - val_loss: 4.1373 - val_mae: 1.5763\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3795 - mae: 1.6862 - val_loss: 4.1262 - val_mae: 1.5777\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4613 - mae: 1.6656 - val_loss: 4.0664 - val_mae: 1.5450\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5992 - mae: 1.6979 - val_loss: 4.0874 - val_mae: 1.5699\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0822 - mae: 1.5839 - val_loss: 4.0641 - val_mae: 1.5498\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0099 - mae: 1.6139 - val_loss: 4.0268 - val_mae: 1.5403\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2892 - mae: 1.6396 - val_loss: 4.0271 - val_mae: 1.5544\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4244 - mae: 1.6591 - val_loss: 3.9546 - val_mae: 1.5226\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2502 - mae: 1.6524 - val_loss: 4.1394 - val_mae: 1.5867\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1629 - mae: 1.6027 - val_loss: 4.0081 - val_mae: 1.5413\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2815 - mae: 1.6504 - val_loss: 4.0072 - val_mae: 1.5416\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2604 - mae: 1.6479 - val_loss: 3.9298 - val_mae: 1.5275\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9575 - mae: 1.5706 - val_loss: 3.9749 - val_mae: 1.5334\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2817 - mae: 1.6166 - val_loss: 3.9937 - val_mae: 1.5390\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1006 - mae: 1.5843 - val_loss: 3.9174 - val_mae: 1.5146\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2528 - mae: 1.6219 - val_loss: 3.9812 - val_mae: 1.5467\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8756 - mae: 1.5732 - val_loss: 3.9401 - val_mae: 1.5252\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0888 - mae: 1.6422 - val_loss: 3.8925 - val_mae: 1.5065\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7329 - mae: 1.5126 - val_loss: 3.9577 - val_mae: 1.5329\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9956 - mae: 1.5975 - val_loss: 3.9239 - val_mae: 1.5260\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8983 - mae: 1.5654 - val_loss: 3.9272 - val_mae: 1.5312\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8862 - mae: 1.5444 - val_loss: 3.8453 - val_mae: 1.4927\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9660 - mae: 1.5962 - val_loss: 3.9185 - val_mae: 1.5258\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0390 - mae: 1.5897 - val_loss: 3.8960 - val_mae: 1.5222\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2916 - mae: 1.6414 - val_loss: 3.8676 - val_mae: 1.5081\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8689 - mae: 1.5774 - val_loss: 3.9045 - val_mae: 1.5088\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1250 - mae: 1.6279 - val_loss: 3.8293 - val_mae: 1.4814\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9009 - mae: 1.5340 - val_loss: 4.0223 - val_mae: 1.5659\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1556 - mae: 1.6011 - val_loss: 3.8241 - val_mae: 1.4945\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0274 - mae: 1.5823 - val_loss: 3.9458 - val_mae: 1.5471\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9308 - mae: 1.5698 - val_loss: 3.7330 - val_mae: 1.4561\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9855 - mae: 1.5959 - val_loss: 3.9288 - val_mae: 1.5351\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1202 - mae: 1.6115 - val_loss: 3.8056 - val_mae: 1.5005\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6350 - mae: 1.5011 - val_loss: 3.7807 - val_mae: 1.4889\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5046 - mae: 1.4903 - val_loss: 3.8530 - val_mae: 1.5080\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5242 - mae: 1.4835 - val_loss: 3.7769 - val_mae: 1.4879\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8473 - mae: 1.5556 - val_loss: 3.8645 - val_mae: 1.5257\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8060 - mae: 1.5574 - val_loss: 3.7536 - val_mae: 1.4812\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0122 - mae: 1.5889 - val_loss: 3.9071 - val_mae: 1.5338\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5799 - mae: 1.5044 - val_loss: 3.8441 - val_mae: 1.5162\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6592 - mae: 1.5082 - val_loss: 3.7688 - val_mae: 1.4914\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0187 - mae: 1.5831 - val_loss: 3.7913 - val_mae: 1.4844\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8689 - mae: 1.5756 - val_loss: 3.9190 - val_mae: 1.5520\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8369 - mae: 1.5638 - val_loss: 3.7151 - val_mae: 1.4637\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8452 - mae: 1.5341 - val_loss: 4.0317 - val_mae: 1.5786\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6527 - mae: 1.5278 - val_loss: 3.7649 - val_mae: 1.4809\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5837 - mae: 1.5117 - val_loss: 3.7982 - val_mae: 1.5038\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8611 - mae: 1.5533 - val_loss: 3.8539 - val_mae: 1.5189\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7505 - mae: 1.5326 - val_loss: 3.8853 - val_mae: 1.5297\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6076 - mae: 1.5084 - val_loss: 3.7179 - val_mae: 1.4835\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7331 - mae: 1.5374 - val_loss: 3.7725 - val_mae: 1.4853\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3535 - mae: 1.4423 - val_loss: 3.7595 - val_mae: 1.4915\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8358 - mae: 1.5782 - val_loss: 3.8954 - val_mae: 1.5400\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6851 - mae: 1.5315 - val_loss: 3.7108 - val_mae: 1.4684\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9299 - mae: 1.5782 - val_loss: 3.8047 - val_mae: 1.5064\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5420 - mae: 1.5201 - val_loss: 3.7828 - val_mae: 1.4895\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5793 - mae: 1.4916 - val_loss: 3.8241 - val_mae: 1.5174\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9185 - mae: 1.5731 - val_loss: 3.7966 - val_mae: 1.4946\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6677 - mae: 1.5043 - val_loss: 3.7933 - val_mae: 1.5104\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6052 - mae: 1.5332 - val_loss: 3.7829 - val_mae: 1.4889\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9743 - mae: 1.5756 - val_loss: 3.8099 - val_mae: 1.5071\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6411 - mae: 1.4948 - val_loss: 3.8787 - val_mae: 1.5341\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4551 - mae: 1.4905 - val_loss: 3.7507 - val_mae: 1.4801\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7587 - mae: 1.5212 - val_loss: 3.9296 - val_mae: 1.5534\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6576 - mae: 1.5241 - val_loss: 3.7500 - val_mae: 1.4779\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6527 - mae: 1.5236 - val_loss: 3.8570 - val_mae: 1.5228\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6092 - mae: 1.5175 - val_loss: 3.7946 - val_mae: 1.5012\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1688 - mae: 1.4211 - val_loss: 3.8368 - val_mae: 1.5153\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6866 - mae: 1.5062 - val_loss: 3.8732 - val_mae: 1.5217\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4850 - mae: 1.4810 - val_loss: 3.7759 - val_mae: 1.4968\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6161 - mae: 1.5124 - val_loss: 3.8999 - val_mae: 1.5415\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6235 - mae: 1.4990 - val_loss: 3.8590 - val_mae: 1.5215\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3938 - mae: 1.4657 - val_loss: 3.8817 - val_mae: 1.5223\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6008 - mae: 1.5086 - val_loss: 3.7949 - val_mae: 1.5015\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3756 - mae: 1.4391 - val_loss: 4.0037 - val_mae: 1.5682\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2840 - mae: 1.6287 \n",
            "Test MAE (Mean Absolute Error): 1.63\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "   Predicted     Actual\n",
            "0   7.399656   7.494001\n",
            "1  10.891189  12.394215\n",
            "2  10.309501   9.997158\n",
            "3   7.275903   8.965073\n",
            "4   8.204433  11.882369\n",
            "5  11.075649   8.595982\n",
            "6  10.594082  13.475625\n",
            "7   7.839289  11.871617\n",
            "8   6.259302   4.827736\n",
            "9   8.725819   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Predicted total rebounds for the player's next game: 7.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#demar derozan"
      ],
      "metadata": {
        "id": "Y4omsawwBXGi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bK35kO07BY7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [5.2], # Changed to list\n",
        "    'avg_min_last5': [32.5], # Changed to list\n",
        "    'opp_avg_reb_allowed': [43.7], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [8], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4eb0589-22bf-48b6-a07d-2036f31cffa6",
        "id": "1hLjubJGBZKN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 80.6762 - mae: 8.4659 - val_loss: 79.3348 - val_mae: 8.4582\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 63.9584 - mae: 7.3896 - val_loss: 59.0453 - val_mae: 7.1308\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 43.4860 - mae: 5.8545 - val_loss: 34.5735 - val_mae: 5.2036\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 23.0249 - mae: 4.0553 - val_loss: 15.3757 - val_mae: 3.2169\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.0000 - mae: 2.6851 - val_loss: 7.0921 - val_mae: 2.1346\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.2857 - mae: 1.9992 - val_loss: 5.0236 - val_mae: 1.7529\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.4103 - mae: 1.8611 - val_loss: 4.5855 - val_mae: 1.6803\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 5.3284 - mae: 1.8202 - val_loss: 4.4359 - val_mae: 1.6422\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.1191 - mae: 1.8053 - val_loss: 4.3995 - val_mae: 1.6320\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4.7659 - mae: 1.7170 - val_loss: 4.3333 - val_mae: 1.6110\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8266 - mae: 1.7269 - val_loss: 4.3448 - val_mae: 1.6220\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6074 - mae: 1.7208 - val_loss: 4.3009 - val_mae: 1.6084\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.6496 - mae: 1.7234 - val_loss: 4.3157 - val_mae: 1.6205\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.4146 - mae: 1.6717 - val_loss: 4.2827 - val_mae: 1.6190\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3756 - mae: 1.6630 - val_loss: 4.2165 - val_mae: 1.5945\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6853 - mae: 1.7420 - val_loss: 4.2443 - val_mae: 1.6147\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3220 - mae: 1.6411 - val_loss: 4.2477 - val_mae: 1.6212\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2506 - mae: 1.6251 - val_loss: 4.1852 - val_mae: 1.5955\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3198 - mae: 1.6492 - val_loss: 4.1998 - val_mae: 1.6098\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.4464 - mae: 1.6460 - val_loss: 4.1264 - val_mae: 1.5861\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.4158 - mae: 1.6507 - val_loss: 4.1677 - val_mae: 1.6116\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.3625 - mae: 1.6532 - val_loss: 4.1446 - val_mae: 1.6034\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5404 - mae: 1.7314 - val_loss: 4.0694 - val_mae: 1.5788\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3591 - mae: 1.6656 - val_loss: 4.1841 - val_mae: 1.6166\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.4148 - mae: 1.6673 - val_loss: 4.0814 - val_mae: 1.5950\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4.5389 - mae: 1.7103 - val_loss: 4.1818 - val_mae: 1.6145\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.2621 - mae: 1.6319 - val_loss: 4.0193 - val_mae: 1.5629\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.2150 - mae: 1.6320 - val_loss: 4.0861 - val_mae: 1.5973\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.1938 - mae: 1.6176 - val_loss: 4.0326 - val_mae: 1.5747\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.3388 - mae: 1.6660 - val_loss: 4.0409 - val_mae: 1.5790\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.0212 - mae: 1.6014 - val_loss: 4.0596 - val_mae: 1.5914\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.9581 - mae: 1.5826 - val_loss: 3.9944 - val_mae: 1.5635\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0129 - mae: 1.5791 - val_loss: 3.9619 - val_mae: 1.5626\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0358 - mae: 1.5921 - val_loss: 4.0198 - val_mae: 1.5845\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4787 - mae: 1.6641 - val_loss: 4.0133 - val_mae: 1.5779\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.1773 - mae: 1.6071 - val_loss: 4.0029 - val_mae: 1.5774\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.2498 - mae: 1.6249 - val_loss: 3.9020 - val_mae: 1.5477\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.0039 - mae: 1.5626 - val_loss: 3.9529 - val_mae: 1.5682\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.2686 - mae: 1.6360 - val_loss: 3.9588 - val_mae: 1.5671\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.1137 - mae: 1.5888 - val_loss: 3.9792 - val_mae: 1.5778\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.0857 - mae: 1.6131 - val_loss: 3.8758 - val_mae: 1.5464\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.1507 - mae: 1.6160 - val_loss: 3.9188 - val_mae: 1.5577\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.1189 - mae: 1.6104 - val_loss: 3.8699 - val_mae: 1.5408\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.8293 - mae: 1.5795 - val_loss: 3.9264 - val_mae: 1.5744\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.9598 - mae: 1.6017 - val_loss: 3.9697 - val_mae: 1.5763\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.8170 - mae: 1.5463 - val_loss: 3.9347 - val_mae: 1.5663\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8005 - mae: 1.5536 - val_loss: 3.8836 - val_mae: 1.5572\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8757 - mae: 1.5762 - val_loss: 3.8257 - val_mae: 1.5221\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8768 - mae: 1.5805 - val_loss: 3.9432 - val_mae: 1.5789\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1168 - mae: 1.6389 - val_loss: 3.9396 - val_mae: 1.5705\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7745 - mae: 1.5307 - val_loss: 3.9089 - val_mae: 1.5545\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8397 - mae: 1.5563 - val_loss: 3.8689 - val_mae: 1.5458\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0524 - mae: 1.5938 - val_loss: 3.8869 - val_mae: 1.5503\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8784 - mae: 1.5608 - val_loss: 3.8533 - val_mae: 1.5360\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7661 - mae: 1.5450 - val_loss: 3.8690 - val_mae: 1.5457\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9732 - mae: 1.5835 - val_loss: 3.8460 - val_mae: 1.5396\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6991 - mae: 1.5275 - val_loss: 3.9102 - val_mae: 1.5514\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8248 - mae: 1.5414 - val_loss: 3.8640 - val_mae: 1.5423\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8310 - mae: 1.5473 - val_loss: 3.8279 - val_mae: 1.5286\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8970 - mae: 1.5768 - val_loss: 3.8885 - val_mae: 1.5524\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5411 - mae: 1.4866 - val_loss: 3.9203 - val_mae: 1.5651\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7774 - mae: 1.5496 - val_loss: 3.8843 - val_mae: 1.5490\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8850 - mae: 1.5653 - val_loss: 3.8658 - val_mae: 1.5433\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9705 - mae: 1.5887 - val_loss: 3.8274 - val_mae: 1.5330\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7732 - mae: 1.5530 - val_loss: 3.8649 - val_mae: 1.5464\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5590 - mae: 1.5173 - val_loss: 3.8301 - val_mae: 1.5343\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6886 - mae: 1.5431 - val_loss: 3.9289 - val_mae: 1.5597\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2068 - mae: 1.6354 - val_loss: 3.9013 - val_mae: 1.5538\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8057 - mae: 1.5781 - val_loss: 3.8813 - val_mae: 1.5519\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5192 - mae: 1.4825 - val_loss: 3.9429 - val_mae: 1.5650\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7750 - mae: 1.5474 - val_loss: 3.9286 - val_mae: 1.5622\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0774 - mae: 1.5986 - val_loss: 3.9518 - val_mae: 1.5771\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5606 - mae: 1.5083 - val_loss: 3.8463 - val_mae: 1.5395\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8357 - mae: 1.5577 - val_loss: 3.8820 - val_mae: 1.5438\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7543 - mae: 1.5481 - val_loss: 3.8279 - val_mae: 1.5282\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6745 - mae: 1.5122 - val_loss: 3.8672 - val_mae: 1.5529\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6152 - mae: 1.5152 - val_loss: 3.9109 - val_mae: 1.5498\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5604 - mae: 1.4818 - val_loss: 3.8652 - val_mae: 1.5479\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8429 - mae: 1.5599 - val_loss: 3.9042 - val_mae: 1.5493\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8292 - mae: 1.5755 - val_loss: 3.8588 - val_mae: 1.5374\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7656 - mae: 1.5615 - val_loss: 3.9550 - val_mae: 1.5703\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7107 - mae: 1.5311 - val_loss: 3.8203 - val_mae: 1.5359\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3194 - mae: 1.4186 - val_loss: 3.9404 - val_mae: 1.5616\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5781 - mae: 1.5102 - val_loss: 3.9656 - val_mae: 1.5717\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2817 - mae: 1.4205 - val_loss: 3.8594 - val_mae: 1.5511\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6883 - mae: 1.5283 - val_loss: 3.9125 - val_mae: 1.5566\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8695 - mae: 1.5471 - val_loss: 3.9989 - val_mae: 1.5926\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5681 - mae: 1.5029 - val_loss: 3.9004 - val_mae: 1.5517\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6023 - mae: 1.5023 - val_loss: 3.9938 - val_mae: 1.5823\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5900 - mae: 1.5014 - val_loss: 3.9665 - val_mae: 1.5657\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5566 - mae: 1.4896 - val_loss: 3.9252 - val_mae: 1.5596\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5486 - mae: 1.4858 - val_loss: 3.8870 - val_mae: 1.5497\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4204 - mae: 1.4641 - val_loss: 3.9944 - val_mae: 1.5840\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3693 - mae: 1.4690 - val_loss: 3.8472 - val_mae: 1.5470\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5004 - mae: 1.4931 - val_loss: 3.9304 - val_mae: 1.5610\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4349 - mae: 1.4538 - val_loss: 3.9433 - val_mae: 1.5613\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5564 - mae: 1.4841 - val_loss: 3.8684 - val_mae: 1.5545\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6836 - mae: 1.5139 - val_loss: 3.9402 - val_mae: 1.5590\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1619 - mae: 1.4151 - val_loss: 4.0049 - val_mae: 1.5812\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6804 - mae: 1.5288 - val_loss: 3.8876 - val_mae: 1.5541\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0564 - mae: 1.5937 \n",
            "Test MAE (Mean Absolute Error): 1.62\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "   Predicted     Actual\n",
            "0   7.005332   7.494001\n",
            "1  11.261320  12.394215\n",
            "2  10.518345   9.997158\n",
            "3   7.823334   8.965073\n",
            "4   8.030688  11.882369\n",
            "5  11.498480   8.595982\n",
            "6  10.889118  13.475625\n",
            "7   8.442185  11.871617\n",
            "8   6.652769   4.827736\n",
            "9   8.542921   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Predicted total rebounds for the player's next game: 8.07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#luca doncic"
      ],
      "metadata": {
        "id": "MHeAK-5cCDu_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "srM5ZF7rCFy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [7], # Changed to list\n",
        "    'avg_min_last5': [35.6], # Changed to list\n",
        "    'opp_avg_reb_allowed': [46.2], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [8], # Changed to list\n",
        "    'home_indicator': [0], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a021755a-4a71-4410-9095-30b57242faf2",
        "id": "AeyXWL2BCGCJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - loss: 80.0498 - mae: 8.5060 - val_loss: 73.8578 - val_mae: 8.1810\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 58.1661 - mae: 7.0830 - val_loss: 49.8416 - val_mae: 6.5334\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 37.1970 - mae: 5.4073 - val_loss: 24.0978 - val_mae: 4.3329\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.2767 - mae: 3.2287 - val_loss: 8.9028 - val_mae: 2.5110\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3989 - mae: 2.2198 - val_loss: 5.2292 - val_mae: 1.8586\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.9297 - mae: 1.9262 - val_loss: 4.7240 - val_mae: 1.7320\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.5962 - mae: 1.8989 - val_loss: 4.5308 - val_mae: 1.6738\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.9356 - mae: 1.7857 - val_loss: 4.4536 - val_mae: 1.6546\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.3620 - mae: 1.8352 - val_loss: 4.4243 - val_mae: 1.6512\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.3650 - mae: 1.8357 - val_loss: 4.3396 - val_mae: 1.6303\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.1561 - mae: 1.7976 - val_loss: 4.2456 - val_mae: 1.6048\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.9700 - mae: 1.7615 - val_loss: 4.2078 - val_mae: 1.5980\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9072 - mae: 1.7466 - val_loss: 4.2420 - val_mae: 1.6150\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8518 - mae: 1.7677 - val_loss: 4.0603 - val_mae: 1.5548\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4067 - mae: 1.6696 - val_loss: 4.1994 - val_mae: 1.6137\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5582 - mae: 1.6881 - val_loss: 4.0689 - val_mae: 1.5694\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6767 - mae: 1.7218 - val_loss: 4.0437 - val_mae: 1.5629\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6027 - mae: 1.6883 - val_loss: 4.0465 - val_mae: 1.5646\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1412 - mae: 1.6022 - val_loss: 4.0181 - val_mae: 1.5572\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4512 - mae: 1.6721 - val_loss: 4.0271 - val_mae: 1.5635\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8465 - mae: 1.7548 - val_loss: 3.9079 - val_mae: 1.5259\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7093 - mae: 1.7284 - val_loss: 3.9343 - val_mae: 1.5330\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4373 - mae: 1.6786 - val_loss: 3.9360 - val_mae: 1.5389\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3262 - mae: 1.6609 - val_loss: 3.9918 - val_mae: 1.5638\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7751 - mae: 1.7389 - val_loss: 3.8894 - val_mae: 1.5199\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3677 - mae: 1.6619 - val_loss: 3.8681 - val_mae: 1.5228\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3374 - mae: 1.6663 - val_loss: 3.9276 - val_mae: 1.5400\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2265 - mae: 1.6118 - val_loss: 3.8674 - val_mae: 1.5208\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3476 - mae: 1.6490 - val_loss: 3.7862 - val_mae: 1.4982\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3767 - mae: 1.6609 - val_loss: 3.8675 - val_mae: 1.5341\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3607 - mae: 1.6833 - val_loss: 3.8146 - val_mae: 1.5104\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9685 - mae: 1.5762 - val_loss: 3.8191 - val_mae: 1.5126\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4652 - mae: 1.6704 - val_loss: 3.8146 - val_mae: 1.5143\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0978 - mae: 1.6156 - val_loss: 3.7503 - val_mae: 1.4927\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4601 - mae: 1.6729 - val_loss: 3.8144 - val_mae: 1.5187\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2110 - mae: 1.6118 - val_loss: 3.7605 - val_mae: 1.4952\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1347 - mae: 1.6347 - val_loss: 3.7933 - val_mae: 1.5131\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6995 - mae: 1.5096 - val_loss: 3.7207 - val_mae: 1.4853\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0743 - mae: 1.5675 - val_loss: 3.7490 - val_mae: 1.4997\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2142 - mae: 1.6124 - val_loss: 3.6079 - val_mae: 1.4500\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0189 - mae: 1.5875 - val_loss: 3.7277 - val_mae: 1.4957\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4084 - mae: 1.6533 - val_loss: 3.6737 - val_mae: 1.4760\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2803 - mae: 1.6444 - val_loss: 3.7482 - val_mae: 1.5033\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8325 - mae: 1.5698 - val_loss: 3.6508 - val_mae: 1.4691\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6707 - mae: 1.5265 - val_loss: 3.7092 - val_mae: 1.4931\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6594 - mae: 1.5194 - val_loss: 3.6513 - val_mae: 1.4694\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8558 - mae: 1.5617 - val_loss: 3.6370 - val_mae: 1.4717\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6952 - mae: 1.5143 - val_loss: 3.7249 - val_mae: 1.4979\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1514 - mae: 1.6301 - val_loss: 3.6782 - val_mae: 1.4760\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0805 - mae: 1.6011 - val_loss: 3.7358 - val_mae: 1.5033\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1886 - mae: 1.6169 - val_loss: 3.6008 - val_mae: 1.4581\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9469 - mae: 1.5738 - val_loss: 3.6879 - val_mae: 1.4843\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1693 - mae: 1.5896 - val_loss: 3.7564 - val_mae: 1.5081\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2655 - mae: 1.6115 - val_loss: 3.7537 - val_mae: 1.5093\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0593 - mae: 1.5914 - val_loss: 3.6332 - val_mae: 1.4721\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7994 - mae: 1.5508 - val_loss: 3.7652 - val_mae: 1.5042\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8531 - mae: 1.5572 - val_loss: 3.6019 - val_mae: 1.4621\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1905 - mae: 1.5935 - val_loss: 3.6773 - val_mae: 1.4701\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8609 - mae: 1.5661 - val_loss: 3.6245 - val_mae: 1.4645\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1623 - mae: 1.6031 - val_loss: 3.6639 - val_mae: 1.4698\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8172 - mae: 1.5320 - val_loss: 3.6731 - val_mae: 1.4852\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9670 - mae: 1.6087 - val_loss: 3.6767 - val_mae: 1.4773\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0254 - mae: 1.6023 - val_loss: 3.6967 - val_mae: 1.4865\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7197 - mae: 1.5324 - val_loss: 3.6035 - val_mae: 1.4472\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9264 - mae: 1.5800 - val_loss: 3.7507 - val_mae: 1.5057\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0557 - mae: 1.6128 - val_loss: 3.5749 - val_mae: 1.4493\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0847 - mae: 1.5794 - val_loss: 3.7164 - val_mae: 1.4858\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6971 - mae: 1.5460 - val_loss: 3.5887 - val_mae: 1.4457\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7875 - mae: 1.5391 - val_loss: 3.7579 - val_mae: 1.5115\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9239 - mae: 1.5672 - val_loss: 3.5909 - val_mae: 1.4515\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7071 - mae: 1.5221 - val_loss: 3.7873 - val_mae: 1.5129\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8847 - mae: 1.5612 - val_loss: 3.6758 - val_mae: 1.4695\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8792 - mae: 1.5563 - val_loss: 3.5693 - val_mae: 1.4423\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9179 - mae: 1.5323 - val_loss: 3.8181 - val_mae: 1.5233\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0117 - mae: 1.6022 - val_loss: 3.6891 - val_mae: 1.4786\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6936 - mae: 1.5462 - val_loss: 3.7292 - val_mae: 1.4903\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5132 - mae: 1.5167 - val_loss: 3.6652 - val_mae: 1.4779\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9194 - mae: 1.5818 - val_loss: 3.6955 - val_mae: 1.4784\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5645 - mae: 1.4987 - val_loss: 3.7081 - val_mae: 1.4910\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7499 - mae: 1.5431 - val_loss: 3.7619 - val_mae: 1.4990\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6907 - mae: 1.5136 - val_loss: 3.6465 - val_mae: 1.4664\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5425 - mae: 1.4802 - val_loss: 3.7789 - val_mae: 1.4997\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5981 - mae: 1.5034 - val_loss: 3.7743 - val_mae: 1.5053\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5529 - mae: 1.4949 - val_loss: 3.6360 - val_mae: 1.4657\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6393 - mae: 1.5138 - val_loss: 3.8022 - val_mae: 1.5059\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6301 - mae: 1.5080 - val_loss: 3.6036 - val_mae: 1.4610\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4173 - mae: 1.4474 - val_loss: 3.6709 - val_mae: 1.4761\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7738 - mae: 1.5437 - val_loss: 3.6869 - val_mae: 1.4765\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6638 - mae: 1.5246 - val_loss: 3.6835 - val_mae: 1.4818\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8061 - mae: 1.5620 - val_loss: 3.6258 - val_mae: 1.4633\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8816 - mae: 1.5258 - val_loss: 3.5878 - val_mae: 1.4494\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5621 - mae: 1.4935 - val_loss: 3.9234 - val_mae: 1.5471\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9977 - mae: 1.5857 - val_loss: 3.6665 - val_mae: 1.4725\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6125 - mae: 1.4868 - val_loss: 3.8034 - val_mae: 1.5123\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5090 - mae: 1.5078 - val_loss: 3.6333 - val_mae: 1.4656\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7388 - mae: 1.5227 - val_loss: 3.7090 - val_mae: 1.4901\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5294 - mae: 1.4937 - val_loss: 3.5866 - val_mae: 1.4521\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6825 - mae: 1.5381 - val_loss: 3.6606 - val_mae: 1.4750\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4983 - mae: 1.4813 - val_loss: 3.7742 - val_mae: 1.5000\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8044 - mae: 1.5569 - val_loss: 3.5835 - val_mae: 1.4647\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1732 - mae: 1.6300 \n",
            "Test MAE (Mean Absolute Error): 1.64\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "   Predicted     Actual\n",
            "0   7.407319   7.494001\n",
            "1  11.370780  12.394215\n",
            "2  10.883996   9.997158\n",
            "3   8.165261   8.965073\n",
            "4   8.397237  11.882369\n",
            "5  11.497165   8.595982\n",
            "6  10.790725  13.475625\n",
            "7   7.991510  11.871617\n",
            "8   6.839742   4.827736\n",
            "9   8.493627   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Predicted total rebounds for the player's next game: 8.94\n"
          ]
        }
      ]
    }
  ]
}