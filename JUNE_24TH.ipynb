{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoWZHNK2lov24b+bdo1w+n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starlingomez/preworkmac/blob/master/JUNE_24TH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zAiQC5yAKP4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TANNER BIBE"
      ],
      "metadata": {
        "id": "Lte1jW4DKSFx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcbTqLY_KLNz",
        "outputId": "b0fcedcd-49e4-4353-c28b-32c979b1da1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 4s 38ms/step - loss: 32.9706\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 32.1765\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 30.9292\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 29.6763\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 28.5258\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 27.6190\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 25.9959\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 25.3685\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 23.9072\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 22.0894\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 20.1494\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 18.9338\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 17.6178\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 15.8456\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 13.9386\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 11.6557\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 10.4502\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 8.8844\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 7.9438\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 6.7530\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 4.5695\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 4.5187\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 4.3766\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 5.1144\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 2.7496\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.8283\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 3.1885\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 4.6867\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 4.1515\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 4.5789\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 2.7827\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.9770\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.8587\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 3.0032\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.4945\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.1380\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 2.4317\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 1.6264\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 3.6759\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 2.9477\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 1.8909\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.4705\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 2.0856\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 2.6062\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.8427\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 2.5757\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 1.4196\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 2.0070\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.1536\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.7979\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 1.5258\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.6581\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 2.5790\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.0260\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.9648\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 2.0554\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.1021\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 2.0178\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.0353\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 1.9957\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 2.0986\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 2.3063\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 1.3886\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.7479\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.7389\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0784\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.6030\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.3601\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.1969\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.3027\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 2.0644\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 1.1196\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 1.1604\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.7871\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.7136\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1.2202\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 1.1064\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.9478\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.8511\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6235\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.2288\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.4776\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.9218\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.2256\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.4281\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.3936\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.2657\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.7352\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.9195\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0923\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.3011\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.3668\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.9206\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.0211\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.0753\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.2632\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.8168\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5022\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.0547\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.4820\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8553\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.9468\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.3585\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 1.5578\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.9063\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.6883\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.0218\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.2976\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.8121\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.3851\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.6085\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.4395\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.8836\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8922\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.6037\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.4012\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5827\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.5744\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7041\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.7584\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.5629\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.6310\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8926\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.7814\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.8911\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.2936\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.4983\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.5948\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.5631\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.4941\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.4259\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.4103\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3858\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6414\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.3007\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.6343\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.8227\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.6092\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.4776\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.2687\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.2306\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3741\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 1.1752\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.9838\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3374\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.7704\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.4665\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.9776\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.2277\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.9785\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.9250\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.3684\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2891\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5549\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.3190\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.3154\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.3757\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.3549\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.5850\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.3262\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6491\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.3473\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.7450\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.4529\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.8904\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9297\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7096\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4225\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.8329\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6473\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.3578\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.3019\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.5996\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6396\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8888\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6925\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.7344\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.5376\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6956\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5581\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1823\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4215\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4992\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6474\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.5395\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.4403\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6281\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8917\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7355\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6998\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4298\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6018\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.2562\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.6618\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5571\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1405\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2402\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4255\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.8578\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.4452\n",
            "1/1 [==============================] - 0s 455ms/step\n",
            "Mean Squared Error: 0.3180912631000865\n",
            "R-squared: -4.089460209601384\n",
            "Predicted strikeouts: [5.305146 6.891613]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Organize the data into a DataFrame\n",
        "data = {\n",
        "    'innings_pitched': [6.5, 4.15, 3.05, 5.05, 6, 5.55, 5.15, 5.1, 5.5, 6.5],\n",
        "    'total_batter_faced': [24.5, 19.5, 19.5, 20, 24, 26, 23, 22.5, 22, 22.5],\n",
        "    'opponent_strikeout_rate': [0.3465, 0.3175, 0.1795, 0.3025, 0.2505, 0.231, 0.175, 0.25, 0.2775, 0.2695],\n",
        "    'strikeouts': [8, 6.5, 4, 6, 6, 6, 4, 5.5, 6, 6]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the independent variables and the dependent variable\n",
        "X = df[['innings_pitched', 'total_batter_faced', 'opponent_strikeout_rate']].values\n",
        "y = df['strikeouts'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model with a modified learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=200, batch_size=4, verbose=1)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Output the model's predictions\n",
        "print(\"Predicted strikeouts:\", y_pred.flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A NOLA"
      ],
      "metadata": {
        "id": "aUl1VtVDKj2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Organize the data into a DataFrame\n",
        "data = {\n",
        "    'innings_pitched': [3.6, 6, 6.05, 4.1, 4.1, 3.6, 6.5, 5.5, 5.55, 4.5],\n",
        "    'total_batter_faced': [18.5, 23, 26.5, 21.5, 23, 21, 24.5, 21, 26.5, 22.5],\n",
        "    'opponent_strikeout_rate': [0.136, 0.195, 0.127, 0.2305, 0.0415, 0.196, 0.25, 0.149, 0.208, 0.1345],\n",
        "    'strikeouts': [2.5, 4.5, 3.5, 5, 1, 4.5, 6, 3, 5.5, 3]\n",
        "}\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the independent variables and the dependent variable\n",
        "X = df[['innings_pitched', 'total_batter_faced', 'opponent_strikeout_rate']].values\n",
        "y = df['strikeouts'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model with a modified learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=200, batch_size=4, verbose=1)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Output the model's predictions\n",
        "print(\"Predicted strikeouts:\", y_pred.flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lHFCVRhtKmpn",
        "outputId": "1805c2af-3410-4ee7-987c-0b333e2c2e08"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 2s 24ms/step - loss: 16.0228\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 14.8885\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.7049\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 13.6505\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.4681\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 13.3132\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 12.6382\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 11.8574\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 11.7921\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 11.2471\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 10.7646\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 10.1528\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 9.3663\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 8.5607\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 8.4295\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 7.6784\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 6.7429\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 7.5112\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 6.2711\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 5.2552\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 5.1354\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 5.3664\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 3.0586\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 3.9011\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 3.4868\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.5320\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.7124\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.6809\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.3429\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8580\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.6651\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.3736\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1979\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6640\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.2350\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9815\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7585\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6764\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6848\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.1065\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6650\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4667\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9532\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.2164\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2007\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7596\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7577\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.9820\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.3189\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.1983\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.7974\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8970\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4365\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.5263\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.8530\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.4895\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.1608\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6694\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9110\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9793\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.8582\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9112\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.1848\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6447\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.7496\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6510\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.0730\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.5376\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4683\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6924\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.7607\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.7554\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.3444\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.9085\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.5524\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.0216\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.4617\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6370\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4929\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7913\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0488\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3654\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7701\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0170\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5013\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2851\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9400\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3242\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4292\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7896\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8201\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6565\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4223\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7497\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6297\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9142\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4500\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3511\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4336\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4916\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3454\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3644\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3724\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4535\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4568\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5260\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2950\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4360\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5500\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4788\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3426\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3288\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3952\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4004\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7964\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3130\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3123\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5270\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7006\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5253\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4417\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3646\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7858\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4188\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4018\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2705\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3123\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7840\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7825\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5043\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2339\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2262\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2736\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2792\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3266\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3100\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3640\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3367\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2221\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5237\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5833\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4484\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3261\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5600\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3356\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4614\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6022\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4191\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5797\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1060\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3332\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3086\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1668\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2172\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4093\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6345\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1644\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3192\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2229\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2615\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3629\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3220\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3040\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1424\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3704\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1882\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2366\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4511\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3397\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1364\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3906\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1815\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2165\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4685\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5549\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2762\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2723\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3284\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5140\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2500\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1882\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1350\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2693\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2919\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4977\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3305\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3666\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2704\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3471\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1283\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1301\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0980\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4681\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1086\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3524\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3667\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3335\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3783\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1865\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5187\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "Mean Squared Error: 0.2672221512759734\n",
            "R-squared: -0.0688886051038935\n",
            "Predicted strikeouts: [4.8969665 4.0867267]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "B FALTER"
      ],
      "metadata": {
        "id": "liyZFQKVO16U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Organize the data into a DataFrame\n",
        "data = {\n",
        "    'innings_pitched': [5.55, 5.05, 5.5, 6.5, 6.55, 6.6, 3.1, 5.1, 5.05, 6.05],\n",
        "    'total_batter_faced': [23, 23.5, 23.5, 23.5, 26, 24.5, 14, 25.5, 21, 23.5],\n",
        "    'opponent_strikeout_rate': [0.1825, 0.2545, 0.2765, 0.1765, 0.2175, 0.169, 0.02, 0.172, 0.381, 0.251],\n",
        "    'strikeouts': [4, 6, 6.5, 4, 5.5, 4, 0.5, 4.5, 8, 6]\n",
        "}\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the independent variables and the dependent variable\n",
        "X = df[['innings_pitched', 'total_batter_faced', 'opponent_strikeout_rate']].values\n",
        "y = df['strikeouts'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model with a modified learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=200, batch_size=4, verbose=1)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Output the model's predictions\n",
        "print(\"Predicted strikeouts:\", y_pred.flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNRF2H_oO3JD",
        "outputId": "478153b8-db80-4b5e-cef5-776a5b0a675e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 2s 9ms/step - loss: 22.2985\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 21.3474\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 20.6966\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 20.7167\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 20.1384\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 19.3081\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 18.5556\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 18.2315\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 17.6253\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 16.5890\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 15.8396\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 14.6260\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.0771\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.9509\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 13.6159\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.0458\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 9.8884\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.5569\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.8805\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 6.3009\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 6.5940\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 3.7275\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 3.4997\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 3.1794\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.3935\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.4432\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2444\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.4239\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.9192\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 2.6839\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.4065\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0553\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.8368\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6593\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.3869\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7499\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.0005\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9008\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4711\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9015\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5701\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7685\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7693\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7688\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5694\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9482\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6868\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7802\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4520\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9003\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.5718\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8713\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0289\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.2608\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4488\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.5848\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4125\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6480\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9238\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1824\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7547\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.2985\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8751\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3606\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8272\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.4839\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.7982\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7134\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4713\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3164\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6120\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4420\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1153\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3855\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3103\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7563\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5333\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3187\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2856\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8513\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3314\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8979\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5997\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4384\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3672\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3881\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7114\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6608\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.3286\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5599\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5598\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1786\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4470\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3023\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7451\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5923\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4717\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3117\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6216\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7710\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3959\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3771\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5931\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3482\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3999\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.1197\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4897\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2413\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4612\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2149\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5286\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2891\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7643\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2424\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8924\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8130\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0701\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3162\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6156\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4126\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7023\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.0107\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.1996\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2623\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4024\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0098\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3985\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4144\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3939\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2058\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5602\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1356\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3106\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3451\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2106\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.1340\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3788\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5080\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3849\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.1239\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.0864\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1343\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5234\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2897\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0546\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4463\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.3061\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.4239\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3240\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.4239\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.5577\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.2300\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.4234\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.1213\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5845\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3321\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.2854\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.5131\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.7479\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1626\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.2984\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4950\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2952\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4956\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3470\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.1649\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1054\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2050\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5650\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3257\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2096\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3237\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2533\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4564\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1960\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1897\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3004\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1125\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4775\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2716\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2206\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1443\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2542\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1826\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4845\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3142\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4495\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2969\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0913\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0719\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2290\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4599\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1645\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3421\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3349\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0686\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4949\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0214\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7138\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2666\n",
            "1/1 [==============================] - 0s 178ms/step\n",
            "Mean Squared Error: 0.9066731689537164\n",
            "R-squared: 0.09332683104628359\n",
            "Predicted strikeouts: [9.326473 5.768019]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TANNER HOUCK"
      ],
      "metadata": {
        "id": "eM6mmU_WPZ_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Organize the data into a DataFrame\n",
        "data = {\n",
        "    'innings_pitched': [5.2, 6, 6.5, 6.1, 6.5, 5.5, 5.1, 6, 6, 4.7],\n",
        "    'total_batter_faced': [24, 24, 26.5, 27, 27.5, 21, 25, 23.5, 23, 22],\n",
        "    'opponent_strikeout_rate': [0.187, 0.259, 0.287, 0.203, 0.2035, 0.2135, 0.176, 0.1505, 0.196, 0.2855],\n",
        "    'strikeouts': [4.5, 6, 7.5, 5.5, 5.5, 4.5, 4.5, 3.5, 4.5, 6.5]\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the independent variables and the dependent variable\n",
        "X = df[['innings_pitched', 'total_batter_faced', 'opponent_strikeout_rate']].values\n",
        "y = df['strikeouts'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model with a modified learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=200, batch_size=4, verbose=1)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Output the model's predictions\n",
        "print(\"Predicted strikeouts:\", y_pred.flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50NI7z-CPbz7",
        "outputId": "0366d330-6ce8-4587-e049-8e65ff21ed56"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 1s 18ms/step - loss: 29.0137\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 27.3247\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 27.2089\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 25.8808\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 25.3897\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 24.8471\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 23.1004\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 22.7143\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 21.2684\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 20.7014\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 18.1987\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 16.5871\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 17.5648\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 16.6774\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 15.3115\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12.2449\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.7520\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.6026\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 7.7853\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.9355\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5.9518\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.8764\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.3904\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.4338\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.9131\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.4542\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5727\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4351\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.6416\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.2336\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.9721\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 3.6390\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.7729\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.4906\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6953\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4824\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.7468\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.7542\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 2.5232\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8936\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4334\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.8098\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.9786\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5435\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.2119\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.2082\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.2032\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.0837\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5291\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.8139\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.9642\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.0626\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.8953\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6740\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5821\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3211\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.8690\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.8866\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.1383\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2322\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3508\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6400\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8249\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9661\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3352\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6144\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4522\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7571\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1252\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4642\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8927\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8797\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2027\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7012\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7363\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6518\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7344\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5010\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6727\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3618\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9691\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4128\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3366\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3509\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6959\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6373\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.9939\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.8183\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8996\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5049\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5007\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6599\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9397\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4117\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6726\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6388\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5585\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7200\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6399\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4993\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5713\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1399\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5693\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4581\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6842\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7668\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3755\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2777\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0728\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5236\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0058\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6001\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2773\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9806\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5885\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.4783\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5778\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.7991\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6908\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7237\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5066\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6036\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6823\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4174\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4122\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6666\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5033\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4665\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3325\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3613\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4744\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3441\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1402\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2087\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4400\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7393\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2117\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7090\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0720\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7048\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9019\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2298\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8993\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4978\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8621\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4191\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2683\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4020\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2804\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.8571\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5305\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3392\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2686\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3709\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3243\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4142\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6878\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2473\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6875\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.5271\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5795\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1864\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0940\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5507\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6616\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5462\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5654\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0438\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4795\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4624\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6963\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5360\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5543\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2388\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8229\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4341\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1316\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3879\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4112\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.8332\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1747\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4012\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3580\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.1379\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4739\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5219\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3096\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2565\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4110\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4991\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.2203\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6022\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7965\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5702\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6184\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2345\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3456\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5584\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4995\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7242\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "Mean Squared Error: 4.855150060175276\n",
            "R-squared: -7.631377884756047\n",
            "Predicted strikeouts: [2.3453634 3.7488134]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LANCE LYNN"
      ],
      "metadata": {
        "id": "wr_A_T_wS40F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Organize the data into a DataFrame\n",
        "data = {\n",
        "    'innings_pitched': [5.65, 3.65, 4, 4, 6, 5.6, 4.6, 3.1, 5.1, 5.5],\n",
        "    'total_batter_faced': [25.5, 22, 21.5, 19, 23.5, 23.5, 23, 18, 25, 23],\n",
        "    'opponent_strikeout_rate': [0.2175, 0.1875, 0.302, 0.1835, 0.282, 0.2535, 0.195, 0.1875, 0.234, 0.193],\n",
        "    'strikeouts': [5.5, 4, 6.5, 3.5, 6.5, 6, 4.5, 3.5, 6, 4.5]\n",
        "}\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the independent variables and the dependent variable\n",
        "X = df[['innings_pitched', 'total_batter_faced', 'opponent_strikeout_rate']].values\n",
        "y = df['strikeouts'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model with a modified learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=200, batch_size=4, verbose=1)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Output the model's predictions\n",
        "print(\"Predicted strikeouts:\", y_pred.flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDsgZC86Tr_C",
        "outputId": "869b6cc1-7ebe-44ce-cbe5-d74cf94fbd21"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 2s 12ms/step - loss: 26.1442\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 24.2714\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 23.9807\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 23.6134\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 22.0934\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 21.7962\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 20.0631\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 19.4939\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 17.4608\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.1071\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 16.4477\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.1193\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.5599\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.6172\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.0555\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.1625\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.6758\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.5331\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 6.2330\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.9828\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 4.4175\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.7941\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.3657\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7069\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0302\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.4086\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6732\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.1489\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.1138\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5072\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.2772\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.0143\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0096\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7289\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2416\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5288\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8931\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4025\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6486\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1982\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2536\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3839\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.2911\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8965\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7883\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0550\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4195\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2786\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9236\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4221\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6891\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6577\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0493\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6641\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9217\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3094\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5955\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5667\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5188\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.5356\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3741\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1829\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9056\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7328\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8454\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4694\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.9104\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4982\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.8394\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.2128\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.6847\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.3044\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.4808\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.1166\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.3962\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.4465\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.8567\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2707\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6566\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5129\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7095\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.1014\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.4848\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.1032\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5308\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5116\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6682\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4615\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5125\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4577\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5162\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0660\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8781\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8982\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4509\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.7730\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4771\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4274\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.5237\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.2922\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3592\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6438\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3169\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5934\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0370\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.2399\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5974\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8767\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4833\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6931\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6113\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5312\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6252\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8052\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0305\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3856\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.9543\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5077\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4770\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.8521\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8518\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4321\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4660\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4424\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1937\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3619\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6955\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9557\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6660\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5893\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2848\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0011\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7958\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6364\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4523\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5437\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7551\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.5347\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2661\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2315\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2441\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9511\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6159\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6142\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3381\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6699\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.9710\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4723\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5214\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.2717\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.3945\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4955\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6394\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5110\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4518\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1573\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.3467\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5051\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2603\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0912\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2855\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3019\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3904\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2988\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8134\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4425\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3024\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2338\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.2907\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4992\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4732\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3643\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3023\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3768\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3962\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0724\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3267\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2236\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5401\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9259\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3506\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7811\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8521\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3030\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4698\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4599\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5694\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4668\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1147\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5090\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2184\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2932\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2390\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6872\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3316\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3687\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2525\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0270\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3088\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7aded625cee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 98ms/step\n",
            "Mean Squared Error: 0.787166347468883\n",
            "R-squared: 0.21283365253111697\n",
            "Predicted strikeouts: [4.7487354 4.093111 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GARRET CROCHET"
      ],
      "metadata": {
        "id": "-yvEmFkTVgDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Organize the data into a DataFrame\n",
        "data = {\n",
        "    'innings_pitched': [4.55, 4.55, 5, 5.5, 6.1, 5.5, 5.5, 6, 6.5, 6],\n",
        "    'total_batter_faced': [22.5, 17.5, 23.5, 25, 24, 23.5, 22.5, 24, 23.5, 21.5],\n",
        "    'opponent_strikeout_rate': [0.176, 0.31, 0.252, 0.28, 0.3075, 0.1525, 0.2265, 0.319, 0.22, 0.2345],\n",
        "    'strikeouts': [4.5, 7, 6, 7, 7, 3.5, 5, 7.5, 5, 4.5]\n",
        "}\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the independent variables and the dependent variable\n",
        "X = df[['innings_pitched', 'total_batter_faced', 'opponent_strikeout_rate']].values\n",
        "y = df['strikeouts'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model with a modified learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=200, batch_size=4, verbose=1)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Output the model's predictions\n",
        "print(\"Predicted strikeouts:\", y_pred.flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka2yE7P0Vj8E",
        "outputId": "d5d3c75a-7595-4516-c04b-b7f3aa6afff3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 1s 10ms/step - loss: 33.4223\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 32.7867\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 32.0586\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 30.9871\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 31.7534\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 29.6849\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 29.2237\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 28.1822\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 27.3463\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 26.0998\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 24.7491\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 22.9248\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 21.7783\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 20.5859\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 19.5799\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 17.0558\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 15.4641\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.3721\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 13.4705\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.5439\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.1457\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.1140\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.3769\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.7890\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 3.8403\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.3627\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.9306\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 4.1984\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 2.1584\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.2185\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 2.2435\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 2.5691\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 2.2005\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.9410\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.7072\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.9119\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.2773\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5746\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.2613\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8633\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.5861\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.6334\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.4875\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.7482\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.1296\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.6079\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2607\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.5422\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1949\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8675\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.4675\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.5302\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2749\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.1108\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.2339\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5782\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.4564\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0012\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.9675\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9870\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9865\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.8008\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4580\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.6346\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.2512\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9588\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.5229\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.0392\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.6280\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.7554\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6726\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.0374\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5830\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.8398\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.7316\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.3087\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.5042\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.4597\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.7583\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.7190\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8817\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5106\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8785\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7315\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.2056\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.3956\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.4814\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7036\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7005\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2947\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8578\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8243\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6857\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9939\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5780\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7806\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.4028\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.7574\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3795\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1079\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.3130\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0705\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.2518\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7738\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4840\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7372\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.1975\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8532\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.0740\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8790\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6721\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7005\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.8071\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6386\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6750\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7427\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4712\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7459\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5838\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6183\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7476\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3912\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3169\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1897\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9480\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4047\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.8893\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8682\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.4997\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3444\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1789\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9093\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6392\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2966\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8449\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7737\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1482\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2754\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3343\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6321\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.2575\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6346\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2883\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7064\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5336\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9515\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.2780\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6048\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4192\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5163\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5585\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2710\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.8823\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2794\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3398\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4326\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5873\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5185\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4863\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9339\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9161\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3095\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4584\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4195\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3367\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5607\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5129\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9217\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2236\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0452\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9458\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4558\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4092\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5459\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6335\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6693\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3958\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4579\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9644\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8520\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9299\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4189\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3233\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4036\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3197\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2856\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3422\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3339\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4931\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2786\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4692\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.2268\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4036\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.5760\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.9334\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.4830\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.7297\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.7502\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5964\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7aded625eef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 160ms/step\n",
            "Mean Squared Error: 27.86379184570808\n",
            "R-squared: -26.86379184570808\n",
            "Predicted strikeouts: [ 5.328342 14.457867]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "COLE RAGAN"
      ],
      "metadata": {
        "id": "wyYy9fjCyMRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Organize the data into a DataFrame\n",
        "data = {\n",
        "    'innings_pitched': [5, 7.5, 6.5, 4.6, 5.05, 6.6, 6.5, 6.05, 6.5, 6.1],\n",
        "    'total_batter_faced': [22, 27, 23.5, 19, 25.5, 25, 24, 23.5, 25, 26],\n",
        "    'opponent_strikeout_rate': [0.218, 0.184, 0.3045, 0.1605, 0.2385, 0.335, 0.232, 0.3955, 0.3605, 0.2115],\n",
        "    'strikeouts': [5, 5, 7, 3.5, 6, 8, 5.5, 8, 9, 5.5]\n",
        "}\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the independent variables and the dependent variable\n",
        "X = df[['innings_pitched', 'total_batter_faced', 'opponent_strikeout_rate']].values\n",
        "y = df['strikeouts'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model with a modified learning rate\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=200, batch_size=4, verbose=1)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Output the model's predictions\n",
        "print(\"Predicted strikeouts:\", y_pred.flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p116_uC0yN6D",
        "outputId": "956c0ada-4a30-4e2b-cbb9-4e1fd1730a6c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 1s 10ms/step - loss: 40.3854\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 38.6682\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 38.1640\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 36.5703\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 36.1589\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 35.3393\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 33.7509\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 31.6755\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 31.5206\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 30.0880\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 27.9783\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 25.7647\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 24.3611\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 22.9906\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 20.5186\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 20.6490\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 19.2873\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.6767\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 13.4601\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.1215\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.7599\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.7644\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.0051\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.2804\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5.6221\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.2097\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.7446\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.5801\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.3187\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 5.0284\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.9167\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.1499\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.6651\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.1126\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2844\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3137\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.7803\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.4621\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.9193\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 3.1366\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.5055\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.1591\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.7132\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.9117\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2256\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.4043\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.3728\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.2638\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.9611\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8425\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9662\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.8682\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0876\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1591\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1252\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.6783\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6289\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6456\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1915\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6781\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.1594\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6706\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.4158\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.1779\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6131\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2865\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1681\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9619\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3181\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 2.6346\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.6542\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6031\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.7637\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9798\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.2160\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.6341\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9506\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8967\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7866\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.2300\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5227\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8200\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5201\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9543\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3781\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1590\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1471\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7765\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6934\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9423\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9367\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0375\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.6883\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3861\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.6455\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5509\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5237\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8475\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7091\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.7507\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.8563\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6812\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6314\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.2114\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.2664\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1709\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5830\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1358\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.2379\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.2526\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6489\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7279\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6729\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3227\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.4173\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6989\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7616\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6708\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5856\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4390\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.9140\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9616\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.8910\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6588\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5295\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9234\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2154\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.9591\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9821\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8081\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.7648\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6205\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7268\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.2769\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8600\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9314\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9328\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0252\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7637\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6386\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7544\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1461\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8592\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6745\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4921\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7912\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9179\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7639\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.1020\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.7155\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.3050\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3999\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5441\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1436\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3823\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5435\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4839\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.9241\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.4549\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2838\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5399\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6688\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6728\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0691\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7578\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3118\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3333\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0232\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4933\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4036\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6615\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1360\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1592\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3445\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.5169\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.8437\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5901\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7032\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3416\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0167\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9613\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.9178\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5788\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5032\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6910\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4822\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9048\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1364\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6714\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5585\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1548\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9172\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4458\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6805\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3247\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6192\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5223\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6586\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0216\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7288\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "Mean Squared Error: 9.813367748631663\n",
            "R-squared: -1.4533419371579157\n",
            "Predicted strikeouts: [8.149275 9.347758]\n"
          ]
        }
      ]
    }
  ]
}