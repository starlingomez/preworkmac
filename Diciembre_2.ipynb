{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5aJantYvwEJmIN2Eb08TB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starlingomez/preworkmac/blob/master/Diciembre_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3P3DfA0ZO1a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#clint capela"
      ],
      "metadata": {
        "id": "dJuJf0SLaRCD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QgxU-BQoaU0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [10.4], # Changed to list\n",
        "    'avg_min_last5': [22.6], # Changed to list\n",
        "    'opp_avg_reb_allowed': [46.2], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [4], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24fb945f-7d4e-4f16-edc8-2a5d36294f44",
        "id": "AeyXWL2BCGCJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - loss: 76.1969 - mae: 8.2059 - val_loss: 65.1779 - val_mae: 7.5928\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 50.5564 - mae: 6.4846 - val_loss: 36.0507 - val_mae: 5.3637\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 24.4454 - mae: 4.2142 - val_loss: 13.2683 - val_mae: 3.0964\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5996 - mae: 2.5357 - val_loss: 5.5043 - val_mae: 1.8647\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.1064 - mae: 1.9727 - val_loss: 4.4297 - val_mae: 1.5854\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8665 - mae: 1.9454 - val_loss: 4.2782 - val_mae: 1.5376\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0784 - mae: 1.7844 - val_loss: 4.3062 - val_mae: 1.5632\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1311 - mae: 1.8052 - val_loss: 4.2116 - val_mae: 1.5377\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7863 - mae: 1.7501 - val_loss: 4.1797 - val_mae: 1.5395\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2162 - mae: 1.7827 - val_loss: 4.1377 - val_mae: 1.5251\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1286 - mae: 1.8159 - val_loss: 4.1827 - val_mae: 1.5541\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6835 - mae: 1.7118 - val_loss: 4.1069 - val_mae: 1.5309\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9932 - mae: 1.7782 - val_loss: 4.0929 - val_mae: 1.5375\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7174 - mae: 1.7186 - val_loss: 4.0649 - val_mae: 1.5275\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6419 - mae: 1.7297 - val_loss: 4.0621 - val_mae: 1.5322\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5488 - mae: 1.7027 - val_loss: 4.0075 - val_mae: 1.5182\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5598 - mae: 1.6774 - val_loss: 3.9453 - val_mae: 1.5009\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6077 - mae: 1.7156 - val_loss: 3.9781 - val_mae: 1.5132\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7395 - mae: 1.7421 - val_loss: 4.0159 - val_mae: 1.5343\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5724 - mae: 1.6912 - val_loss: 3.9456 - val_mae: 1.5084\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1711 - mae: 1.6347 - val_loss: 3.9504 - val_mae: 1.5087\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5466 - mae: 1.6751 - val_loss: 3.9426 - val_mae: 1.5108\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1036 - mae: 1.6023 - val_loss: 3.9745 - val_mae: 1.5236\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3968 - mae: 1.6723 - val_loss: 3.9434 - val_mae: 1.5188\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2895 - mae: 1.6012 - val_loss: 3.9570 - val_mae: 1.5240\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3049 - mae: 1.6389 - val_loss: 3.9787 - val_mae: 1.5323\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3767 - mae: 1.6270 - val_loss: 3.9847 - val_mae: 1.5374\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1270 - mae: 1.6080 - val_loss: 3.9036 - val_mae: 1.5016\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2925 - mae: 1.6338 - val_loss: 3.9947 - val_mae: 1.5477\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1875 - mae: 1.5901 - val_loss: 3.9061 - val_mae: 1.5149\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2858 - mae: 1.6251 - val_loss: 3.8772 - val_mae: 1.5020\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7512 - mae: 1.5334 - val_loss: 3.9229 - val_mae: 1.5224\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0298 - mae: 1.6130 - val_loss: 3.8698 - val_mae: 1.5092\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0231 - mae: 1.6023 - val_loss: 3.8470 - val_mae: 1.5059\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8399 - mae: 1.5356 - val_loss: 3.9653 - val_mae: 1.5384\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0174 - mae: 1.5758 - val_loss: 3.8751 - val_mae: 1.5075\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1699 - mae: 1.6191 - val_loss: 3.8771 - val_mae: 1.5147\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9877 - mae: 1.5860 - val_loss: 3.9945 - val_mae: 1.5489\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4281 - mae: 1.6840 - val_loss: 3.8691 - val_mae: 1.5126\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5290 - mae: 1.4928 - val_loss: 4.0392 - val_mae: 1.5556\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7310 - mae: 1.5396 - val_loss: 3.8773 - val_mae: 1.5126\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8403 - mae: 1.5370 - val_loss: 3.8990 - val_mae: 1.5100\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7400 - mae: 1.5127 - val_loss: 3.9150 - val_mae: 1.5222\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9824 - mae: 1.5983 - val_loss: 4.0399 - val_mae: 1.5589\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8349 - mae: 1.5570 - val_loss: 3.8453 - val_mae: 1.4972\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6129 - mae: 1.5211 - val_loss: 3.9362 - val_mae: 1.5369\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0251 - mae: 1.6016 - val_loss: 3.9492 - val_mae: 1.5354\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7103 - mae: 1.5319 - val_loss: 3.9946 - val_mae: 1.5407\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6226 - mae: 1.5223 - val_loss: 3.9057 - val_mae: 1.5241\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2252 - mae: 1.5962 - val_loss: 4.0455 - val_mae: 1.5619\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6680 - mae: 1.5212 - val_loss: 3.8468 - val_mae: 1.4981\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0709 - mae: 1.5912 - val_loss: 3.8487 - val_mae: 1.4993\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8304 - mae: 1.5465 - val_loss: 3.9783 - val_mae: 1.5434\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0239 - mae: 1.6069 - val_loss: 3.9534 - val_mae: 1.5231\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8853 - mae: 1.5719 - val_loss: 3.8838 - val_mae: 1.5139\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8275 - mae: 1.5187 - val_loss: 3.8483 - val_mae: 1.5076\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7418 - mae: 1.5251 - val_loss: 3.8351 - val_mae: 1.5024\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8723 - mae: 1.5639 - val_loss: 3.9515 - val_mae: 1.5333\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8161 - mae: 1.5376 - val_loss: 3.9290 - val_mae: 1.5221\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2844 - mae: 1.6441 - val_loss: 3.8634 - val_mae: 1.5087\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7335 - mae: 1.5215 - val_loss: 3.8815 - val_mae: 1.5075\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6910 - mae: 1.5201 - val_loss: 3.9662 - val_mae: 1.5343\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8696 - mae: 1.5347 - val_loss: 3.8412 - val_mae: 1.4949\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7541 - mae: 1.5128 - val_loss: 4.0916 - val_mae: 1.5749\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6444 - mae: 1.5093 - val_loss: 3.8114 - val_mae: 1.4951\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5803 - mae: 1.4915 - val_loss: 3.9635 - val_mae: 1.5300\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8377 - mae: 1.5695 - val_loss: 3.9500 - val_mae: 1.5361\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5550 - mae: 1.4699 - val_loss: 3.8763 - val_mae: 1.5035\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7899 - mae: 1.5375 - val_loss: 3.8846 - val_mae: 1.5059\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0106 - mae: 1.6049 - val_loss: 3.9030 - val_mae: 1.5134\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9125 - mae: 1.5885 - val_loss: 4.1090 - val_mae: 1.5773\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4983 - mae: 1.4705 - val_loss: 3.9534 - val_mae: 1.5267\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3057 - mae: 1.4365 - val_loss: 3.9918 - val_mae: 1.5398\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4603 - mae: 1.4785 - val_loss: 4.0902 - val_mae: 1.5781\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5457 - mae: 1.4782 - val_loss: 3.8737 - val_mae: 1.4991\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6985 - mae: 1.4867 - val_loss: 4.1477 - val_mae: 1.5800\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9313 - mae: 1.5719 - val_loss: 3.9444 - val_mae: 1.5282\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3544 - mae: 1.4183 - val_loss: 3.9756 - val_mae: 1.5252\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8872 - mae: 1.5487 - val_loss: 4.0692 - val_mae: 1.5600\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9278 - mae: 1.5537 - val_loss: 3.9488 - val_mae: 1.5272\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8022 - mae: 1.5462 - val_loss: 3.9472 - val_mae: 1.5195\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6638 - mae: 1.5136 - val_loss: 4.0614 - val_mae: 1.5568\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3933 - mae: 1.4838 - val_loss: 4.1418 - val_mae: 1.5935\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1715 - mae: 1.4131 - val_loss: 3.9349 - val_mae: 1.5139\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8156 - mae: 1.5671 - val_loss: 4.0559 - val_mae: 1.5650\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6737 - mae: 1.5421 - val_loss: 3.9716 - val_mae: 1.5325\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3993 - mae: 1.4623 - val_loss: 4.0532 - val_mae: 1.5616\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6864 - mae: 1.5222 - val_loss: 4.1122 - val_mae: 1.5724\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5972 - mae: 1.5270 - val_loss: 3.9324 - val_mae: 1.5243\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3657 - mae: 1.4675 - val_loss: 4.0192 - val_mae: 1.5354\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7135 - mae: 1.5532 - val_loss: 4.0836 - val_mae: 1.5542\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8140 - mae: 1.5241 - val_loss: 4.1649 - val_mae: 1.5889\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9525 - mae: 1.5705 - val_loss: 4.0498 - val_mae: 1.5639\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4234 - mae: 1.4774 - val_loss: 4.1574 - val_mae: 1.5945\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8375 - mae: 1.5576 - val_loss: 4.0935 - val_mae: 1.5631\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4289 - mae: 1.4681 - val_loss: 4.0529 - val_mae: 1.5570\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5500 - mae: 1.4921 - val_loss: 4.0416 - val_mae: 1.5580\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6598 - mae: 1.5282 - val_loss: 3.9969 - val_mae: 1.5354\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2151 - mae: 1.4344 - val_loss: 4.0307 - val_mae: 1.5389\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6496 - mae: 1.5114 - val_loss: 4.1385 - val_mae: 1.5790\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1399 - mae: 1.6249 \n",
            "Test MAE (Mean Absolute Error): 1.66\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "   Predicted     Actual\n",
            "0   7.240720   7.494001\n",
            "1  11.571712  12.394215\n",
            "2  10.273617   9.997158\n",
            "3   7.799217   8.965073\n",
            "4   8.349730  11.882369\n",
            "5  11.191674   8.595982\n",
            "6  11.297392  13.475625\n",
            "7   8.548056  11.871617\n",
            "8   6.825089   4.827736\n",
            "9   8.634943   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Predicted total rebounds for the player's next game: 7.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#jalen jonshon"
      ],
      "metadata": {
        "id": "jTy7aRT3bdaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xzao9a8qbfJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [9], # Changed to list\n",
        "    'avg_min_last5': [36.4], # Changed to list\n",
        "    'opp_avg_reb_allowed': [46.2], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [9], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88e18734-60fa-4769-ee62-ad5ea4991014",
        "id": "I2bWaQS2bfYd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 81.0570 - mae: 8.5394 - val_loss: 72.4610 - val_mae: 8.1592\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 57.1126 - mae: 7.0637 - val_loss: 46.8610 - val_mae: 6.4553\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.1989 - mae: 5.2965 - val_loss: 20.9049 - val_mae: 4.1779\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.8800 - mae: 3.1892 - val_loss: 6.6736 - val_mae: 2.1376\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.1147 - mae: 1.9884 - val_loss: 4.2852 - val_mae: 1.5890\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7185 - mae: 1.9088 - val_loss: 4.3576 - val_mae: 1.6318\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3560 - mae: 1.8396 - val_loss: 4.3177 - val_mae: 1.6227\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0514 - mae: 1.7765 - val_loss: 4.3228 - val_mae: 1.6268\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9950 - mae: 1.7539 - val_loss: 4.2582 - val_mae: 1.6137\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7755 - mae: 1.7526 - val_loss: 4.1974 - val_mae: 1.6000\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9517 - mae: 1.7801 - val_loss: 4.1625 - val_mae: 1.5915\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8020 - mae: 1.7403 - val_loss: 4.1413 - val_mae: 1.5893\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0938 - mae: 1.8099 - val_loss: 4.1221 - val_mae: 1.5919\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7557 - mae: 1.7074 - val_loss: 4.1211 - val_mae: 1.5918\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7529 - mae: 1.7463 - val_loss: 4.0456 - val_mae: 1.5626\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3389 - mae: 1.8178 - val_loss: 4.1029 - val_mae: 1.5995\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5322 - mae: 1.7034 - val_loss: 4.0086 - val_mae: 1.5661\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0497 - mae: 1.5853 - val_loss: 4.0234 - val_mae: 1.5703\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3926 - mae: 1.6438 - val_loss: 4.0208 - val_mae: 1.5685\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2246 - mae: 1.6389 - val_loss: 3.9921 - val_mae: 1.5629\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7634 - mae: 1.7275 - val_loss: 4.0211 - val_mae: 1.5737\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5527 - mae: 1.7093 - val_loss: 4.0353 - val_mae: 1.5812\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4108 - mae: 1.6681 - val_loss: 3.9485 - val_mae: 1.5517\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2285 - mae: 1.6325 - val_loss: 3.9640 - val_mae: 1.5550\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1916 - mae: 1.6162 - val_loss: 3.9411 - val_mae: 1.5488\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3014 - mae: 1.6473 - val_loss: 3.8879 - val_mae: 1.5333\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2837 - mae: 1.6437 - val_loss: 3.9463 - val_mae: 1.5570\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0655 - mae: 1.5909 - val_loss: 3.9054 - val_mae: 1.5447\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3106 - mae: 1.6463 - val_loss: 3.8843 - val_mae: 1.5425\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2486 - mae: 1.6512 - val_loss: 3.9142 - val_mae: 1.5522\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2446 - mae: 1.6166 - val_loss: 3.8432 - val_mae: 1.5254\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3276 - mae: 1.6553 - val_loss: 3.8558 - val_mae: 1.5274\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3678 - mae: 1.6549 - val_loss: 3.8307 - val_mae: 1.5212\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2424 - mae: 1.6553 - val_loss: 3.8808 - val_mae: 1.5416\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9423 - mae: 1.5851 - val_loss: 3.8442 - val_mae: 1.5251\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5235 - mae: 1.7157 - val_loss: 3.7839 - val_mae: 1.5076\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1608 - mae: 1.6032 - val_loss: 3.8002 - val_mae: 1.5125\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2450 - mae: 1.6377 - val_loss: 3.7966 - val_mae: 1.5176\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0693 - mae: 1.5727 - val_loss: 3.7675 - val_mae: 1.4999\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2870 - mae: 1.6509 - val_loss: 3.8042 - val_mae: 1.5196\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1828 - mae: 1.6149 - val_loss: 3.7668 - val_mae: 1.5050\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2159 - mae: 1.6067 - val_loss: 3.7176 - val_mae: 1.4826\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9957 - mae: 1.5796 - val_loss: 3.7449 - val_mae: 1.4960\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3040 - mae: 1.6204 - val_loss: 3.7896 - val_mae: 1.5192\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3509 - mae: 1.6509 - val_loss: 3.7945 - val_mae: 1.5217\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1885 - mae: 1.6169 - val_loss: 3.7453 - val_mae: 1.5014\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7763 - mae: 1.5217 - val_loss: 3.7374 - val_mae: 1.5030\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9337 - mae: 1.5915 - val_loss: 3.7543 - val_mae: 1.4980\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9104 - mae: 1.5667 - val_loss: 3.7358 - val_mae: 1.4946\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0961 - mae: 1.5944 - val_loss: 3.7460 - val_mae: 1.5100\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7163 - mae: 1.5485 - val_loss: 3.7240 - val_mae: 1.5032\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9841 - mae: 1.5945 - val_loss: 3.6304 - val_mae: 1.4633\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1018 - mae: 1.6230 - val_loss: 3.7930 - val_mae: 1.5247\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0219 - mae: 1.5912 - val_loss: 3.6279 - val_mae: 1.4682\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0681 - mae: 1.5804 - val_loss: 3.7466 - val_mae: 1.5114\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6583 - mae: 1.5115 - val_loss: 3.6560 - val_mae: 1.4863\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0805 - mae: 1.6067 - val_loss: 3.6499 - val_mae: 1.4762\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7825 - mae: 1.5385 - val_loss: 3.7318 - val_mae: 1.5090\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9419 - mae: 1.5583 - val_loss: 3.5812 - val_mae: 1.4561\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8601 - mae: 1.5446 - val_loss: 3.6960 - val_mae: 1.5022\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6233 - mae: 1.5271 - val_loss: 3.7609 - val_mae: 1.5237\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8430 - mae: 1.5663 - val_loss: 3.5779 - val_mae: 1.4628\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6895 - mae: 1.5409 - val_loss: 3.7213 - val_mae: 1.5121\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7978 - mae: 1.5361 - val_loss: 3.5941 - val_mae: 1.4663\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6331 - mae: 1.4881 - val_loss: 3.6858 - val_mae: 1.4989\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7177 - mae: 1.5151 - val_loss: 3.6454 - val_mae: 1.4858\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7900 - mae: 1.5278 - val_loss: 3.6786 - val_mae: 1.5012\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7668 - mae: 1.5279 - val_loss: 3.6583 - val_mae: 1.4934\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7026 - mae: 1.5237 - val_loss: 3.5764 - val_mae: 1.4657\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8935 - mae: 1.5497 - val_loss: 3.6306 - val_mae: 1.4891\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7172 - mae: 1.5279 - val_loss: 3.6204 - val_mae: 1.4747\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7856 - mae: 1.5347 - val_loss: 3.6570 - val_mae: 1.4896\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5395 - mae: 1.4910 - val_loss: 3.7507 - val_mae: 1.5246\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8428 - mae: 1.5534 - val_loss: 3.6300 - val_mae: 1.4871\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6583 - mae: 1.5012 - val_loss: 3.6838 - val_mae: 1.5045\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6629 - mae: 1.5061 - val_loss: 3.6338 - val_mae: 1.4861\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3364 - mae: 1.4445 - val_loss: 3.7561 - val_mae: 1.5309\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9832 - mae: 1.5880 - val_loss: 3.5748 - val_mae: 1.4625\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8030 - mae: 1.5327 - val_loss: 3.6781 - val_mae: 1.5023\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6867 - mae: 1.5081 - val_loss: 3.6413 - val_mae: 1.4980\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8469 - mae: 1.5450 - val_loss: 3.6196 - val_mae: 1.4768\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6294 - mae: 1.5199 - val_loss: 3.7610 - val_mae: 1.5313\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6827 - mae: 1.4762 - val_loss: 3.6438 - val_mae: 1.4908\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5081 - mae: 1.4692 - val_loss: 3.6573 - val_mae: 1.4806\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2636 - mae: 1.4459 - val_loss: 3.8571 - val_mae: 1.5459\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8854 - mae: 1.5717 - val_loss: 3.6467 - val_mae: 1.4881\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5401 - mae: 1.4808 - val_loss: 3.7781 - val_mae: 1.5221\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7007 - mae: 1.5154 - val_loss: 3.6320 - val_mae: 1.4762\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5067 - mae: 1.4956 - val_loss: 3.7442 - val_mae: 1.5096\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3745 - mae: 1.4500 - val_loss: 3.6329 - val_mae: 1.4798\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3873 - mae: 1.4568 - val_loss: 3.7917 - val_mae: 1.5270\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5796 - mae: 1.4728 - val_loss: 3.7840 - val_mae: 1.5196\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5931 - mae: 1.4982 - val_loss: 3.6795 - val_mae: 1.4927\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7468 - mae: 1.5294 - val_loss: 3.9220 - val_mae: 1.5703\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3972 - mae: 1.4633 - val_loss: 3.7263 - val_mae: 1.5011\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3039 - mae: 1.4186 - val_loss: 3.7520 - val_mae: 1.5071\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5865 - mae: 1.5167 - val_loss: 3.7936 - val_mae: 1.5210\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3534 - mae: 1.4467 - val_loss: 3.7414 - val_mae: 1.5107\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5507 - mae: 1.4670 - val_loss: 3.6742 - val_mae: 1.4871\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6996 - mae: 1.5157 - val_loss: 3.6861 - val_mae: 1.4815\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1929 - mae: 1.6231 \n",
            "Test MAE (Mean Absolute Error): 1.64\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "   Predicted     Actual\n",
            "0   7.418662   7.494001\n",
            "1  11.145714  12.394215\n",
            "2  10.231182   9.997158\n",
            "3   7.558118   8.965073\n",
            "4   7.948621  11.882369\n",
            "5  11.462205   8.595982\n",
            "6  11.016181  13.475625\n",
            "7   8.437012  11.871617\n",
            "8   6.152874   4.827736\n",
            "9   8.151377   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Predicted total rebounds for the player's next game: 10.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qj75ShChPJiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#okongwo"
      ],
      "metadata": {
        "id": "wF0E_GiTb1j1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a16y2uddb6OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [7.2], # Changed to list\n",
        "    'avg_min_last5': [24.5], # Changed to list\n",
        "    'opp_avg_reb_allowed': [46.2], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [9], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88e18734-60fa-4769-ee62-ad5ea4991014",
        "id": "LxpklonIb6bo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 81.0570 - mae: 8.5394 - val_loss: 72.4610 - val_mae: 8.1592\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 57.1126 - mae: 7.0637 - val_loss: 46.8610 - val_mae: 6.4553\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.1989 - mae: 5.2965 - val_loss: 20.9049 - val_mae: 4.1779\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.8800 - mae: 3.1892 - val_loss: 6.6736 - val_mae: 2.1376\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.1147 - mae: 1.9884 - val_loss: 4.2852 - val_mae: 1.5890\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7185 - mae: 1.9088 - val_loss: 4.3576 - val_mae: 1.6318\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3560 - mae: 1.8396 - val_loss: 4.3177 - val_mae: 1.6227\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0514 - mae: 1.7765 - val_loss: 4.3228 - val_mae: 1.6268\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9950 - mae: 1.7539 - val_loss: 4.2582 - val_mae: 1.6137\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7755 - mae: 1.7526 - val_loss: 4.1974 - val_mae: 1.6000\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9517 - mae: 1.7801 - val_loss: 4.1625 - val_mae: 1.5915\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8020 - mae: 1.7403 - val_loss: 4.1413 - val_mae: 1.5893\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0938 - mae: 1.8099 - val_loss: 4.1221 - val_mae: 1.5919\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7557 - mae: 1.7074 - val_loss: 4.1211 - val_mae: 1.5918\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7529 - mae: 1.7463 - val_loss: 4.0456 - val_mae: 1.5626\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3389 - mae: 1.8178 - val_loss: 4.1029 - val_mae: 1.5995\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5322 - mae: 1.7034 - val_loss: 4.0086 - val_mae: 1.5661\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0497 - mae: 1.5853 - val_loss: 4.0234 - val_mae: 1.5703\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3926 - mae: 1.6438 - val_loss: 4.0208 - val_mae: 1.5685\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2246 - mae: 1.6389 - val_loss: 3.9921 - val_mae: 1.5629\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7634 - mae: 1.7275 - val_loss: 4.0211 - val_mae: 1.5737\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5527 - mae: 1.7093 - val_loss: 4.0353 - val_mae: 1.5812\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4108 - mae: 1.6681 - val_loss: 3.9485 - val_mae: 1.5517\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2285 - mae: 1.6325 - val_loss: 3.9640 - val_mae: 1.5550\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1916 - mae: 1.6162 - val_loss: 3.9411 - val_mae: 1.5488\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3014 - mae: 1.6473 - val_loss: 3.8879 - val_mae: 1.5333\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2837 - mae: 1.6437 - val_loss: 3.9463 - val_mae: 1.5570\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0655 - mae: 1.5909 - val_loss: 3.9054 - val_mae: 1.5447\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3106 - mae: 1.6463 - val_loss: 3.8843 - val_mae: 1.5425\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2486 - mae: 1.6512 - val_loss: 3.9142 - val_mae: 1.5522\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2446 - mae: 1.6166 - val_loss: 3.8432 - val_mae: 1.5254\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3276 - mae: 1.6553 - val_loss: 3.8558 - val_mae: 1.5274\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3678 - mae: 1.6549 - val_loss: 3.8307 - val_mae: 1.5212\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2424 - mae: 1.6553 - val_loss: 3.8808 - val_mae: 1.5416\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9423 - mae: 1.5851 - val_loss: 3.8442 - val_mae: 1.5251\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5235 - mae: 1.7157 - val_loss: 3.7839 - val_mae: 1.5076\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1608 - mae: 1.6032 - val_loss: 3.8002 - val_mae: 1.5125\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2450 - mae: 1.6377 - val_loss: 3.7966 - val_mae: 1.5176\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0693 - mae: 1.5727 - val_loss: 3.7675 - val_mae: 1.4999\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2870 - mae: 1.6509 - val_loss: 3.8042 - val_mae: 1.5196\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1828 - mae: 1.6149 - val_loss: 3.7668 - val_mae: 1.5050\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2159 - mae: 1.6067 - val_loss: 3.7176 - val_mae: 1.4826\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9957 - mae: 1.5796 - val_loss: 3.7449 - val_mae: 1.4960\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3040 - mae: 1.6204 - val_loss: 3.7896 - val_mae: 1.5192\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3509 - mae: 1.6509 - val_loss: 3.7945 - val_mae: 1.5217\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1885 - mae: 1.6169 - val_loss: 3.7453 - val_mae: 1.5014\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7763 - mae: 1.5217 - val_loss: 3.7374 - val_mae: 1.5030\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9337 - mae: 1.5915 - val_loss: 3.7543 - val_mae: 1.4980\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9104 - mae: 1.5667 - val_loss: 3.7358 - val_mae: 1.4946\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0961 - mae: 1.5944 - val_loss: 3.7460 - val_mae: 1.5100\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7163 - mae: 1.5485 - val_loss: 3.7240 - val_mae: 1.5032\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9841 - mae: 1.5945 - val_loss: 3.6304 - val_mae: 1.4633\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1018 - mae: 1.6230 - val_loss: 3.7930 - val_mae: 1.5247\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0219 - mae: 1.5912 - val_loss: 3.6279 - val_mae: 1.4682\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0681 - mae: 1.5804 - val_loss: 3.7466 - val_mae: 1.5114\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6583 - mae: 1.5115 - val_loss: 3.6560 - val_mae: 1.4863\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0805 - mae: 1.6067 - val_loss: 3.6499 - val_mae: 1.4762\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7825 - mae: 1.5385 - val_loss: 3.7318 - val_mae: 1.5090\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9419 - mae: 1.5583 - val_loss: 3.5812 - val_mae: 1.4561\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8601 - mae: 1.5446 - val_loss: 3.6960 - val_mae: 1.5022\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6233 - mae: 1.5271 - val_loss: 3.7609 - val_mae: 1.5237\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8430 - mae: 1.5663 - val_loss: 3.5779 - val_mae: 1.4628\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6895 - mae: 1.5409 - val_loss: 3.7213 - val_mae: 1.5121\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7978 - mae: 1.5361 - val_loss: 3.5941 - val_mae: 1.4663\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6331 - mae: 1.4881 - val_loss: 3.6858 - val_mae: 1.4989\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7177 - mae: 1.5151 - val_loss: 3.6454 - val_mae: 1.4858\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7900 - mae: 1.5278 - val_loss: 3.6786 - val_mae: 1.5012\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7668 - mae: 1.5279 - val_loss: 3.6583 - val_mae: 1.4934\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7026 - mae: 1.5237 - val_loss: 3.5764 - val_mae: 1.4657\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8935 - mae: 1.5497 - val_loss: 3.6306 - val_mae: 1.4891\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7172 - mae: 1.5279 - val_loss: 3.6204 - val_mae: 1.4747\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7856 - mae: 1.5347 - val_loss: 3.6570 - val_mae: 1.4896\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5395 - mae: 1.4910 - val_loss: 3.7507 - val_mae: 1.5246\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8428 - mae: 1.5534 - val_loss: 3.6300 - val_mae: 1.4871\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6583 - mae: 1.5012 - val_loss: 3.6838 - val_mae: 1.5045\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6629 - mae: 1.5061 - val_loss: 3.6338 - val_mae: 1.4861\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3364 - mae: 1.4445 - val_loss: 3.7561 - val_mae: 1.5309\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9832 - mae: 1.5880 - val_loss: 3.5748 - val_mae: 1.4625\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8030 - mae: 1.5327 - val_loss: 3.6781 - val_mae: 1.5023\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6867 - mae: 1.5081 - val_loss: 3.6413 - val_mae: 1.4980\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8469 - mae: 1.5450 - val_loss: 3.6196 - val_mae: 1.4768\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6294 - mae: 1.5199 - val_loss: 3.7610 - val_mae: 1.5313\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6827 - mae: 1.4762 - val_loss: 3.6438 - val_mae: 1.4908\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5081 - mae: 1.4692 - val_loss: 3.6573 - val_mae: 1.4806\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2636 - mae: 1.4459 - val_loss: 3.8571 - val_mae: 1.5459\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8854 - mae: 1.5717 - val_loss: 3.6467 - val_mae: 1.4881\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5401 - mae: 1.4808 - val_loss: 3.7781 - val_mae: 1.5221\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7007 - mae: 1.5154 - val_loss: 3.6320 - val_mae: 1.4762\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5067 - mae: 1.4956 - val_loss: 3.7442 - val_mae: 1.5096\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3745 - mae: 1.4500 - val_loss: 3.6329 - val_mae: 1.4798\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3873 - mae: 1.4568 - val_loss: 3.7917 - val_mae: 1.5270\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5796 - mae: 1.4728 - val_loss: 3.7840 - val_mae: 1.5196\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5931 - mae: 1.4982 - val_loss: 3.6795 - val_mae: 1.4927\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7468 - mae: 1.5294 - val_loss: 3.9220 - val_mae: 1.5703\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3972 - mae: 1.4633 - val_loss: 3.7263 - val_mae: 1.5011\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3039 - mae: 1.4186 - val_loss: 3.7520 - val_mae: 1.5071\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5865 - mae: 1.5167 - val_loss: 3.7936 - val_mae: 1.5210\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3534 - mae: 1.4467 - val_loss: 3.7414 - val_mae: 1.5107\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5507 - mae: 1.4670 - val_loss: 3.6742 - val_mae: 1.4871\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6996 - mae: 1.5157 - val_loss: 3.6861 - val_mae: 1.4815\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1929 - mae: 1.6231 \n",
            "Test MAE (Mean Absolute Error): 1.64\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "   Predicted     Actual\n",
            "0   7.418662   7.494001\n",
            "1  11.145714  12.394215\n",
            "2  10.231182   9.997158\n",
            "3   7.558118   8.965073\n",
            "4   7.948621  11.882369\n",
            "5  11.462205   8.595982\n",
            "6  11.016181  13.475625\n",
            "7   8.437012  11.871617\n",
            "8   6.152874   4.827736\n",
            "9   8.151377   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Predicted total rebounds for the player's next game: 10.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#jason tatum"
      ],
      "metadata": {
        "id": "Z7b1VZ1AcXTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HBKmOp8Icnzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [9.6], # Changed to list\n",
        "    'avg_min_last5': [35.9], # Changed to list\n",
        "    'opp_avg_reb_allowed': [46.2], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [8.7], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92c18b74-41ec-4798-dd95-564e6129dae5",
        "id": "uL7Bn157coLK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 75.7025 - mae: 8.2387 - val_loss: 65.7218 - val_mae: 7.7019\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 51.6438 - mae: 6.6352 - val_loss: 37.6600 - val_mae: 5.6592\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.5972 - mae: 4.6721 - val_loss: 12.5984 - val_mae: 3.1111\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.4233 - mae: 2.3950 - val_loss: 5.3595 - val_mae: 1.8215\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9803 - mae: 1.7654 - val_loss: 4.8793 - val_mae: 1.6944\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0547 - mae: 1.7727 - val_loss: 4.8524 - val_mae: 1.7171\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8761 - mae: 1.7518 - val_loss: 4.6823 - val_mae: 1.6706\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7200 - mae: 1.7016 - val_loss: 4.6294 - val_mae: 1.6786\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4319 - mae: 1.6752 - val_loss: 4.5067 - val_mae: 1.6485\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6758 - mae: 1.6798 - val_loss: 4.5004 - val_mae: 1.6621\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6160 - mae: 1.7168 - val_loss: 4.4785 - val_mae: 1.6624\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8296 - mae: 1.7425 - val_loss: 4.3954 - val_mae: 1.6369\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7042 - mae: 1.7428 - val_loss: 4.3188 - val_mae: 1.6238\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5399 - mae: 1.6853 - val_loss: 4.2747 - val_mae: 1.6182\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7607 - mae: 1.7413 - val_loss: 4.2476 - val_mae: 1.6094\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1176 - mae: 1.5847 - val_loss: 4.2208 - val_mae: 1.6029\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3952 - mae: 1.6621 - val_loss: 4.2095 - val_mae: 1.6144\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3474 - mae: 1.7051 - val_loss: 4.1248 - val_mae: 1.5795\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4744 - mae: 1.6739 - val_loss: 4.1250 - val_mae: 1.5840\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5706 - mae: 1.7110 - val_loss: 4.0790 - val_mae: 1.5789\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5442 - mae: 1.6917 - val_loss: 4.0402 - val_mae: 1.5673\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4448 - mae: 1.6768 - val_loss: 3.9909 - val_mae: 1.5420\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3081 - mae: 1.6578 - val_loss: 4.0649 - val_mae: 1.5759\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8860 - mae: 1.5317 - val_loss: 3.9450 - val_mae: 1.5401\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4989 - mae: 1.6977 - val_loss: 4.0254 - val_mae: 1.5722\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3925 - mae: 1.6703 - val_loss: 4.0162 - val_mae: 1.5667\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0974 - mae: 1.6127 - val_loss: 3.9102 - val_mae: 1.5358\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4793 - mae: 1.6680 - val_loss: 3.9466 - val_mae: 1.5588\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0442 - mae: 1.6000 - val_loss: 3.8705 - val_mae: 1.5196\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2930 - mae: 1.6595 - val_loss: 3.8795 - val_mae: 1.5336\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2585 - mae: 1.6539 - val_loss: 3.8196 - val_mae: 1.5212\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8316 - mae: 1.7425 - val_loss: 3.7957 - val_mae: 1.5005\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1472 - mae: 1.5801 - val_loss: 3.8532 - val_mae: 1.5304\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4709 - mae: 1.6661 - val_loss: 3.8344 - val_mae: 1.5274\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9139 - mae: 1.5764 - val_loss: 3.7325 - val_mae: 1.4930\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0461 - mae: 1.6099 - val_loss: 3.7311 - val_mae: 1.4902\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6634 - mae: 1.5238 - val_loss: 3.7636 - val_mae: 1.5038\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8382 - mae: 1.5565 - val_loss: 3.7313 - val_mae: 1.5004\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5002 - mae: 1.4709 - val_loss: 3.7315 - val_mae: 1.5001\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8301 - mae: 1.5458 - val_loss: 3.7559 - val_mae: 1.5100\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9886 - mae: 1.5966 - val_loss: 3.6784 - val_mae: 1.4752\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7605 - mae: 1.5137 - val_loss: 3.7546 - val_mae: 1.5086\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8074 - mae: 1.5404 - val_loss: 3.7039 - val_mae: 1.4895\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1984 - mae: 1.6314 - val_loss: 3.7102 - val_mae: 1.5060\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8244 - mae: 1.5352 - val_loss: 3.6857 - val_mae: 1.4909\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8247 - mae: 1.5293 - val_loss: 3.6106 - val_mae: 1.4654\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1936 - mae: 1.6200 - val_loss: 3.6738 - val_mae: 1.4946\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9277 - mae: 1.5519 - val_loss: 3.6266 - val_mae: 1.4665\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9410 - mae: 1.5664 - val_loss: 3.6314 - val_mae: 1.4823\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1114 - mae: 1.6307 - val_loss: 3.5635 - val_mae: 1.4385\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0079 - mae: 1.5966 - val_loss: 3.6883 - val_mae: 1.4966\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7107 - mae: 1.5131 - val_loss: 3.6917 - val_mae: 1.5048\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8366 - mae: 1.5524 - val_loss: 3.6083 - val_mae: 1.4777\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5122 - mae: 1.4799 - val_loss: 3.5554 - val_mae: 1.4303\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6688 - mae: 1.5069 - val_loss: 3.7499 - val_mae: 1.5205\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6509 - mae: 1.5101 - val_loss: 3.6036 - val_mae: 1.4719\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7600 - mae: 1.5586 - val_loss: 3.6208 - val_mae: 1.4637\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8654 - mae: 1.5741 - val_loss: 3.5904 - val_mae: 1.4599\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1383 - mae: 1.5998 - val_loss: 3.7532 - val_mae: 1.5306\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6415 - mae: 1.4925 - val_loss: 3.5795 - val_mae: 1.4463\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6806 - mae: 1.5094 - val_loss: 3.6078 - val_mae: 1.4719\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5202 - mae: 1.4870 - val_loss: 3.6812 - val_mae: 1.4892\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5572 - mae: 1.5025 - val_loss: 3.6074 - val_mae: 1.4652\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8184 - mae: 1.5581 - val_loss: 3.6360 - val_mae: 1.4770\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0867 - mae: 1.5884 - val_loss: 3.7310 - val_mae: 1.5081\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7032 - mae: 1.5375 - val_loss: 3.5557 - val_mae: 1.4368\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7309 - mae: 1.5240 - val_loss: 3.6865 - val_mae: 1.4904\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4757 - mae: 1.4778 - val_loss: 3.6676 - val_mae: 1.4832\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4764 - mae: 1.4756 - val_loss: 3.6360 - val_mae: 1.4659\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4376 - mae: 1.4816 - val_loss: 3.7084 - val_mae: 1.5033\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8796 - mae: 1.5543 - val_loss: 3.6406 - val_mae: 1.4694\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7799 - mae: 1.5560 - val_loss: 3.7624 - val_mae: 1.5145\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6027 - mae: 1.5163 - val_loss: 3.6491 - val_mae: 1.4776\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1274 - mae: 1.5884 - val_loss: 3.6316 - val_mae: 1.4664\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5564 - mae: 1.4599 - val_loss: 3.7927 - val_mae: 1.5164\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6248 - mae: 1.4888 - val_loss: 3.6668 - val_mae: 1.4726\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5655 - mae: 1.4839 - val_loss: 3.6688 - val_mae: 1.4887\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2863 - mae: 1.4260 - val_loss: 3.7104 - val_mae: 1.4885\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6222 - mae: 1.5151 - val_loss: 3.6469 - val_mae: 1.4660\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8251 - mae: 1.5477 - val_loss: 3.8446 - val_mae: 1.5414\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8559 - mae: 1.5513 - val_loss: 3.6998 - val_mae: 1.4889\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4547 - mae: 1.4514 - val_loss: 3.6695 - val_mae: 1.4778\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2012 - mae: 1.4193 - val_loss: 3.7585 - val_mae: 1.4952\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6888 - mae: 1.5246 - val_loss: 3.9353 - val_mae: 1.5760\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5738 - mae: 1.5069 - val_loss: 3.6440 - val_mae: 1.4528\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4576 - mae: 1.4720 - val_loss: 3.7845 - val_mae: 1.5167\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4651 - mae: 1.4634 - val_loss: 3.8409 - val_mae: 1.5333\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5605 - mae: 1.4915 - val_loss: 3.8143 - val_mae: 1.5331\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7838 - mae: 1.5329 - val_loss: 3.7939 - val_mae: 1.5223\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4451 - mae: 1.4785 - val_loss: 3.7001 - val_mae: 1.4774\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4981 - mae: 1.4660 - val_loss: 3.6817 - val_mae: 1.4664\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8388 - mae: 1.5410 - val_loss: 3.6986 - val_mae: 1.4693\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5407 - mae: 1.4967 - val_loss: 3.7618 - val_mae: 1.5092\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2312 - mae: 1.3933 - val_loss: 3.7852 - val_mae: 1.5136\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6394 - mae: 1.5127 - val_loss: 3.7401 - val_mae: 1.4996\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4839 - mae: 1.4957 - val_loss: 3.7966 - val_mae: 1.4863\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7221 - mae: 1.5551 - val_loss: 3.7856 - val_mae: 1.5230\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1357 - mae: 1.4091 - val_loss: 3.8114 - val_mae: 1.5223\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5587 - mae: 1.5024 - val_loss: 3.8497 - val_mae: 1.5334\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.1297 - mae: 1.4219 - val_loss: 3.8062 - val_mae: 1.5146\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1891 - mae: 1.6166 \n",
            "Test MAE (Mean Absolute Error): 1.64\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "   Predicted     Actual\n",
            "0   7.422961   7.494001\n",
            "1  11.191973  12.394215\n",
            "2  10.205963   9.997158\n",
            "3   7.358296   8.965073\n",
            "4   7.755096  11.882369\n",
            "5  11.579846   8.595982\n",
            "6  10.631193  13.475625\n",
            "7   8.440374  11.871617\n",
            "8   6.317001   4.827736\n",
            "9   7.996000   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Predicted total rebounds for the player's next game: 10.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EWQqgUvDd_C0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#rudy gobert"
      ],
      "metadata": {
        "id": "PNVPwLIDdwNY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rgj77_eeeDWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [13.2], # Changed to list\n",
        "    'avg_min_last5': [38.7], # Changed to list\n",
        "    'opp_avg_reb_allowed': [43.6], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [14], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d654d126-ddf8-4fcf-efec-a6b717c0c1f6",
        "id": "1IaNBwNOeDj3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 79.7011 - mae: 8.4542 - val_loss: 71.7385 - val_mae: 8.0756\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 57.6003 - mae: 7.0257 - val_loss: 45.5846 - val_mae: 6.2405\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.5841 - mae: 4.9355 - val_loss: 19.3621 - val_mae: 3.8141\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.3503 - mae: 2.7730 - val_loss: 6.6434 - val_mae: 2.0653\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3033 - mae: 2.0017 - val_loss: 4.7252 - val_mae: 1.6731\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3761 - mae: 1.8587 - val_loss: 4.4911 - val_mae: 1.6327\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2952 - mae: 1.8141 - val_loss: 4.4766 - val_mae: 1.6293\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1994 - mae: 1.8091 - val_loss: 4.3743 - val_mae: 1.5943\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8060 - mae: 1.7181 - val_loss: 4.3636 - val_mae: 1.5910\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5492 - mae: 1.6788 - val_loss: 4.3826 - val_mae: 1.6062\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1638 - mae: 1.7791 - val_loss: 4.2642 - val_mae: 1.5758\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4785 - mae: 1.6766 - val_loss: 4.2645 - val_mae: 1.5715\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6510 - mae: 1.7218 - val_loss: 4.2368 - val_mae: 1.5702\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7144 - mae: 1.7346 - val_loss: 4.1887 - val_mae: 1.5718\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8495 - mae: 1.7507 - val_loss: 4.1658 - val_mae: 1.5620\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3872 - mae: 1.6715 - val_loss: 4.1101 - val_mae: 1.5501\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6547 - mae: 1.6950 - val_loss: 4.1595 - val_mae: 1.5786\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5176 - mae: 1.6845 - val_loss: 4.0515 - val_mae: 1.5310\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6285 - mae: 1.7163 - val_loss: 4.1129 - val_mae: 1.5681\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1804 - mae: 1.6223 - val_loss: 4.0007 - val_mae: 1.5292\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4074 - mae: 1.6560 - val_loss: 3.9922 - val_mae: 1.5292\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5804 - mae: 1.6838 - val_loss: 4.0005 - val_mae: 1.5324\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6788 - mae: 1.7105 - val_loss: 3.9408 - val_mae: 1.5126\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5589 - mae: 1.6977 - val_loss: 3.9973 - val_mae: 1.5433\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5240 - mae: 1.6997 - val_loss: 3.9340 - val_mae: 1.5245\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3064 - mae: 1.6449 - val_loss: 3.9044 - val_mae: 1.5085\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2867 - mae: 1.6469 - val_loss: 3.9646 - val_mae: 1.5471\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4097 - mae: 1.6617 - val_loss: 3.9388 - val_mae: 1.5318\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3676 - mae: 1.6747 - val_loss: 3.8654 - val_mae: 1.5130\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8809 - mae: 1.5664 - val_loss: 3.7870 - val_mae: 1.4783\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4107 - mae: 1.6822 - val_loss: 3.8654 - val_mae: 1.5196\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1434 - mae: 1.6227 - val_loss: 3.8138 - val_mae: 1.4959\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3513 - mae: 1.6598 - val_loss: 3.8005 - val_mae: 1.4867\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2848 - mae: 1.6447 - val_loss: 3.9192 - val_mae: 1.5470\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9777 - mae: 1.5864 - val_loss: 3.7735 - val_mae: 1.4848\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1593 - mae: 1.6115 - val_loss: 3.8137 - val_mae: 1.5046\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9114 - mae: 1.5845 - val_loss: 3.7282 - val_mae: 1.4741\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9292 - mae: 1.5798 - val_loss: 3.7364 - val_mae: 1.4736\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9275 - mae: 1.5948 - val_loss: 3.7438 - val_mae: 1.4864\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3968 - mae: 1.6883 - val_loss: 3.7393 - val_mae: 1.4743\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0839 - mae: 1.5982 - val_loss: 3.6493 - val_mae: 1.4529\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2245 - mae: 1.6305 - val_loss: 3.7804 - val_mae: 1.4977\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6781 - mae: 1.5357 - val_loss: 3.6451 - val_mae: 1.4453\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0858 - mae: 1.6110 - val_loss: 3.7109 - val_mae: 1.4805\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2113 - mae: 1.6243 - val_loss: 3.6754 - val_mae: 1.4680\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8377 - mae: 1.5591 - val_loss: 3.7233 - val_mae: 1.4758\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9405 - mae: 1.5674 - val_loss: 3.6451 - val_mae: 1.4557\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9416 - mae: 1.5893 - val_loss: 3.6307 - val_mae: 1.4532\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0170 - mae: 1.5809 - val_loss: 3.7428 - val_mae: 1.4899\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2384 - mae: 1.6259 - val_loss: 3.6784 - val_mae: 1.4657\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0414 - mae: 1.6361 - val_loss: 3.6443 - val_mae: 1.4544\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8962 - mae: 1.5558 - val_loss: 3.7136 - val_mae: 1.4897\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1215 - mae: 1.6034 - val_loss: 3.6190 - val_mae: 1.4490\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8850 - mae: 1.5674 - val_loss: 3.7296 - val_mae: 1.4903\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8536 - mae: 1.5553 - val_loss: 3.6095 - val_mae: 1.4490\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9554 - mae: 1.6042 - val_loss: 3.5720 - val_mae: 1.4358\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4761 - mae: 1.4625 - val_loss: 3.6937 - val_mae: 1.4742\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9839 - mae: 1.5878 - val_loss: 3.6343 - val_mae: 1.4643\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6242 - mae: 1.5044 - val_loss: 3.6612 - val_mae: 1.4627\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5112 - mae: 1.4860 - val_loss: 3.6009 - val_mae: 1.4545\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0821 - mae: 1.6227 - val_loss: 3.5976 - val_mae: 1.4523\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8031 - mae: 1.5307 - val_loss: 3.7151 - val_mae: 1.4829\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9176 - mae: 1.5664 - val_loss: 3.5365 - val_mae: 1.4339\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0260 - mae: 1.5855 - val_loss: 3.6720 - val_mae: 1.4813\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8528 - mae: 1.5514 - val_loss: 3.6187 - val_mae: 1.4678\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7373 - mae: 1.5340 - val_loss: 3.5868 - val_mae: 1.4606\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9276 - mae: 1.5503 - val_loss: 3.5119 - val_mae: 1.4298\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6339 - mae: 1.5136 - val_loss: 3.7592 - val_mae: 1.5089\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9558 - mae: 1.6005 - val_loss: 3.5037 - val_mae: 1.4324\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7326 - mae: 1.5354 - val_loss: 3.6099 - val_mae: 1.4690\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6744 - mae: 1.5294 - val_loss: 3.5085 - val_mae: 1.4387\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6206 - mae: 1.4995 - val_loss: 3.5280 - val_mae: 1.4427\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7173 - mae: 1.5213 - val_loss: 3.5896 - val_mae: 1.4533\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7120 - mae: 1.5262 - val_loss: 3.6224 - val_mae: 1.4695\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8495 - mae: 1.5673 - val_loss: 3.5781 - val_mae: 1.4657\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1143 - mae: 1.5951 - val_loss: 3.4924 - val_mae: 1.4333\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6979 - mae: 1.5335 - val_loss: 3.5781 - val_mae: 1.4569\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5146 - mae: 1.4830 - val_loss: 3.5561 - val_mae: 1.4608\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9265 - mae: 1.5836 - val_loss: 3.5907 - val_mae: 1.4641\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7686 - mae: 1.5522 - val_loss: 3.6227 - val_mae: 1.4712\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9205 - mae: 1.5727 - val_loss: 3.4821 - val_mae: 1.4343\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4705 - mae: 1.4969 - val_loss: 3.6289 - val_mae: 1.4745\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5420 - mae: 1.4903 - val_loss: 3.6074 - val_mae: 1.4676\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5797 - mae: 1.5257 - val_loss: 3.6337 - val_mae: 1.4816\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8043 - mae: 1.5461 - val_loss: 3.6156 - val_mae: 1.4666\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5878 - mae: 1.5113 - val_loss: 3.5963 - val_mae: 1.4703\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2445 - mae: 1.4264 - val_loss: 3.6465 - val_mae: 1.4796\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8114 - mae: 1.5787 - val_loss: 3.6409 - val_mae: 1.4840\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5083 - mae: 1.5126 - val_loss: 3.6683 - val_mae: 1.4912\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5425 - mae: 1.4849 - val_loss: 3.6185 - val_mae: 1.4747\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6043 - mae: 1.5353 - val_loss: 3.7378 - val_mae: 1.5154\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5789 - mae: 1.5365 - val_loss: 3.5560 - val_mae: 1.4534\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0426 - mae: 1.5865 - val_loss: 3.6225 - val_mae: 1.4755\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6859 - mae: 1.5349 - val_loss: 3.6383 - val_mae: 1.4810\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7319 - mae: 1.5367 - val_loss: 3.7092 - val_mae: 1.5067\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5197 - mae: 1.4796 - val_loss: 3.5987 - val_mae: 1.4725\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7706 - mae: 1.5419 - val_loss: 3.7744 - val_mae: 1.5229\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6941 - mae: 1.5411 - val_loss: 3.6240 - val_mae: 1.4715\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4404 - mae: 1.4739 - val_loss: 3.7961 - val_mae: 1.5275\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6071 - mae: 1.5072 - val_loss: 3.6769 - val_mae: 1.4926\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0617 - mae: 1.6350 \n",
            "Test MAE (Mean Absolute Error): 1.66\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "   Predicted     Actual\n",
            "0   6.676138   7.494001\n",
            "1  11.263981  12.394215\n",
            "2  10.875855   9.997158\n",
            "3   7.571741   8.965073\n",
            "4   8.583762  11.882369\n",
            "5  11.080107   8.595982\n",
            "6  11.181456  13.475625\n",
            "7   8.092148  11.871617\n",
            "8   6.790811   4.827736\n",
            "9   7.817484   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Predicted total rebounds for the player's next game: 14.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#nic claxton"
      ],
      "metadata": {
        "id": "waW6XPVDgHV-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VFfG2fpWgJmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [6.8], # Changed to list\n",
        "    'avg_min_last5': [24.7], # Changed to list\n",
        "    'opp_avg_reb_allowed': [46.3], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [9], # Changed to list\n",
        "    'home_indicator': [0], # Changed to list\n",
        "    'back_to_back': [1], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f424053-88e1-43f9-9521-b41c452dbc16",
        "id": "XBT0Aoo5gJ7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 82.8151 - mae: 8.6127 - val_loss: 79.3751 - val_mae: 8.5113\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 62.6353 - mae: 7.3880 - val_loss: 57.8862 - val_mae: 7.1328\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 43.7818 - mae: 6.0154 - val_loss: 31.2268 - val_mae: 5.0286\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.6484 - mae: 3.8882 - val_loss: 11.6308 - val_mae: 2.8416\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.0994 - mae: 2.2579 - val_loss: 5.9687 - val_mae: 1.9596\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8862 - mae: 1.8838 - val_loss: 5.0323 - val_mae: 1.7608\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0851 - mae: 1.8025 - val_loss: 4.9042 - val_mae: 1.7328\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8147 - mae: 1.7531 - val_loss: 4.7842 - val_mae: 1.7005\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1702 - mae: 1.8041 - val_loss: 4.6423 - val_mae: 1.6629\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0574 - mae: 1.7853 - val_loss: 4.6298 - val_mae: 1.6646\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8950 - mae: 1.7678 - val_loss: 4.5062 - val_mae: 1.6204\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7023 - mae: 1.7392 - val_loss: 4.5598 - val_mae: 1.6474\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7085 - mae: 1.7186 - val_loss: 4.3982 - val_mae: 1.5939\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6541 - mae: 1.7192 - val_loss: 4.4349 - val_mae: 1.6201\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7128 - mae: 1.6952 - val_loss: 4.3508 - val_mae: 1.5964\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5136 - mae: 1.7151 - val_loss: 4.3371 - val_mae: 1.6048\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7293 - mae: 1.7167 - val_loss: 4.2964 - val_mae: 1.5965\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4947 - mae: 1.6749 - val_loss: 4.2762 - val_mae: 1.5869\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1676 - mae: 1.6286 - val_loss: 4.2592 - val_mae: 1.5893\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4269 - mae: 1.6711 - val_loss: 4.1695 - val_mae: 1.5659\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4625 - mae: 1.6579 - val_loss: 4.1247 - val_mae: 1.5502\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0456 - mae: 1.5900 - val_loss: 4.1790 - val_mae: 1.5731\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2430 - mae: 1.6429 - val_loss: 4.0763 - val_mae: 1.5409\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9387 - mae: 1.5648 - val_loss: 4.1756 - val_mae: 1.5758\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5538 - mae: 1.6770 - val_loss: 4.1180 - val_mae: 1.5702\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5901 - mae: 1.7065 - val_loss: 4.0498 - val_mae: 1.5369\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1800 - mae: 1.6249 - val_loss: 4.0481 - val_mae: 1.5461\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0357 - mae: 1.5892 - val_loss: 3.9422 - val_mae: 1.4959\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2662 - mae: 1.6390 - val_loss: 4.0550 - val_mae: 1.5485\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6885 - mae: 1.5353 - val_loss: 3.9799 - val_mae: 1.5246\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1165 - mae: 1.5853 - val_loss: 4.0158 - val_mae: 1.5436\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0878 - mae: 1.6054 - val_loss: 3.9607 - val_mae: 1.5266\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3626 - mae: 1.6642 - val_loss: 3.9340 - val_mae: 1.5078\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1666 - mae: 1.6067 - val_loss: 3.9718 - val_mae: 1.5273\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0421 - mae: 1.5937 - val_loss: 3.9079 - val_mae: 1.5040\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1888 - mae: 1.6090 - val_loss: 3.9190 - val_mae: 1.5052\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9683 - mae: 1.5653 - val_loss: 3.8759 - val_mae: 1.4961\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2307 - mae: 1.6222 - val_loss: 3.9524 - val_mae: 1.5280\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9625 - mae: 1.5836 - val_loss: 3.8924 - val_mae: 1.5068\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1773 - mae: 1.6093 - val_loss: 3.8866 - val_mae: 1.5054\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0930 - mae: 1.5901 - val_loss: 3.9059 - val_mae: 1.5056\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3322 - mae: 1.6615 - val_loss: 3.9507 - val_mae: 1.5313\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9786 - mae: 1.5744 - val_loss: 3.8624 - val_mae: 1.4937\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9226 - mae: 1.5852 - val_loss: 3.9783 - val_mae: 1.5403\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8980 - mae: 1.5598 - val_loss: 3.8572 - val_mae: 1.4900\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9345 - mae: 1.5722 - val_loss: 3.8908 - val_mae: 1.5189\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0495 - mae: 1.5854 - val_loss: 3.8742 - val_mae: 1.5114\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3332 - mae: 1.6241 - val_loss: 3.7986 - val_mae: 1.4820\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6364 - mae: 1.5337 - val_loss: 3.7593 - val_mae: 1.4582\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7135 - mae: 1.5291 - val_loss: 3.8050 - val_mae: 1.4839\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8377 - mae: 1.5657 - val_loss: 3.8850 - val_mae: 1.5222\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9387 - mae: 1.5738 - val_loss: 3.8589 - val_mae: 1.5084\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8847 - mae: 1.5355 - val_loss: 3.8291 - val_mae: 1.5040\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8195 - mae: 1.5434 - val_loss: 3.8671 - val_mae: 1.5095\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0088 - mae: 1.5682 - val_loss: 3.7758 - val_mae: 1.4849\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7008 - mae: 1.5340 - val_loss: 3.7498 - val_mae: 1.4705\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1741 - mae: 1.6298 - val_loss: 3.7361 - val_mae: 1.4713\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9592 - mae: 1.5523 - val_loss: 3.7186 - val_mae: 1.4587\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9768 - mae: 1.5781 - val_loss: 3.8246 - val_mae: 1.5008\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9028 - mae: 1.5514 - val_loss: 3.6919 - val_mae: 1.4621\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9200 - mae: 1.5328 - val_loss: 3.6722 - val_mae: 1.4461\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8115 - mae: 1.5436 - val_loss: 3.7824 - val_mae: 1.4885\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6857 - mae: 1.5176 - val_loss: 3.7196 - val_mae: 1.4732\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2472 - mae: 1.6457 - val_loss: 3.7377 - val_mae: 1.4802\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8194 - mae: 1.5588 - val_loss: 3.7987 - val_mae: 1.5030\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6064 - mae: 1.5058 - val_loss: 3.7404 - val_mae: 1.4884\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9133 - mae: 1.5661 - val_loss: 3.7696 - val_mae: 1.5026\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1352 - mae: 1.5768 - val_loss: 3.7002 - val_mae: 1.4653\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5851 - mae: 1.4910 - val_loss: 3.6888 - val_mae: 1.4679\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9790 - mae: 1.5680 - val_loss: 3.7283 - val_mae: 1.4774\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9402 - mae: 1.5397 - val_loss: 3.7641 - val_mae: 1.4915\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8822 - mae: 1.5617 - val_loss: 3.7642 - val_mae: 1.4977\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8485 - mae: 1.5603 - val_loss: 3.6838 - val_mae: 1.4716\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6423 - mae: 1.4923 - val_loss: 3.7107 - val_mae: 1.4722\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9682 - mae: 1.5788 - val_loss: 3.6754 - val_mae: 1.4691\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7781 - mae: 1.5292 - val_loss: 3.6813 - val_mae: 1.4768\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9651 - mae: 1.5704 - val_loss: 3.6437 - val_mae: 1.4564\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1259 - mae: 1.6121 - val_loss: 3.7364 - val_mae: 1.4904\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0310 - mae: 1.5806 - val_loss: 3.7613 - val_mae: 1.5019\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9025 - mae: 1.5377 - val_loss: 3.6808 - val_mae: 1.4675\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8581 - mae: 1.5188 - val_loss: 3.7566 - val_mae: 1.4921\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5229 - mae: 1.4895 - val_loss: 3.6936 - val_mae: 1.4781\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5286 - mae: 1.4802 - val_loss: 3.7683 - val_mae: 1.5044\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0743 - mae: 1.5849 - val_loss: 3.6058 - val_mae: 1.4423\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7424 - mae: 1.5217 - val_loss: 3.9173 - val_mae: 1.5523\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7442 - mae: 1.5104 - val_loss: 3.6255 - val_mae: 1.4510\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5048 - mae: 1.4603 - val_loss: 3.7302 - val_mae: 1.4863\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7451 - mae: 1.5256 - val_loss: 3.7567 - val_mae: 1.4925\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5498 - mae: 1.5064 - val_loss: 3.6825 - val_mae: 1.4654\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8350 - mae: 1.5739 - val_loss: 3.6546 - val_mae: 1.4651\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8056 - mae: 1.5310 - val_loss: 3.7801 - val_mae: 1.4987\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5208 - mae: 1.4687 - val_loss: 3.6369 - val_mae: 1.4518\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7267 - mae: 1.5422 - val_loss: 3.7733 - val_mae: 1.5031\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5296 - mae: 1.4805 - val_loss: 3.7129 - val_mae: 1.4792\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5737 - mae: 1.4697 - val_loss: 3.7729 - val_mae: 1.5062\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8583 - mae: 1.5528 - val_loss: 3.6479 - val_mae: 1.4519\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9578 - mae: 1.5427 - val_loss: 3.7281 - val_mae: 1.4937\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3851 - mae: 1.4625 - val_loss: 3.7811 - val_mae: 1.5056\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6066 - mae: 1.5035 - val_loss: 3.6961 - val_mae: 1.4743\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7418 - mae: 1.5224 - val_loss: 3.7010 - val_mae: 1.4839\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2001 - mae: 1.6386 \n",
            "Test MAE (Mean Absolute Error): 1.66\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "   Predicted     Actual\n",
            "0   7.355953   7.494001\n",
            "1  11.168180  12.394215\n",
            "2  10.297441   9.997158\n",
            "3   7.592773   8.965073\n",
            "4   8.058082  11.882369\n",
            "5  11.620517   8.595982\n",
            "6  10.942772  13.475625\n",
            "7   7.998325  11.871617\n",
            "8   6.288674   4.827736\n",
            "9   8.125606   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Predicted total rebounds for the player's next game: 7.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#cameron jonhson"
      ],
      "metadata": {
        "id": "gyAao9xYhXsb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ayVfMq4bhbfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [4.8], # Changed to list\n",
        "    'avg_min_last5': [28.6], # Changed to list\n",
        "    'opp_avg_reb_allowed': [46.3], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [6], # Changed to list\n",
        "    'home_indicator': [0], # Changed to list\n",
        "    'back_to_back': [1], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eac66426-bed7-4a8e-b9a7-2e9237c53d57",
        "id": "edhbHhBAhbtO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 78.8872 - mae: 8.4130 - val_loss: 74.2888 - val_mae: 8.1964\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 59.5055 - mae: 7.1945 - val_loss: 48.0885 - val_mae: 6.4103\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.4854 - mae: 5.2059 - val_loss: 21.4794 - val_mae: 4.0785\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.3731 - mae: 3.0054 - val_loss: 8.0999 - val_mae: 2.2981\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2344 - mae: 2.0061 - val_loss: 5.3648 - val_mae: 1.8221\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7916 - mae: 1.9446 - val_loss: 4.9879 - val_mae: 1.7582\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2755 - mae: 1.8389 - val_loss: 4.7975 - val_mae: 1.7131\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0214 - mae: 1.8038 - val_loss: 4.7634 - val_mae: 1.7087\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4184 - mae: 1.6873 - val_loss: 4.6394 - val_mae: 1.6703\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7083 - mae: 1.7431 - val_loss: 4.5827 - val_mae: 1.6681\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7578 - mae: 1.7511 - val_loss: 4.5023 - val_mae: 1.6521\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6058 - mae: 1.7038 - val_loss: 4.4104 - val_mae: 1.6275\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4165 - mae: 1.6698 - val_loss: 4.3751 - val_mae: 1.6277\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6707 - mae: 1.7406 - val_loss: 4.3497 - val_mae: 1.6180\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6068 - mae: 1.7088 - val_loss: 4.2464 - val_mae: 1.5879\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8101 - mae: 1.7657 - val_loss: 4.3892 - val_mae: 1.6508\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1896 - mae: 1.6294 - val_loss: 4.2152 - val_mae: 1.5896\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3196 - mae: 1.6620 - val_loss: 4.2146 - val_mae: 1.5901\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6129 - mae: 1.7490 - val_loss: 4.2525 - val_mae: 1.6122\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3434 - mae: 1.6387 - val_loss: 4.1622 - val_mae: 1.5857\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1240 - mae: 1.6068 - val_loss: 4.1285 - val_mae: 1.5687\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2869 - mae: 1.6694 - val_loss: 4.0687 - val_mae: 1.5566\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4134 - mae: 1.7101 - val_loss: 3.9856 - val_mae: 1.5327\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3185 - mae: 1.6388 - val_loss: 4.0851 - val_mae: 1.5735\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2056 - mae: 1.6312 - val_loss: 4.0908 - val_mae: 1.5715\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2790 - mae: 1.6593 - val_loss: 4.0059 - val_mae: 1.5374\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1914 - mae: 1.6050 - val_loss: 4.0226 - val_mae: 1.5508\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3499 - mae: 1.6371 - val_loss: 4.0235 - val_mae: 1.5561\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5046 - mae: 1.6907 - val_loss: 3.9060 - val_mae: 1.5034\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3712 - mae: 1.6789 - val_loss: 4.0131 - val_mae: 1.5535\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2872 - mae: 1.6367 - val_loss: 3.9065 - val_mae: 1.5158\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1561 - mae: 1.6288 - val_loss: 3.9872 - val_mae: 1.5544\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2953 - mae: 1.6308 - val_loss: 3.8865 - val_mae: 1.5075\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1185 - mae: 1.6196 - val_loss: 3.8994 - val_mae: 1.5103\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1855 - mae: 1.5963 - val_loss: 3.8967 - val_mae: 1.5177\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9573 - mae: 1.5739 - val_loss: 3.9209 - val_mae: 1.5274\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1207 - mae: 1.6258 - val_loss: 3.9144 - val_mae: 1.5248\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3591 - mae: 1.6640 - val_loss: 3.8546 - val_mae: 1.5047\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1798 - mae: 1.6041 - val_loss: 3.7816 - val_mae: 1.4767\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1246 - mae: 1.6063 - val_loss: 3.9148 - val_mae: 1.5333\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3022 - mae: 1.6619 - val_loss: 3.8160 - val_mae: 1.5025\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9544 - mae: 1.5747 - val_loss: 3.7927 - val_mae: 1.4959\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8506 - mae: 1.5412 - val_loss: 3.8805 - val_mae: 1.5303\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0210 - mae: 1.5993 - val_loss: 3.7059 - val_mae: 1.4662\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1793 - mae: 1.6197 - val_loss: 3.8040 - val_mae: 1.4995\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9114 - mae: 1.5635 - val_loss: 3.8116 - val_mae: 1.5031\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9133 - mae: 1.5751 - val_loss: 3.7143 - val_mae: 1.4674\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9945 - mae: 1.5880 - val_loss: 3.8388 - val_mae: 1.5189\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9295 - mae: 1.5789 - val_loss: 3.7316 - val_mae: 1.4691\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0456 - mae: 1.6081 - val_loss: 3.7568 - val_mae: 1.4991\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0957 - mae: 1.5880 - val_loss: 3.7134 - val_mae: 1.4787\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9330 - mae: 1.5462 - val_loss: 3.6429 - val_mae: 1.4467\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8966 - mae: 1.5523 - val_loss: 3.8685 - val_mae: 1.5299\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8678 - mae: 1.5530 - val_loss: 3.6844 - val_mae: 1.4739\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1028 - mae: 1.6095 - val_loss: 3.7465 - val_mae: 1.4931\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2773 - mae: 1.6566 - val_loss: 3.7003 - val_mae: 1.4786\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7520 - mae: 1.5487 - val_loss: 3.5726 - val_mae: 1.4337\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9189 - mae: 1.5718 - val_loss: 3.7081 - val_mae: 1.4820\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9832 - mae: 1.5885 - val_loss: 3.6597 - val_mae: 1.4666\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8926 - mae: 1.5958 - val_loss: 3.7332 - val_mae: 1.4988\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7662 - mae: 1.5301 - val_loss: 3.6696 - val_mae: 1.4739\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0917 - mae: 1.5901 - val_loss: 3.7344 - val_mae: 1.4981\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7426 - mae: 1.5290 - val_loss: 3.6679 - val_mae: 1.4824\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8798 - mae: 1.5526 - val_loss: 3.6339 - val_mae: 1.4643\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5496 - mae: 1.4953 - val_loss: 3.6674 - val_mae: 1.4712\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9251 - mae: 1.5519 - val_loss: 3.6467 - val_mae: 1.4748\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1849 - mae: 1.6271 - val_loss: 3.7166 - val_mae: 1.5009\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8881 - mae: 1.5810 - val_loss: 3.5967 - val_mae: 1.4594\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5711 - mae: 1.4682 - val_loss: 3.6424 - val_mae: 1.4634\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9735 - mae: 1.5810 - val_loss: 3.6536 - val_mae: 1.4924\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8855 - mae: 1.5678 - val_loss: 3.7145 - val_mae: 1.5006\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8771 - mae: 1.5555 - val_loss: 3.5858 - val_mae: 1.4520\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7921 - mae: 1.5222 - val_loss: 3.5984 - val_mae: 1.4619\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9632 - mae: 1.5910 - val_loss: 3.7062 - val_mae: 1.4939\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7030 - mae: 1.5500 - val_loss: 3.7167 - val_mae: 1.5082\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6526 - mae: 1.5085 - val_loss: 3.6085 - val_mae: 1.4603\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5355 - mae: 1.5051 - val_loss: 3.5788 - val_mae: 1.4593\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9176 - mae: 1.5700 - val_loss: 3.6047 - val_mae: 1.4579\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0242 - mae: 1.6243 - val_loss: 3.7656 - val_mae: 1.5134\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7439 - mae: 1.5476 - val_loss: 3.7241 - val_mae: 1.4967\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8398 - mae: 1.5366 - val_loss: 3.7527 - val_mae: 1.5074\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6988 - mae: 1.5428 - val_loss: 3.6249 - val_mae: 1.4772\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6068 - mae: 1.5069 - val_loss: 3.6512 - val_mae: 1.4782\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6291 - mae: 1.4979 - val_loss: 3.6060 - val_mae: 1.4733\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6875 - mae: 1.5359 - val_loss: 3.5574 - val_mae: 1.4592\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7791 - mae: 1.5368 - val_loss: 3.6719 - val_mae: 1.4883\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6136 - mae: 1.5107 - val_loss: 3.6252 - val_mae: 1.4821\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8179 - mae: 1.5214 - val_loss: 3.5785 - val_mae: 1.4669\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6437 - mae: 1.5083 - val_loss: 3.7498 - val_mae: 1.5163\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7562 - mae: 1.5443 - val_loss: 3.5965 - val_mae: 1.4637\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6302 - mae: 1.4953 - val_loss: 3.7111 - val_mae: 1.5088\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5246 - mae: 1.4901 - val_loss: 3.6631 - val_mae: 1.4900\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9470 - mae: 1.5603 - val_loss: 3.5364 - val_mae: 1.4508\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6970 - mae: 1.5237 - val_loss: 3.6118 - val_mae: 1.4814\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6585 - mae: 1.5082 - val_loss: 3.7018 - val_mae: 1.5063\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8901 - mae: 1.5572 - val_loss: 3.6836 - val_mae: 1.4990\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6048 - mae: 1.5249 - val_loss: 3.6100 - val_mae: 1.4824\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4412 - mae: 1.4877 - val_loss: 3.6671 - val_mae: 1.4915\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4497 - mae: 1.4779 - val_loss: 3.6979 - val_mae: 1.5024\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3774 - mae: 1.4805 - val_loss: 3.6181 - val_mae: 1.4758\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0848 - mae: 1.6038 \n",
            "Test MAE (Mean Absolute Error): 1.63\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "   Predicted     Actual\n",
            "0   7.174722   7.494001\n",
            "1  11.592830  12.394215\n",
            "2  10.483668   9.997158\n",
            "3   7.654709   8.965073\n",
            "4   8.099473  11.882369\n",
            "5  11.599083   8.595982\n",
            "6  11.310248  13.475625\n",
            "7   8.398950  11.871617\n",
            "8   6.346822   4.827736\n",
            "9   8.569771   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Predicted total rebounds for the player's next game: 6.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#nikola vucevic"
      ],
      "metadata": {
        "id": "My3ccE7GiFp0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SbL9SaEKiHmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [11], # Changed to list\n",
        "    'avg_min_last5': [30.8], # Changed to list\n",
        "    'opp_avg_reb_allowed': [42.7], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [11], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed268e5-1505-47b6-b4a8-9363266d7fb5",
        "id": "pH7hkOMgiHuf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 83.4245 - mae: 8.6764 - val_loss: 76.5744 - val_mae: 8.3531\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 61.2758 - mae: 7.2800 - val_loss: 50.6552 - val_mae: 6.6210\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 36.0718 - mae: 5.3544 - val_loss: 22.3704 - val_mae: 4.1775\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 14.5578 - mae: 3.1533 - val_loss: 7.5601 - val_mae: 2.2717\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8010 - mae: 2.1038 - val_loss: 4.9726 - val_mae: 1.7570\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8058 - mae: 1.9402 - val_loss: 4.6511 - val_mae: 1.6749\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0657 - mae: 1.8054 - val_loss: 4.5911 - val_mae: 1.6708\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9631 - mae: 1.7821 - val_loss: 4.5217 - val_mae: 1.6454\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3829 - mae: 1.8391 - val_loss: 4.4778 - val_mae: 1.6344\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2270 - mae: 1.8275 - val_loss: 4.4720 - val_mae: 1.6393\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2448 - mae: 1.8278 - val_loss: 4.4273 - val_mae: 1.6279\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8319 - mae: 1.7503 - val_loss: 4.4193 - val_mae: 1.6281\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2134 - mae: 1.8349 - val_loss: 4.3638 - val_mae: 1.6186\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6340 - mae: 1.7100 - val_loss: 4.3819 - val_mae: 1.6326\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9077 - mae: 1.7776 - val_loss: 4.3309 - val_mae: 1.6219\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2733 - mae: 1.6399 - val_loss: 4.2961 - val_mae: 1.6073\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3558 - mae: 1.6792 - val_loss: 4.3081 - val_mae: 1.6166\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4827 - mae: 1.6794 - val_loss: 4.2393 - val_mae: 1.5952\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6367 - mae: 1.7160 - val_loss: 4.3221 - val_mae: 1.6369\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2843 - mae: 1.6455 - val_loss: 4.1851 - val_mae: 1.5913\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6702 - mae: 1.7459 - val_loss: 4.2666 - val_mae: 1.6246\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3098 - mae: 1.6712 - val_loss: 4.2101 - val_mae: 1.6031\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0405 - mae: 1.6370 - val_loss: 4.1623 - val_mae: 1.5912\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6724 - mae: 1.7006 - val_loss: 4.1510 - val_mae: 1.5949\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4535 - mae: 1.7024 - val_loss: 4.1799 - val_mae: 1.6079\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1020 - mae: 1.6386 - val_loss: 4.1645 - val_mae: 1.6033\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2551 - mae: 1.6401 - val_loss: 4.1349 - val_mae: 1.5954\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4169 - mae: 1.6890 - val_loss: 4.0224 - val_mae: 1.5593\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9193 - mae: 1.5679 - val_loss: 4.0719 - val_mae: 1.5763\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8245 - mae: 1.5376 - val_loss: 4.0109 - val_mae: 1.5571\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2954 - mae: 1.6489 - val_loss: 4.0387 - val_mae: 1.5785\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9543 - mae: 1.6019 - val_loss: 3.9660 - val_mae: 1.5492\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9978 - mae: 1.5713 - val_loss: 4.0458 - val_mae: 1.5837\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8883 - mae: 1.5650 - val_loss: 3.9449 - val_mae: 1.5437\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1595 - mae: 1.6358 - val_loss: 3.9989 - val_mae: 1.5658\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2949 - mae: 1.6766 - val_loss: 3.9372 - val_mae: 1.5476\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2353 - mae: 1.6469 - val_loss: 3.8905 - val_mae: 1.5304\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8376 - mae: 1.5697 - val_loss: 3.8782 - val_mae: 1.5404\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0783 - mae: 1.5936 - val_loss: 3.9423 - val_mae: 1.5553\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0763 - mae: 1.5972 - val_loss: 3.8900 - val_mae: 1.5370\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8202 - mae: 1.5321 - val_loss: 3.9089 - val_mae: 1.5510\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3432 - mae: 1.6548 - val_loss: 3.8127 - val_mae: 1.5103\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9677 - mae: 1.5744 - val_loss: 3.8842 - val_mae: 1.5503\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9717 - mae: 1.5574 - val_loss: 3.8941 - val_mae: 1.5475\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0070 - mae: 1.6129 - val_loss: 3.8108 - val_mae: 1.5210\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9419 - mae: 1.5754 - val_loss: 3.8125 - val_mae: 1.5219\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9281 - mae: 1.6058 - val_loss: 3.8516 - val_mae: 1.5334\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9031 - mae: 1.5815 - val_loss: 3.8875 - val_mae: 1.5461\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9685 - mae: 1.5937 - val_loss: 3.8867 - val_mae: 1.5556\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0645 - mae: 1.5779 - val_loss: 3.8131 - val_mae: 1.5185\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6406 - mae: 1.5135 - val_loss: 3.7486 - val_mae: 1.5002\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6804 - mae: 1.5309 - val_loss: 3.7915 - val_mae: 1.5205\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6254 - mae: 1.5070 - val_loss: 3.8647 - val_mae: 1.5428\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6376 - mae: 1.5019 - val_loss: 3.6995 - val_mae: 1.4956\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6039 - mae: 1.5131 - val_loss: 3.8090 - val_mae: 1.5262\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7390 - mae: 1.5412 - val_loss: 3.8204 - val_mae: 1.5300\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5523 - mae: 1.5009 - val_loss: 3.7203 - val_mae: 1.5007\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8425 - mae: 1.5515 - val_loss: 3.8404 - val_mae: 1.5364\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6118 - mae: 1.5049 - val_loss: 3.7244 - val_mae: 1.5044\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6675 - mae: 1.4965 - val_loss: 3.7094 - val_mae: 1.4968\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8047 - mae: 1.5129 - val_loss: 3.7099 - val_mae: 1.4991\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6381 - mae: 1.4921 - val_loss: 3.6791 - val_mae: 1.4912\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6497 - mae: 1.5141 - val_loss: 3.8772 - val_mae: 1.5444\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6579 - mae: 1.5131 - val_loss: 3.7346 - val_mae: 1.5089\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8605 - mae: 1.5572 - val_loss: 3.7358 - val_mae: 1.5048\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8035 - mae: 1.5358 - val_loss: 3.7665 - val_mae: 1.5167\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4997 - mae: 1.4770 - val_loss: 3.7341 - val_mae: 1.5101\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6345 - mae: 1.5449 - val_loss: 3.7739 - val_mae: 1.5183\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5864 - mae: 1.5099 - val_loss: 3.7001 - val_mae: 1.4935\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5025 - mae: 1.4742 - val_loss: 3.9063 - val_mae: 1.5541\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6437 - mae: 1.5347 - val_loss: 3.7069 - val_mae: 1.5050\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8783 - mae: 1.5742 - val_loss: 3.7121 - val_mae: 1.4992\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6386 - mae: 1.5154 - val_loss: 3.7384 - val_mae: 1.5124\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6638 - mae: 1.5051 - val_loss: 3.6805 - val_mae: 1.4873\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3880 - mae: 1.4385 - val_loss: 3.7255 - val_mae: 1.5128\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6706 - mae: 1.5006 - val_loss: 3.7213 - val_mae: 1.5076\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4215 - mae: 1.4548 - val_loss: 3.6853 - val_mae: 1.4827\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4692 - mae: 1.4524 - val_loss: 3.6664 - val_mae: 1.4905\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7345 - mae: 1.5337 - val_loss: 3.6497 - val_mae: 1.4924\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6270 - mae: 1.4908 - val_loss: 3.6994 - val_mae: 1.4937\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7339 - mae: 1.5128 - val_loss: 3.6455 - val_mae: 1.4708\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5021 - mae: 1.5034 - val_loss: 3.7443 - val_mae: 1.5134\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5055 - mae: 1.4959 - val_loss: 3.7229 - val_mae: 1.5064\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3235 - mae: 1.4532 - val_loss: 3.7508 - val_mae: 1.5171\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4725 - mae: 1.5073 - val_loss: 3.7033 - val_mae: 1.4835\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7386 - mae: 1.5443 - val_loss: 3.6418 - val_mae: 1.4689\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5282 - mae: 1.5266 - val_loss: 3.7248 - val_mae: 1.4973\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6535 - mae: 1.5349 - val_loss: 3.7383 - val_mae: 1.5080\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6881 - mae: 1.5222 - val_loss: 3.6783 - val_mae: 1.4818\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5207 - mae: 1.4885 - val_loss: 3.8859 - val_mae: 1.5395\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7695 - mae: 1.5146 - val_loss: 3.7362 - val_mae: 1.4929\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4589 - mae: 1.4958 - val_loss: 3.9176 - val_mae: 1.5598\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5516 - mae: 1.4779 - val_loss: 3.6920 - val_mae: 1.4862\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2265 - mae: 1.4263 - val_loss: 3.7266 - val_mae: 1.4945\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5538 - mae: 1.5030 - val_loss: 3.8080 - val_mae: 1.5191\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3427 - mae: 1.4642 - val_loss: 3.6441 - val_mae: 1.4728\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4314 - mae: 1.4790 - val_loss: 3.6668 - val_mae: 1.4704\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2319 - mae: 1.4345 - val_loss: 3.7764 - val_mae: 1.5058\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7155 - mae: 1.5365 - val_loss: 3.8552 - val_mae: 1.5275\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6342 - mae: 1.5389 - val_loss: 3.7515 - val_mae: 1.4985\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2414 - mae: 1.6458 \n",
            "Test MAE (Mean Absolute Error): 1.66\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
            "   Predicted     Actual\n",
            "0   6.719106   7.494001\n",
            "1  11.474232  12.394215\n",
            "2  10.731071   9.997158\n",
            "3   7.961202   8.965073\n",
            "4   8.318873  11.882369\n",
            "5  11.415544   8.595982\n",
            "6  10.831719  13.475625\n",
            "7   8.117018  11.871617\n",
            "8   6.720280   4.827736\n",
            "9   8.233928   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Predicted total rebounds for the player's next game: 10.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#josh gidey"
      ],
      "metadata": {
        "id": "aRNgWiFZi0sy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vh1gDtK9i4rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [5.4], # Changed to list\n",
        "    'avg_min_last5': [25.5], # Changed to list\n",
        "    'opp_avg_reb_allowed': [42.7], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [6], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1f2d6ab-8338-4084-ae78-9bdb71fc26a5",
        "id": "uCKpPtCFi5Bw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 75.0906 - mae: 8.2059 - val_loss: 68.6400 - val_mae: 7.8821\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 53.3551 - mae: 6.7937 - val_loss: 38.4075 - val_mae: 5.7263\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 25.8466 - mae: 4.4285 - val_loss: 12.6626 - val_mae: 3.0586\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4311 - mae: 2.3521 - val_loss: 5.7943 - val_mae: 1.8760\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9267 - mae: 1.9159 - val_loss: 5.1649 - val_mae: 1.7746\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2837 - mae: 1.8014 - val_loss: 5.1307 - val_mae: 1.7958\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0061 - mae: 1.7546 - val_loss: 4.8968 - val_mae: 1.7261\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5677 - mae: 1.7231 - val_loss: 4.8309 - val_mae: 1.7174\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8542 - mae: 1.7668 - val_loss: 4.6873 - val_mae: 1.6785\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8205 - mae: 1.7361 - val_loss: 4.6416 - val_mae: 1.6803\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4854 - mae: 1.6877 - val_loss: 4.6092 - val_mae: 1.6808\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5793 - mae: 1.7065 - val_loss: 4.5065 - val_mae: 1.6492\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5380 - mae: 1.6920 - val_loss: 4.4534 - val_mae: 1.6416\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5145 - mae: 1.7210 - val_loss: 4.3532 - val_mae: 1.6156\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6012 - mae: 1.6905 - val_loss: 4.3311 - val_mae: 1.6185\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2490 - mae: 1.6478 - val_loss: 4.3055 - val_mae: 1.6202\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4334 - mae: 1.7068 - val_loss: 4.2227 - val_mae: 1.5884\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3804 - mae: 1.6705 - val_loss: 4.2221 - val_mae: 1.5937\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6204 - mae: 1.7306 - val_loss: 4.1914 - val_mae: 1.5928\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4383 - mae: 1.6927 - val_loss: 4.1184 - val_mae: 1.5679\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4848 - mae: 1.6769 - val_loss: 4.1162 - val_mae: 1.5737\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2969 - mae: 1.6400 - val_loss: 4.0649 - val_mae: 1.5551\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3127 - mae: 1.6385 - val_loss: 4.0858 - val_mae: 1.5642\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1073 - mae: 1.5953 - val_loss: 4.0358 - val_mae: 1.5532\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4157 - mae: 1.6609 - val_loss: 4.0033 - val_mae: 1.5542\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2599 - mae: 1.6241 - val_loss: 3.9891 - val_mae: 1.5495\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9567 - mae: 1.5903 - val_loss: 3.9745 - val_mae: 1.5473\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3316 - mae: 1.6352 - val_loss: 3.9703 - val_mae: 1.5583\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0978 - mae: 1.5740 - val_loss: 3.8850 - val_mae: 1.5162\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0353 - mae: 1.5963 - val_loss: 3.9763 - val_mae: 1.5552\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1870 - mae: 1.6147 - val_loss: 3.8995 - val_mae: 1.5432\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1889 - mae: 1.5984 - val_loss: 3.8473 - val_mae: 1.5097\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8103 - mae: 1.5368 - val_loss: 3.8905 - val_mae: 1.5388\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1384 - mae: 1.6042 - val_loss: 3.8790 - val_mae: 1.5414\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0895 - mae: 1.5907 - val_loss: 3.8224 - val_mae: 1.5202\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1953 - mae: 1.6285 - val_loss: 3.7937 - val_mae: 1.5022\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9473 - mae: 1.5617 - val_loss: 3.8173 - val_mae: 1.5112\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7002 - mae: 1.5090 - val_loss: 3.7619 - val_mae: 1.4985\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0039 - mae: 1.5942 - val_loss: 3.7866 - val_mae: 1.5169\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8116 - mae: 1.5345 - val_loss: 3.7639 - val_mae: 1.4962\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7918 - mae: 1.5632 - val_loss: 3.8201 - val_mae: 1.5125\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2653 - mae: 1.6273 - val_loss: 3.7291 - val_mae: 1.4926\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5846 - mae: 1.4922 - val_loss: 3.7930 - val_mae: 1.5221\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1856 - mae: 1.6026 - val_loss: 3.7569 - val_mae: 1.5114\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8913 - mae: 1.5686 - val_loss: 3.6790 - val_mae: 1.4797\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0131 - mae: 1.5507 - val_loss: 3.8395 - val_mae: 1.5330\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9828 - mae: 1.5787 - val_loss: 3.8643 - val_mae: 1.5380\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8899 - mae: 1.5730 - val_loss: 3.7084 - val_mae: 1.4863\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9571 - mae: 1.5553 - val_loss: 3.6953 - val_mae: 1.4771\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6080 - mae: 1.5016 - val_loss: 3.6996 - val_mae: 1.4853\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4177 - mae: 1.4443 - val_loss: 3.8400 - val_mae: 1.5418\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9710 - mae: 1.5686 - val_loss: 3.6643 - val_mae: 1.4777\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6635 - mae: 1.5239 - val_loss: 3.6340 - val_mae: 1.4534\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8661 - mae: 1.5557 - val_loss: 3.8984 - val_mae: 1.5573\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8232 - mae: 1.5336 - val_loss: 3.6808 - val_mae: 1.4839\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7217 - mae: 1.5385 - val_loss: 3.7924 - val_mae: 1.5176\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7287 - mae: 1.5196 - val_loss: 3.7020 - val_mae: 1.4941\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9610 - mae: 1.5788 - val_loss: 3.6640 - val_mae: 1.4738\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8564 - mae: 1.5613 - val_loss: 3.7220 - val_mae: 1.4951\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8908 - mae: 1.5565 - val_loss: 3.6768 - val_mae: 1.4767\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4806 - mae: 1.4906 - val_loss: 3.6869 - val_mae: 1.4913\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7789 - mae: 1.5370 - val_loss: 3.6587 - val_mae: 1.4818\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9448 - mae: 1.5552 - val_loss: 3.7157 - val_mae: 1.4867\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8845 - mae: 1.5749 - val_loss: 3.7703 - val_mae: 1.5059\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5549 - mae: 1.4957 - val_loss: 3.7024 - val_mae: 1.4871\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0393 - mae: 1.6069 - val_loss: 3.6902 - val_mae: 1.4813\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9753 - mae: 1.5776 - val_loss: 3.7006 - val_mae: 1.4901\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6580 - mae: 1.5032 - val_loss: 3.6624 - val_mae: 1.4766\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4609 - mae: 1.4615 - val_loss: 3.9069 - val_mae: 1.5618\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5172 - mae: 1.5034 - val_loss: 3.6226 - val_mae: 1.4607\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5009 - mae: 1.4968 - val_loss: 3.7586 - val_mae: 1.5092\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9849 - mae: 1.5972 - val_loss: 3.7360 - val_mae: 1.4943\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1068 - mae: 1.5979 - val_loss: 3.6934 - val_mae: 1.4831\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3932 - mae: 1.4633 - val_loss: 3.7479 - val_mae: 1.4911\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6656 - mae: 1.5276 - val_loss: 3.6712 - val_mae: 1.4584\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1135 - mae: 1.5734 - val_loss: 3.9750 - val_mae: 1.5765\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8761 - mae: 1.5770 - val_loss: 3.6670 - val_mae: 1.4763\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4067 - mae: 1.4478 - val_loss: 3.7019 - val_mae: 1.4829\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4898 - mae: 1.4810 - val_loss: 3.8481 - val_mae: 1.5285\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7179 - mae: 1.5463 - val_loss: 3.7438 - val_mae: 1.4975\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6556 - mae: 1.5299 - val_loss: 3.7806 - val_mae: 1.5163\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2120 - mae: 1.4280 - val_loss: 3.7218 - val_mae: 1.4906\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7757 - mae: 1.5445 - val_loss: 3.7823 - val_mae: 1.5179\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6107 - mae: 1.4821 - val_loss: 3.6912 - val_mae: 1.4884\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5939 - mae: 1.5200 - val_loss: 3.9901 - val_mae: 1.5707\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5532 - mae: 1.5331 - val_loss: 3.7225 - val_mae: 1.4910\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8053 - mae: 1.5406 - val_loss: 3.7893 - val_mae: 1.5069\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6402 - mae: 1.4925 - val_loss: 3.6773 - val_mae: 1.4755\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5280 - mae: 1.4799 - val_loss: 3.7301 - val_mae: 1.5007\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6012 - mae: 1.5096 - val_loss: 3.8260 - val_mae: 1.5286\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6003 - mae: 1.5191 - val_loss: 3.7966 - val_mae: 1.5167\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4665 - mae: 1.4896 - val_loss: 3.8150 - val_mae: 1.5217\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7145 - mae: 1.5313 - val_loss: 3.7428 - val_mae: 1.5097\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2047 - mae: 1.4018 - val_loss: 3.8215 - val_mae: 1.5207\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6248 - mae: 1.5052 - val_loss: 3.7683 - val_mae: 1.5131\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9263 - mae: 1.5845 - val_loss: 3.8711 - val_mae: 1.5459\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6021 - mae: 1.5148 - val_loss: 3.7128 - val_mae: 1.4940\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3072 - mae: 1.4409 - val_loss: 3.7427 - val_mae: 1.5095\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5310 - mae: 1.4977 - val_loss: 3.7816 - val_mae: 1.5072\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4543 - mae: 1.4784 - val_loss: 3.9094 - val_mae: 1.5523\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1532 - mae: 1.6538 \n",
            "Test MAE (Mean Absolute Error): 1.66\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "   Predicted     Actual\n",
            "0   6.417253   7.494001\n",
            "1  11.208931  12.394215\n",
            "2  10.391018   9.997158\n",
            "3   7.093582   8.965073\n",
            "4   8.117719  11.882369\n",
            "5  11.421334   8.595982\n",
            "6  10.799481  13.475625\n",
            "7   7.891380  11.871617\n",
            "8   6.247735   4.827736\n",
            "9   7.925852   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Predicted total rebounds for the player's next game: 5.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "ODH3POpZi2kS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}