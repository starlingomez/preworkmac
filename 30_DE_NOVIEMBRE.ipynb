{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFUJn9A/7lkuDLqXwMfh2J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starlingomez/preworkmac/blob/master/30_DE_NOVIEMBRE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZbfy-0BAOOy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#cody martin"
      ],
      "metadata": {
        "id": "-FJsaoL1BEFI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tXVj1vQfBGgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [5.6], # Changed to list\n",
        "    'avg_min_last5': [26.9], # Changed to list\n",
        "    'opp_avg_reb_allowed': [45.2], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [5], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [1], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6019b032-7e89-411f-d508-aed86607c7b2",
        "id": "DCXcTcT2ACEt"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 83.5233 - mae: 8.6779 - val_loss: 76.1521 - val_mae: 8.3509\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 64.1480 - mae: 7.5175 - val_loss: 51.3347 - val_mae: 6.7218\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 39.2007 - mae: 5.6667 - val_loss: 25.0083 - val_mae: 4.5270\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17.0020 - mae: 3.4677 - val_loss: 8.9245 - val_mae: 2.5688\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.7796 - mae: 2.1040 - val_loss: 5.2142 - val_mae: 1.8548\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 5.4128 - mae: 1.8553 - val_loss: 4.8458 - val_mae: 1.7672\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2245 - mae: 1.8284 - val_loss: 4.7566 - val_mae: 1.7467\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9705 - mae: 1.7910 - val_loss: 4.7221 - val_mae: 1.7429\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7861 - mae: 1.7591 - val_loss: 4.5968 - val_mae: 1.7048\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5087 - mae: 1.6912 - val_loss: 4.5751 - val_mae: 1.7021\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5586 - mae: 1.7032 - val_loss: 4.5126 - val_mae: 1.6865\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7581 - mae: 1.7551 - val_loss: 4.4680 - val_mae: 1.6765\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4394 - mae: 1.6763 - val_loss: 4.4450 - val_mae: 1.6699\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7029 - mae: 1.7042 - val_loss: 4.4349 - val_mae: 1.6753\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4981 - mae: 1.6925 - val_loss: 4.3225 - val_mae: 1.6423\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8571 - mae: 1.7850 - val_loss: 4.2658 - val_mae: 1.6191\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3735 - mae: 1.6584 - val_loss: 4.2859 - val_mae: 1.6314\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7090 - mae: 1.7417 - val_loss: 4.2392 - val_mae: 1.6222\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6905 - mae: 1.7047 - val_loss: 4.2078 - val_mae: 1.6125\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7537 - mae: 1.7485 - val_loss: 4.1951 - val_mae: 1.6120\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5317 - mae: 1.7102 - val_loss: 4.0992 - val_mae: 1.5790\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0536 - mae: 1.6195 - val_loss: 4.1541 - val_mae: 1.6033\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4608 - mae: 1.6814 - val_loss: 4.1104 - val_mae: 1.5876\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3397 - mae: 1.6528 - val_loss: 4.1378 - val_mae: 1.5921\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4148 - mae: 1.6680 - val_loss: 4.0252 - val_mae: 1.5490\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3026 - mae: 1.6661 - val_loss: 4.0170 - val_mae: 1.5529\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5754 - mae: 1.6940 - val_loss: 4.0211 - val_mae: 1.5641\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0232 - mae: 1.6128 - val_loss: 3.9916 - val_mae: 1.5447\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0954 - mae: 1.6320 - val_loss: 3.9786 - val_mae: 1.5489\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4941 - mae: 1.6943 - val_loss: 3.9528 - val_mae: 1.5413\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3255 - mae: 1.6832 - val_loss: 3.9268 - val_mae: 1.5324\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7684 - mae: 1.7162 - val_loss: 3.9215 - val_mae: 1.5268\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2467 - mae: 1.6466 - val_loss: 3.8938 - val_mae: 1.5187\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4776 - mae: 1.6616 - val_loss: 3.9111 - val_mae: 1.5260\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0019 - mae: 1.5869 - val_loss: 3.8564 - val_mae: 1.5054\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4073 - mae: 1.6602 - val_loss: 3.9080 - val_mae: 1.5317\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9425 - mae: 1.5962 - val_loss: 3.9049 - val_mae: 1.5255\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0538 - mae: 1.5916 - val_loss: 3.8848 - val_mae: 1.5217\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6701 - mae: 1.4952 - val_loss: 3.8275 - val_mae: 1.4998\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2925 - mae: 1.6562 - val_loss: 3.8504 - val_mae: 1.5139\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8981 - mae: 1.5855 - val_loss: 3.8085 - val_mae: 1.4913\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0501 - mae: 1.5864 - val_loss: 3.8920 - val_mae: 1.5353\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7239 - mae: 1.5333 - val_loss: 3.8077 - val_mae: 1.4992\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7502 - mae: 1.5357 - val_loss: 3.8473 - val_mae: 1.5187\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8796 - mae: 1.5401 - val_loss: 3.8016 - val_mae: 1.5012\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2241 - mae: 1.6116 - val_loss: 3.7732 - val_mae: 1.4879\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0355 - mae: 1.6022 - val_loss: 3.7911 - val_mae: 1.5009\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0842 - mae: 1.6146 - val_loss: 3.7651 - val_mae: 1.4865\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8457 - mae: 1.5591 - val_loss: 3.7923 - val_mae: 1.4992\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0793 - mae: 1.5955 - val_loss: 3.7037 - val_mae: 1.4747\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0302 - mae: 1.5952 - val_loss: 3.6809 - val_mae: 1.4651\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1378 - mae: 1.6156 - val_loss: 3.7406 - val_mae: 1.4850\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7822 - mae: 1.5616 - val_loss: 3.8094 - val_mae: 1.5070\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7838 - mae: 1.5272 - val_loss: 3.7256 - val_mae: 1.4866\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7689 - mae: 1.5629 - val_loss: 3.7155 - val_mae: 1.4804\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4854 - mae: 1.4896 - val_loss: 3.6814 - val_mae: 1.4731\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7375 - mae: 1.5492 - val_loss: 3.7023 - val_mae: 1.4794\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0325 - mae: 1.5696 - val_loss: 3.6794 - val_mae: 1.4760\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9512 - mae: 1.5738 - val_loss: 3.8182 - val_mae: 1.5207\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8919 - mae: 1.5732 - val_loss: 3.6658 - val_mae: 1.4768\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4652 - mae: 1.4463 - val_loss: 3.8378 - val_mae: 1.5298\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8780 - mae: 1.5517 - val_loss: 3.6674 - val_mae: 1.4756\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5677 - mae: 1.4781 - val_loss: 3.7433 - val_mae: 1.5062\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9330 - mae: 1.5746 - val_loss: 3.6487 - val_mae: 1.4830\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8205 - mae: 1.5630 - val_loss: 3.6820 - val_mae: 1.4819\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7514 - mae: 1.5200 - val_loss: 3.6705 - val_mae: 1.4905\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7053 - mae: 1.5265 - val_loss: 3.7996 - val_mae: 1.5173\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8849 - mae: 1.5585 - val_loss: 3.6502 - val_mae: 1.4754\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5106 - mae: 1.4662 - val_loss: 3.7385 - val_mae: 1.5156\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6680 - mae: 1.4923 - val_loss: 3.7838 - val_mae: 1.5222\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0115 - mae: 1.5906 - val_loss: 3.6773 - val_mae: 1.4954\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8478 - mae: 1.5706 - val_loss: 3.6737 - val_mae: 1.4932\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9979 - mae: 1.5934 - val_loss: 3.7739 - val_mae: 1.5238\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7180 - mae: 1.5145 - val_loss: 3.6522 - val_mae: 1.4969\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3884 - mae: 1.4764 - val_loss: 3.7693 - val_mae: 1.5210\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6540 - mae: 1.5189 - val_loss: 3.6453 - val_mae: 1.4900\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7443 - mae: 1.5150 - val_loss: 3.6892 - val_mae: 1.5134\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6829 - mae: 1.5312 - val_loss: 3.6433 - val_mae: 1.4964\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2330 - mae: 1.4308 - val_loss: 3.8170 - val_mae: 1.5440\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6322 - mae: 1.4895 - val_loss: 3.7082 - val_mae: 1.5167\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7378 - mae: 1.5127 - val_loss: 3.7067 - val_mae: 1.5177\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8237 - mae: 1.5392 - val_loss: 3.7122 - val_mae: 1.5107\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2687 - mae: 1.4366 - val_loss: 3.7063 - val_mae: 1.5176\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5195 - mae: 1.4683 - val_loss: 3.7662 - val_mae: 1.5227\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5376 - mae: 1.5166 - val_loss: 3.6716 - val_mae: 1.5057\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3577 - mae: 1.4384 - val_loss: 3.8920 - val_mae: 1.5681\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7449 - mae: 1.5411 - val_loss: 3.7462 - val_mae: 1.5311\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8061 - mae: 1.5507 - val_loss: 3.7348 - val_mae: 1.5273\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5387 - mae: 1.5062 - val_loss: 3.7734 - val_mae: 1.5426\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8729 - mae: 1.5702 - val_loss: 3.7527 - val_mae: 1.5405\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4605 - mae: 1.4950 - val_loss: 3.6724 - val_mae: 1.5081\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3029 - mae: 1.4512 - val_loss: 3.7016 - val_mae: 1.5216\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4394 - mae: 1.4519 - val_loss: 3.7859 - val_mae: 1.5403\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2563 - mae: 1.4339 - val_loss: 3.7033 - val_mae: 1.5152\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2811 - mae: 1.4278 - val_loss: 3.8127 - val_mae: 1.5526\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5405 - mae: 1.4822 - val_loss: 3.7548 - val_mae: 1.5333\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5625 - mae: 1.4999 - val_loss: 3.9771 - val_mae: 1.5943\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4228 - mae: 1.4596 - val_loss: 3.7572 - val_mae: 1.5273\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4281 - mae: 1.4553 - val_loss: 3.7228 - val_mae: 1.5260\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3858 - mae: 1.4546 - val_loss: 3.8441 - val_mae: 1.5559\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2877 - mae: 1.6492 \n",
            "Test MAE (Mean Absolute Error): 1.66\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "   Predicted     Actual\n",
            "0   7.338245   7.494001\n",
            "1  11.440925  12.394215\n",
            "2   9.886438   9.997158\n",
            "3   7.187840   8.965073\n",
            "4   8.271001  11.882369\n",
            "5  11.492152   8.595982\n",
            "6  11.023385  13.475625\n",
            "7   8.094821  11.871617\n",
            "8   6.562948   4.827736\n",
            "9   8.449162   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Predicted total rebounds for the player's next game: 7.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#josh green"
      ],
      "metadata": {
        "id": "P7AobMcbC93m"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hzOFmQRdC2pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [2.8], # Changed to list\n",
        "    'avg_min_last5': [30.1], # Changed to list\n",
        "    'opp_avg_reb_allowed': [45.2], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [3], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [1], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4d44c4a-76e7-48b7-fad7-ca7af0c395b3",
        "id": "gbLDkxvoC25v"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 77.1760 - mae: 8.3006 - val_loss: 72.5926 - val_mae: 8.1002\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 58.7794 - mae: 7.0849 - val_loss: 47.3990 - val_mae: 6.3808\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 35.3494 - mae: 5.2775 - val_loss: 21.6760 - val_mae: 4.0964\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.0730 - mae: 3.1157 - val_loss: 7.4072 - val_mae: 2.1995\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.0313 - mae: 2.1379 - val_loss: 4.5474 - val_mae: 1.6278\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3461 - mae: 1.8537 - val_loss: 4.3450 - val_mae: 1.5769\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.5563 - mae: 1.8607 - val_loss: 4.3239 - val_mae: 1.5700\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.3156 - mae: 1.8254 - val_loss: 4.2390 - val_mae: 1.5464\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.9798 - mae: 1.7481 - val_loss: 4.2122 - val_mae: 1.5425\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.2707 - mae: 1.8060 - val_loss: 4.1645 - val_mae: 1.5292\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.8272 - mae: 1.7699 - val_loss: 4.1379 - val_mae: 1.5257\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.8612 - mae: 1.7402 - val_loss: 4.0569 - val_mae: 1.5023\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9270 - mae: 1.7533 - val_loss: 4.0211 - val_mae: 1.4963\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7295 - mae: 1.7315 - val_loss: 3.9911 - val_mae: 1.4924\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8897 - mae: 1.7515 - val_loss: 4.0105 - val_mae: 1.5127\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3871 - mae: 1.6606 - val_loss: 3.9286 - val_mae: 1.4883\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.4769 - mae: 1.6823 - val_loss: 3.9242 - val_mae: 1.4916\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.4268 - mae: 1.6586 - val_loss: 3.8891 - val_mae: 1.4781\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.8062 - mae: 1.7414 - val_loss: 3.8924 - val_mae: 1.4931\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.2870 - mae: 1.6360 - val_loss: 3.8437 - val_mae: 1.4767\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4.2678 - mae: 1.6061 - val_loss: 3.8054 - val_mae: 1.4607\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.3957 - mae: 1.6497 - val_loss: 3.8304 - val_mae: 1.4832\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.0954 - mae: 1.6138 - val_loss: 3.8344 - val_mae: 1.4821\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4.6843 - mae: 1.7329 - val_loss: 3.8509 - val_mae: 1.4935\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.2730 - mae: 1.6275 - val_loss: 3.7952 - val_mae: 1.4788\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.1776 - mae: 1.6098 - val_loss: 3.8076 - val_mae: 1.4816\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.2306 - mae: 1.6427 - val_loss: 3.7567 - val_mae: 1.4630\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.4719 - mae: 1.6711 - val_loss: 3.7241 - val_mae: 1.4560\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9274 - mae: 1.5733 - val_loss: 3.7565 - val_mae: 1.4655\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.4652 - mae: 1.6724 - val_loss: 3.7708 - val_mae: 1.4749\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.5197 - mae: 1.6937 - val_loss: 3.6981 - val_mae: 1.4534\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 4.4680 - mae: 1.6849 - val_loss: 3.7947 - val_mae: 1.4854\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.1151 - mae: 1.6013 - val_loss: 3.6804 - val_mae: 1.4480\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.3787 - mae: 1.6687 - val_loss: 3.7925 - val_mae: 1.4884\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.0204 - mae: 1.5880 - val_loss: 3.7022 - val_mae: 1.4601\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.7830 - mae: 1.5694 - val_loss: 3.7285 - val_mae: 1.4696\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5409 - mae: 1.6888 - val_loss: 3.6956 - val_mae: 1.4644\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.2845 - mae: 1.6270 - val_loss: 3.6396 - val_mae: 1.4410\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.8478 - mae: 1.5596 - val_loss: 3.7179 - val_mae: 1.4625\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.7656 - mae: 1.5532 - val_loss: 3.6929 - val_mae: 1.4639\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1357 - mae: 1.6129 - val_loss: 3.6783 - val_mae: 1.4725\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9089 - mae: 1.5576 - val_loss: 3.6841 - val_mae: 1.4604\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8980 - mae: 1.5643 - val_loss: 3.6714 - val_mae: 1.4558\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0158 - mae: 1.6208 - val_loss: 3.7270 - val_mae: 1.4856\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8903 - mae: 1.5663 - val_loss: 3.6306 - val_mae: 1.4393\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7859 - mae: 1.5412 - val_loss: 3.8094 - val_mae: 1.5046\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7967 - mae: 1.5259 - val_loss: 3.7393 - val_mae: 1.4789\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3089 - mae: 1.6111 - val_loss: 3.6146 - val_mae: 1.4304\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0012 - mae: 1.5742 - val_loss: 3.7088 - val_mae: 1.4714\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8150 - mae: 1.5356 - val_loss: 3.7060 - val_mae: 1.4698\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8444 - mae: 1.5655 - val_loss: 3.7454 - val_mae: 1.4776\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8882 - mae: 1.5492 - val_loss: 3.6733 - val_mae: 1.4604\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7766 - mae: 1.5346 - val_loss: 3.7363 - val_mae: 1.4785\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2032 - mae: 1.6229 - val_loss: 3.6943 - val_mae: 1.4720\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9291 - mae: 1.5696 - val_loss: 3.6524 - val_mae: 1.4570\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4207 - mae: 1.6711 - val_loss: 3.6553 - val_mae: 1.4467\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8452 - mae: 1.5423 - val_loss: 3.7423 - val_mae: 1.4849\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0161 - mae: 1.5665 - val_loss: 3.6832 - val_mae: 1.4614\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7570 - mae: 1.5334 - val_loss: 3.6681 - val_mae: 1.4503\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1374 - mae: 1.6104 - val_loss: 3.5716 - val_mae: 1.4260\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0802 - mae: 1.5894 - val_loss: 3.6389 - val_mae: 1.4493\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7199 - mae: 1.5340 - val_loss: 3.7807 - val_mae: 1.5019\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9048 - mae: 1.5822 - val_loss: 3.6257 - val_mae: 1.4411\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7273 - mae: 1.5347 - val_loss: 3.6903 - val_mae: 1.4714\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1264 - mae: 1.6254 - val_loss: 3.7808 - val_mae: 1.5082\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9330 - mae: 1.5755 - val_loss: 3.7484 - val_mae: 1.4816\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9610 - mae: 1.6005 - val_loss: 3.6029 - val_mae: 1.4366\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1409 - mae: 1.6368 - val_loss: 3.6614 - val_mae: 1.4639\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5213 - mae: 1.4807 - val_loss: 3.7490 - val_mae: 1.4933\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8201 - mae: 1.5448 - val_loss: 3.6797 - val_mae: 1.4608\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1276 - mae: 1.6188 - val_loss: 3.7043 - val_mae: 1.4784\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8519 - mae: 1.5578 - val_loss: 3.6539 - val_mae: 1.4600\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4994 - mae: 1.4929 - val_loss: 3.8213 - val_mae: 1.5076\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4649 - mae: 1.4818 - val_loss: 3.6845 - val_mae: 1.4687\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8071 - mae: 1.5642 - val_loss: 3.6780 - val_mae: 1.4778\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5909 - mae: 1.4905 - val_loss: 3.6197 - val_mae: 1.4467\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7601 - mae: 1.5237 - val_loss: 3.7350 - val_mae: 1.4876\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8561 - mae: 1.5685 - val_loss: 3.6129 - val_mae: 1.4571\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9965 - mae: 1.5784 - val_loss: 3.7738 - val_mae: 1.4973\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3557 - mae: 1.4522 - val_loss: 3.6869 - val_mae: 1.4796\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0044 - mae: 1.5675 - val_loss: 3.6309 - val_mae: 1.4603\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7670 - mae: 1.5264 - val_loss: 3.8341 - val_mae: 1.5224\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7147 - mae: 1.5468 - val_loss: 3.7930 - val_mae: 1.5106\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8691 - mae: 1.5448 - val_loss: 3.8104 - val_mae: 1.5131\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8101 - mae: 1.5334 - val_loss: 3.7931 - val_mae: 1.5076\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1226 - mae: 1.5950 - val_loss: 3.7772 - val_mae: 1.5012\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3723 - mae: 1.4559 - val_loss: 3.6480 - val_mae: 1.4799\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6676 - mae: 1.5169 - val_loss: 3.8731 - val_mae: 1.5383\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5496 - mae: 1.5092 - val_loss: 3.8640 - val_mae: 1.5336\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4316 - mae: 1.4748 - val_loss: 3.6541 - val_mae: 1.4713\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5187 - mae: 1.4796 - val_loss: 3.7338 - val_mae: 1.5013\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5527 - mae: 1.4772 - val_loss: 3.7349 - val_mae: 1.4977\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6527 - mae: 1.5233 - val_loss: 3.6318 - val_mae: 1.4658\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3614 - mae: 1.4332 - val_loss: 3.8715 - val_mae: 1.5433\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7142 - mae: 1.5369 - val_loss: 3.6546 - val_mae: 1.4689\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4160 - mae: 1.4543 - val_loss: 3.7651 - val_mae: 1.5125\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4972 - mae: 1.4758 - val_loss: 3.7359 - val_mae: 1.5022\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5200 - mae: 1.4709 - val_loss: 3.8473 - val_mae: 1.5351\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5759 - mae: 1.4959 - val_loss: 3.6140 - val_mae: 1.4649\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6307 - mae: 1.5073 - val_loss: 3.7655 - val_mae: 1.5146\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1288 - mae: 1.6333 \n",
            "Test MAE (Mean Absolute Error): 1.65\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "   Predicted     Actual\n",
            "0   6.391118   7.494001\n",
            "1  11.478195  12.394215\n",
            "2  10.349974   9.997158\n",
            "3   7.702509   8.965073\n",
            "4   7.972583  11.882369\n",
            "5  11.266068   8.595982\n",
            "6  11.269551  13.475625\n",
            "7   8.017802  11.871617\n",
            "8   6.297387   4.827736\n",
            "9   8.416084   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Predicted total rebounds for the player's next game: 7.40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#lamelo ball"
      ],
      "metadata": {
        "id": "etd74jG5GexD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YpMutHwvGlft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [6.4], # Changed to list\n",
        "    'avg_min_last5': [34.3], # Changed to list\n",
        "    'opp_avg_reb_allowed': [45.2], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [5], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74f2fd91-b944-4aca-bfce-a16a4d6d8410",
        "id": "teXYwDc-Gng7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 84.8239 - mae: 8.7471 - val_loss: 74.4474 - val_mae: 8.2172\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 61.8669 - mae: 7.3135 - val_loss: 47.2570 - val_mae: 6.3206\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 37.0490 - mae: 5.3494 - val_loss: 20.6128 - val_mae: 3.9619\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 14.1078 - mae: 3.0757 - val_loss: 7.2506 - val_mae: 2.2295\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3330 - mae: 2.1523 - val_loss: 4.6760 - val_mae: 1.7077\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.4202 - mae: 1.8363 - val_loss: 4.5338 - val_mae: 1.6717\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9250 - mae: 1.7611 - val_loss: 4.4544 - val_mae: 1.6418\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4114 - mae: 1.8445 - val_loss: 4.4544 - val_mae: 1.6455\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7522 - mae: 1.7219 - val_loss: 4.3920 - val_mae: 1.6236\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6727 - mae: 1.6915 - val_loss: 4.2972 - val_mae: 1.5990\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4665 - mae: 1.6788 - val_loss: 4.3124 - val_mae: 1.6120\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5975 - mae: 1.7087 - val_loss: 4.2992 - val_mae: 1.6047\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6637 - mae: 1.7084 - val_loss: 4.1751 - val_mae: 1.5681\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8884 - mae: 1.7435 - val_loss: 4.2206 - val_mae: 1.5999\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4200 - mae: 1.6738 - val_loss: 4.1730 - val_mae: 1.5814\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5477 - mae: 1.6806 - val_loss: 4.1464 - val_mae: 1.5781\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6933 - mae: 1.7286 - val_loss: 4.1226 - val_mae: 1.5715\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3911 - mae: 1.6586 - val_loss: 4.1053 - val_mae: 1.5682\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5964 - mae: 1.7229 - val_loss: 4.0796 - val_mae: 1.5613\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6061 - mae: 1.7199 - val_loss: 4.0994 - val_mae: 1.5688\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5505 - mae: 1.7003 - val_loss: 4.0270 - val_mae: 1.5575\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6555 - mae: 1.7102 - val_loss: 4.0377 - val_mae: 1.5505\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2906 - mae: 1.6431 - val_loss: 4.0134 - val_mae: 1.5565\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7252 - mae: 1.6993 - val_loss: 3.9414 - val_mae: 1.5321\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2540 - mae: 1.6429 - val_loss: 3.9974 - val_mae: 1.5490\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3308 - mae: 1.6537 - val_loss: 4.0041 - val_mae: 1.5557\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6033 - mae: 1.6860 - val_loss: 3.9481 - val_mae: 1.5380\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6508 - mae: 1.7221 - val_loss: 3.9466 - val_mae: 1.5455\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6460 - mae: 1.7186 - val_loss: 3.8684 - val_mae: 1.5147\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0838 - mae: 1.6163 - val_loss: 3.8579 - val_mae: 1.5104\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4028 - mae: 1.6476 - val_loss: 3.9246 - val_mae: 1.5392\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3022 - mae: 1.6334 - val_loss: 3.8053 - val_mae: 1.4885\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2803 - mae: 1.6451 - val_loss: 3.8680 - val_mae: 1.5271\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2284 - mae: 1.6387 - val_loss: 3.8110 - val_mae: 1.5084\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2025 - mae: 1.6119 - val_loss: 3.8622 - val_mae: 1.5240\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1687 - mae: 1.6284 - val_loss: 3.7811 - val_mae: 1.4899\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3166 - mae: 1.6229 - val_loss: 3.8435 - val_mae: 1.5250\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4385 - mae: 1.6642 - val_loss: 3.7668 - val_mae: 1.4880\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3046 - mae: 1.6362 - val_loss: 3.8169 - val_mae: 1.5208\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0888 - mae: 1.6216 - val_loss: 3.7553 - val_mae: 1.4968\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9652 - mae: 1.5768 - val_loss: 3.7214 - val_mae: 1.4722\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0256 - mae: 1.5987 - val_loss: 3.7881 - val_mae: 1.5042\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9469 - mae: 1.5829 - val_loss: 3.7527 - val_mae: 1.4903\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4032 - mae: 1.6525 - val_loss: 3.8376 - val_mae: 1.5250\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0528 - mae: 1.6072 - val_loss: 3.7436 - val_mae: 1.4941\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1788 - mae: 1.6232 - val_loss: 3.7744 - val_mae: 1.5073\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0878 - mae: 1.5973 - val_loss: 3.7138 - val_mae: 1.4799\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9505 - mae: 1.5966 - val_loss: 3.7938 - val_mae: 1.4998\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1328 - mae: 1.6271 - val_loss: 3.8550 - val_mae: 1.5319\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0236 - mae: 1.6127 - val_loss: 3.6589 - val_mae: 1.4532\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1068 - mae: 1.6176 - val_loss: 3.7603 - val_mae: 1.5014\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6787 - mae: 1.5109 - val_loss: 3.8279 - val_mae: 1.5206\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2555 - mae: 1.6303 - val_loss: 3.7434 - val_mae: 1.4907\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8981 - mae: 1.5676 - val_loss: 3.8815 - val_mae: 1.5297\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9254 - mae: 1.5768 - val_loss: 3.6431 - val_mae: 1.4523\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9574 - mae: 1.5805 - val_loss: 3.7494 - val_mae: 1.5007\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9981 - mae: 1.5889 - val_loss: 3.6920 - val_mae: 1.4740\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0552 - mae: 1.6097 - val_loss: 3.7760 - val_mae: 1.4985\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5807 - mae: 1.4801 - val_loss: 3.7201 - val_mae: 1.4868\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2051 - mae: 1.6098 - val_loss: 3.7313 - val_mae: 1.4929\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8649 - mae: 1.5672 - val_loss: 3.7175 - val_mae: 1.4833\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9234 - mae: 1.5725 - val_loss: 3.6683 - val_mae: 1.4621\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8358 - mae: 1.5364 - val_loss: 3.7789 - val_mae: 1.5029\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0019 - mae: 1.5786 - val_loss: 3.8282 - val_mae: 1.5262\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8389 - mae: 1.5507 - val_loss: 3.7642 - val_mae: 1.5104\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6987 - mae: 1.5289 - val_loss: 3.6989 - val_mae: 1.4772\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8411 - mae: 1.5483 - val_loss: 3.7333 - val_mae: 1.4890\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0008 - mae: 1.5670 - val_loss: 3.7095 - val_mae: 1.4761\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8495 - mae: 1.5607 - val_loss: 3.8896 - val_mae: 1.5426\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8225 - mae: 1.5410 - val_loss: 3.7125 - val_mae: 1.4812\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5779 - mae: 1.4796 - val_loss: 3.7708 - val_mae: 1.5039\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4103 - mae: 1.6816 - val_loss: 3.7316 - val_mae: 1.4993\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9849 - mae: 1.5907 - val_loss: 3.8258 - val_mae: 1.5248\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8824 - mae: 1.5866 - val_loss: 3.7847 - val_mae: 1.5107\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8064 - mae: 1.5209 - val_loss: 3.7963 - val_mae: 1.5108\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6093 - mae: 1.5098 - val_loss: 3.7536 - val_mae: 1.4987\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8639 - mae: 1.5396 - val_loss: 3.7291 - val_mae: 1.4856\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6166 - mae: 1.5051 - val_loss: 3.8403 - val_mae: 1.5309\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6752 - mae: 1.5238 - val_loss: 3.7822 - val_mae: 1.5102\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7536 - mae: 1.5470 - val_loss: 3.7476 - val_mae: 1.4856\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9374 - mae: 1.5828 - val_loss: 3.7824 - val_mae: 1.5023\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5323 - mae: 1.4837 - val_loss: 3.7610 - val_mae: 1.5039\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8436 - mae: 1.5558 - val_loss: 3.7712 - val_mae: 1.5024\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6963 - mae: 1.5519 - val_loss: 3.8165 - val_mae: 1.5164\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9652 - mae: 1.5880 - val_loss: 3.8579 - val_mae: 1.5270\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9767 - mae: 1.6018 - val_loss: 3.7000 - val_mae: 1.4812\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6085 - mae: 1.4876 - val_loss: 3.7581 - val_mae: 1.5009\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5572 - mae: 1.4696 - val_loss: 3.8754 - val_mae: 1.5370\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0450 - mae: 1.6099 - val_loss: 3.8156 - val_mae: 1.5169\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9115 - mae: 1.5659 - val_loss: 3.7459 - val_mae: 1.4955\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7081 - mae: 1.5030 - val_loss: 3.9069 - val_mae: 1.5438\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6873 - mae: 1.5056 - val_loss: 3.7530 - val_mae: 1.4971\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6048 - mae: 1.5228 - val_loss: 4.0514 - val_mae: 1.5836\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9447 - mae: 1.5671 - val_loss: 3.7175 - val_mae: 1.4818\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8042 - mae: 1.5415 - val_loss: 3.7486 - val_mae: 1.4973\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5719 - mae: 1.4956 - val_loss: 3.8299 - val_mae: 1.5285\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8232 - mae: 1.5655 - val_loss: 3.8575 - val_mae: 1.5269\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5034 - mae: 1.4847 - val_loss: 3.7926 - val_mae: 1.5016\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4566 - mae: 1.4741 - val_loss: 3.7676 - val_mae: 1.4997\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7591 - mae: 1.5408 - val_loss: 3.8057 - val_mae: 1.5212\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1125 - mae: 1.6054 \n",
            "Test MAE (Mean Absolute Error): 1.63\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "   Predicted     Actual\n",
            "0   7.049854   7.494001\n",
            "1  11.372217  12.394215\n",
            "2  10.358828   9.997158\n",
            "3   7.773367   8.965073\n",
            "4   7.895081  11.882369\n",
            "5  10.849834   8.595982\n",
            "6  11.160270  13.475625\n",
            "7   8.328272  11.871617\n",
            "8   6.478929   4.827736\n",
            "9   8.258225   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Predicted total rebounds for the player's next game: 7.61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#clint capela"
      ],
      "metadata": {
        "id": "SrTvHJebIG2s"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Nd4bVi4IIbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [9.6], # Changed to list\n",
        "    'avg_min_last5': [23.1], # Changed to list\n",
        "    'opp_avg_reb_allowed': [43.2], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [7], # Changed to list\n",
        "    'home_indicator': [0], # Changed to list\n",
        "    'back_to_back': [1], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8790668-4060-4d15-8824-e5e4b5695dd5",
        "id": "Zn9keRPwIIsT"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 80.7780 - mae: 8.5306 - val_loss: 75.5175 - val_mae: 8.2810\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 62.1927 - mae: 7.3269 - val_loss: 49.0390 - val_mae: 6.4910\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 37.7708 - mae: 5.4674 - val_loss: 22.2008 - val_mae: 4.1558\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.1020 - mae: 3.4127 - val_loss: 8.1568 - val_mae: 2.3863\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9906 - mae: 2.0997 - val_loss: 5.1566 - val_mae: 1.8307\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.9182 - mae: 1.9236 - val_loss: 4.6098 - val_mae: 1.6735\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8160 - mae: 1.7199 - val_loss: 4.5804 - val_mae: 1.6528\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4484 - mae: 1.8823 - val_loss: 4.4607 - val_mae: 1.6110\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6109 - mae: 1.6971 - val_loss: 4.4302 - val_mae: 1.6080\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6278 - mae: 1.7025 - val_loss: 4.4571 - val_mae: 1.6295\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0718 - mae: 1.7655 - val_loss: 4.3400 - val_mae: 1.5814\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5596 - mae: 1.6860 - val_loss: 4.3052 - val_mae: 1.5853\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5955 - mae: 1.7048 - val_loss: 4.3351 - val_mae: 1.6029\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8330 - mae: 1.7117 - val_loss: 4.2584 - val_mae: 1.5784\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2693 - mae: 1.6407 - val_loss: 4.2706 - val_mae: 1.5956\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5296 - mae: 1.6802 - val_loss: 4.1995 - val_mae: 1.5744\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5262 - mae: 1.7060 - val_loss: 4.2047 - val_mae: 1.5798\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4514 - mae: 1.6569 - val_loss: 4.1315 - val_mae: 1.5547\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1868 - mae: 1.5940 - val_loss: 4.1275 - val_mae: 1.5636\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1812 - mae: 1.6376 - val_loss: 4.1112 - val_mae: 1.5627\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9499 - mae: 1.5880 - val_loss: 4.0448 - val_mae: 1.5406\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5819 - mae: 1.6958 - val_loss: 4.0561 - val_mae: 1.5497\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4505 - mae: 1.6752 - val_loss: 4.0535 - val_mae: 1.5616\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5290 - mae: 1.6993 - val_loss: 3.9792 - val_mae: 1.5313\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3283 - mae: 1.6265 - val_loss: 4.0220 - val_mae: 1.5562\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0696 - mae: 1.6177 - val_loss: 3.9425 - val_mae: 1.5201\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4500 - mae: 1.6867 - val_loss: 3.9899 - val_mae: 1.5488\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2345 - mae: 1.6391 - val_loss: 3.9642 - val_mae: 1.5426\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2971 - mae: 1.6337 - val_loss: 3.9550 - val_mae: 1.5478\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9740 - mae: 1.5646 - val_loss: 3.9470 - val_mae: 1.5424\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4490 - mae: 1.6756 - val_loss: 3.9198 - val_mae: 1.5304\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1674 - mae: 1.6342 - val_loss: 3.9069 - val_mae: 1.5339\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4544 - mae: 1.6750 - val_loss: 3.8874 - val_mae: 1.5278\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9564 - mae: 1.5463 - val_loss: 3.8942 - val_mae: 1.5311\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9723 - mae: 1.5598 - val_loss: 3.8610 - val_mae: 1.5188\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3821 - mae: 1.6376 - val_loss: 3.9387 - val_mae: 1.5560\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2564 - mae: 1.6137 - val_loss: 3.8686 - val_mae: 1.5258\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9443 - mae: 1.5853 - val_loss: 3.8607 - val_mae: 1.5339\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8782 - mae: 1.5629 - val_loss: 3.8125 - val_mae: 1.5114\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0341 - mae: 1.6116 - val_loss: 3.8954 - val_mae: 1.5474\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4165 - mae: 1.6239 - val_loss: 3.8174 - val_mae: 1.5255\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8964 - mae: 1.5526 - val_loss: 3.8216 - val_mae: 1.5215\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2093 - mae: 1.6224 - val_loss: 3.7781 - val_mae: 1.5059\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0701 - mae: 1.5783 - val_loss: 3.8328 - val_mae: 1.5255\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0253 - mae: 1.6023 - val_loss: 3.7792 - val_mae: 1.5166\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8406 - mae: 1.5544 - val_loss: 3.7945 - val_mae: 1.5294\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3888 - mae: 1.6574 - val_loss: 3.8158 - val_mae: 1.5329\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9939 - mae: 1.5965 - val_loss: 3.8031 - val_mae: 1.5328\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2245 - mae: 1.6220 - val_loss: 3.7089 - val_mae: 1.4884\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1234 - mae: 1.5821 - val_loss: 3.7878 - val_mae: 1.5222\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6319 - mae: 1.4837 - val_loss: 3.7563 - val_mae: 1.5205\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9729 - mae: 1.5711 - val_loss: 3.7343 - val_mae: 1.5170\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7828 - mae: 1.5171 - val_loss: 3.7285 - val_mae: 1.5165\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6201 - mae: 1.5164 - val_loss: 3.6974 - val_mae: 1.4952\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9689 - mae: 1.5775 - val_loss: 3.6807 - val_mae: 1.5020\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0573 - mae: 1.6017 - val_loss: 3.7995 - val_mae: 1.5438\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0595 - mae: 1.6242 - val_loss: 3.6647 - val_mae: 1.5002\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7164 - mae: 1.5177 - val_loss: 3.7064 - val_mae: 1.5135\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7842 - mae: 1.5510 - val_loss: 3.7192 - val_mae: 1.5166\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7950 - mae: 1.4863 - val_loss: 3.6501 - val_mae: 1.4982\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7748 - mae: 1.5360 - val_loss: 3.6873 - val_mae: 1.5061\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0642 - mae: 1.5914 - val_loss: 3.6842 - val_mae: 1.5118\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7520 - mae: 1.5248 - val_loss: 3.6676 - val_mae: 1.5096\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1402 - mae: 1.5773 - val_loss: 3.6261 - val_mae: 1.4892\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7858 - mae: 1.5452 - val_loss: 3.7877 - val_mae: 1.5459\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9602 - mae: 1.5485 - val_loss: 3.6147 - val_mae: 1.4869\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8183 - mae: 1.5284 - val_loss: 3.6205 - val_mae: 1.4953\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9851 - mae: 1.5574 - val_loss: 3.6908 - val_mae: 1.5215\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5795 - mae: 1.4912 - val_loss: 3.6985 - val_mae: 1.5221\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0877 - mae: 1.5961 - val_loss: 3.6669 - val_mae: 1.5159\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7551 - mae: 1.5258 - val_loss: 3.6258 - val_mae: 1.4999\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7573 - mae: 1.5229 - val_loss: 3.6454 - val_mae: 1.4981\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6592 - mae: 1.5169 - val_loss: 3.6221 - val_mae: 1.5028\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9724 - mae: 1.5532 - val_loss: 3.6514 - val_mae: 1.5087\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4959 - mae: 1.4713 - val_loss: 3.7500 - val_mae: 1.5395\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8442 - mae: 1.5411 - val_loss: 3.6601 - val_mae: 1.5117\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0143 - mae: 1.5709 - val_loss: 3.6524 - val_mae: 1.5144\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6114 - mae: 1.5138 - val_loss: 3.6271 - val_mae: 1.5110\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4903 - mae: 1.4757 - val_loss: 3.7476 - val_mae: 1.5395\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5403 - mae: 1.4850 - val_loss: 3.6468 - val_mae: 1.5074\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3551 - mae: 1.4138 - val_loss: 3.7068 - val_mae: 1.5358\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7752 - mae: 1.5523 - val_loss: 3.6434 - val_mae: 1.5054\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3804 - mae: 1.4493 - val_loss: 3.6268 - val_mae: 1.5051\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6768 - mae: 1.5017 - val_loss: 3.6031 - val_mae: 1.4871\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6372 - mae: 1.5021 - val_loss: 3.7935 - val_mae: 1.5540\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3805 - mae: 1.4515 - val_loss: 3.6404 - val_mae: 1.5106\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8689 - mae: 1.5527 - val_loss: 3.6522 - val_mae: 1.5158\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6923 - mae: 1.5269 - val_loss: 3.6864 - val_mae: 1.5230\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7540 - mae: 1.5222 - val_loss: 3.6258 - val_mae: 1.5071\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4234 - mae: 1.4456 - val_loss: 3.6415 - val_mae: 1.5132\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3582 - mae: 1.4592 - val_loss: 3.6282 - val_mae: 1.5085\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7254 - mae: 1.5247 - val_loss: 3.5957 - val_mae: 1.4936\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5266 - mae: 1.4765 - val_loss: 3.6253 - val_mae: 1.5134\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4261 - mae: 1.4621 - val_loss: 3.6501 - val_mae: 1.5227\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4983 - mae: 1.4610 - val_loss: 3.6216 - val_mae: 1.5074\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5858 - mae: 1.4661 - val_loss: 3.6925 - val_mae: 1.5260\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6184 - mae: 1.5072 - val_loss: 3.6147 - val_mae: 1.5111\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8517 - mae: 1.5571 - val_loss: 3.8252 - val_mae: 1.5689\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6470 - mae: 1.5480 - val_loss: 3.5871 - val_mae: 1.4755\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7779 - mae: 1.5281 - val_loss: 3.7567 - val_mae: 1.5499\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2777 - mae: 1.6607 \n",
            "Test MAE (Mean Absolute Error): 1.68\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
            "   Predicted     Actual\n",
            "0   6.784524   7.494001\n",
            "1  11.111507  12.394215\n",
            "2  10.783756   9.997158\n",
            "3   7.458310   8.965073\n",
            "4   8.475631  11.882369\n",
            "5  11.053741   8.595982\n",
            "6  10.769015  13.475625\n",
            "7   7.892448  11.871617\n",
            "8   6.242264   4.827736\n",
            "9   7.975735   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Predicted total rebounds for the player's next game: 8.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#okongu"
      ],
      "metadata": {
        "id": "xMbNxR_EJGO8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v9egQD0SJHpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [6.4], # Changed to list\n",
        "    'avg_min_last5': [23.5], # Changed to list\n",
        "    'opp_avg_reb_allowed': [43.2], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [8], # Changed to list\n",
        "    'home_indicator': [0], # Changed to list\n",
        "    'back_to_back': [1], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af24deab-abf3-464a-d061-bae43c4ff8ae",
        "id": "Bo3miVw_JH3-"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 89.0675 - mae: 8.9940 - val_loss: 77.7772 - val_mae: 8.4317\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.1518 - mae: 7.6221 - val_loss: 55.7184 - val_mae: 6.9919\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 42.6931 - mae: 5.9093 - val_loss: 29.8690 - val_mae: 4.9230\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.3789 - mae: 3.8111 - val_loss: 10.9738 - val_mae: 2.7145\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.6750 - mae: 2.3217 - val_loss: 5.4169 - val_mae: 1.7990\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8349 - mae: 1.8976 - val_loss: 4.6230 - val_mae: 1.6670\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.6218 - mae: 1.8986 - val_loss: 4.4525 - val_mae: 1.6419\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2832 - mae: 1.8210 - val_loss: 4.4054 - val_mae: 1.6371\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3489 - mae: 1.8216 - val_loss: 4.2842 - val_mae: 1.6109\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1025 - mae: 1.7977 - val_loss: 4.2595 - val_mae: 1.6046\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1500 - mae: 1.7993 - val_loss: 4.2307 - val_mae: 1.6009\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2260 - mae: 1.8130 - val_loss: 4.2031 - val_mae: 1.6046\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9708 - mae: 1.7507 - val_loss: 4.1359 - val_mae: 1.5873\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7247 - mae: 1.7335 - val_loss: 4.1762 - val_mae: 1.5962\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4418 - mae: 1.6861 - val_loss: 4.1319 - val_mae: 1.5834\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9826 - mae: 1.7710 - val_loss: 4.0680 - val_mae: 1.5623\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4046 - mae: 1.6582 - val_loss: 4.1344 - val_mae: 1.5922\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9318 - mae: 1.7911 - val_loss: 4.0407 - val_mae: 1.5546\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3910 - mae: 1.6471 - val_loss: 4.0687 - val_mae: 1.5762\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2765 - mae: 1.6552 - val_loss: 3.9412 - val_mae: 1.5311\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5505 - mae: 1.7216 - val_loss: 3.9637 - val_mae: 1.5463\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5461 - mae: 1.6994 - val_loss: 4.0064 - val_mae: 1.5558\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5756 - mae: 1.7049 - val_loss: 3.9674 - val_mae: 1.5439\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4580 - mae: 1.6461 - val_loss: 3.9611 - val_mae: 1.5506\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2013 - mae: 1.6264 - val_loss: 3.9226 - val_mae: 1.5324\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4756 - mae: 1.6939 - val_loss: 3.9920 - val_mae: 1.5594\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0638 - mae: 1.6364 - val_loss: 3.9107 - val_mae: 1.5348\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3833 - mae: 1.6802 - val_loss: 3.8484 - val_mae: 1.5069\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2913 - mae: 1.6538 - val_loss: 3.8964 - val_mae: 1.5309\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8503 - mae: 1.5533 - val_loss: 3.8978 - val_mae: 1.5393\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9744 - mae: 1.6011 - val_loss: 3.9060 - val_mae: 1.5292\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2398 - mae: 1.6453 - val_loss: 3.9021 - val_mae: 1.5377\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2196 - mae: 1.6416 - val_loss: 3.8877 - val_mae: 1.5367\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0219 - mae: 1.5997 - val_loss: 3.8834 - val_mae: 1.5262\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0275 - mae: 1.5814 - val_loss: 3.8679 - val_mae: 1.5257\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0747 - mae: 1.6208 - val_loss: 3.8070 - val_mae: 1.4999\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0982 - mae: 1.6088 - val_loss: 3.8388 - val_mae: 1.5174\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0000 - mae: 1.6075 - val_loss: 3.8822 - val_mae: 1.5358\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2121 - mae: 1.6493 - val_loss: 3.8284 - val_mae: 1.5140\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0522 - mae: 1.6163 - val_loss: 3.8315 - val_mae: 1.5141\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1213 - mae: 1.6128 - val_loss: 3.8221 - val_mae: 1.5098\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0322 - mae: 1.6139 - val_loss: 3.8333 - val_mae: 1.5119\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9106 - mae: 1.5602 - val_loss: 3.7784 - val_mae: 1.5028\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4500 - mae: 1.6925 - val_loss: 3.7250 - val_mae: 1.4847\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8453 - mae: 1.5577 - val_loss: 3.9220 - val_mae: 1.5490\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2050 - mae: 1.6399 - val_loss: 3.7238 - val_mae: 1.4822\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9508 - mae: 1.5796 - val_loss: 3.8523 - val_mae: 1.5242\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1020 - mae: 1.6068 - val_loss: 3.6910 - val_mae: 1.4703\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9392 - mae: 1.5982 - val_loss: 3.8577 - val_mae: 1.5296\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0564 - mae: 1.5831 - val_loss: 3.7691 - val_mae: 1.4995\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8496 - mae: 1.5577 - val_loss: 3.7880 - val_mae: 1.5019\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9989 - mae: 1.5796 - val_loss: 3.6770 - val_mae: 1.4674\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9708 - mae: 1.5674 - val_loss: 3.7731 - val_mae: 1.5027\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5818 - mae: 1.4994 - val_loss: 3.7580 - val_mae: 1.4950\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2111 - mae: 1.6301 - val_loss: 3.7858 - val_mae: 1.5020\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1210 - mae: 1.6394 - val_loss: 3.7806 - val_mae: 1.5038\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0151 - mae: 1.6174 - val_loss: 3.7331 - val_mae: 1.4918\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9027 - mae: 1.6028 - val_loss: 3.7233 - val_mae: 1.4873\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9652 - mae: 1.5884 - val_loss: 3.8233 - val_mae: 1.5177\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9581 - mae: 1.5870 - val_loss: 3.7723 - val_mae: 1.5002\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5556 - mae: 1.5078 - val_loss: 3.7346 - val_mae: 1.4837\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7463 - mae: 1.5404 - val_loss: 3.7934 - val_mae: 1.5174\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8771 - mae: 1.5747 - val_loss: 3.7828 - val_mae: 1.5027\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8820 - mae: 1.5491 - val_loss: 3.7555 - val_mae: 1.5048\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7626 - mae: 1.5386 - val_loss: 3.7255 - val_mae: 1.4840\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8076 - mae: 1.5412 - val_loss: 3.7478 - val_mae: 1.4913\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0434 - mae: 1.6249 - val_loss: 3.7650 - val_mae: 1.5046\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6168 - mae: 1.5045 - val_loss: 3.7672 - val_mae: 1.5003\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8118 - mae: 1.5236 - val_loss: 3.7587 - val_mae: 1.4986\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0902 - mae: 1.6105 - val_loss: 3.7655 - val_mae: 1.5004\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8604 - mae: 1.5533 - val_loss: 3.7114 - val_mae: 1.4859\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7354 - mae: 1.5321 - val_loss: 3.7505 - val_mae: 1.4921\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7491 - mae: 1.5391 - val_loss: 3.7511 - val_mae: 1.4991\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6193 - mae: 1.5046 - val_loss: 3.8327 - val_mae: 1.5306\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5486 - mae: 1.5006 - val_loss: 3.6966 - val_mae: 1.4740\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9425 - mae: 1.5506 - val_loss: 3.7649 - val_mae: 1.4997\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7491 - mae: 1.5401 - val_loss: 3.6964 - val_mae: 1.4779\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8443 - mae: 1.5646 - val_loss: 3.9310 - val_mae: 1.5386\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9514 - mae: 1.5622 - val_loss: 3.7188 - val_mae: 1.4729\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7431 - mae: 1.5333 - val_loss: 3.7504 - val_mae: 1.4982\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4517 - mae: 1.4565 - val_loss: 3.7250 - val_mae: 1.4859\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8248 - mae: 1.5871 - val_loss: 3.8345 - val_mae: 1.5191\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7370 - mae: 1.5507 - val_loss: 3.7349 - val_mae: 1.4921\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7492 - mae: 1.5340 - val_loss: 3.8611 - val_mae: 1.5243\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6824 - mae: 1.5392 - val_loss: 3.6967 - val_mae: 1.4788\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7492 - mae: 1.5333 - val_loss: 3.8900 - val_mae: 1.5312\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5896 - mae: 1.5076 - val_loss: 3.8200 - val_mae: 1.5111\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4372 - mae: 1.4801 - val_loss: 3.7871 - val_mae: 1.4989\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7921 - mae: 1.5174 - val_loss: 3.8181 - val_mae: 1.5134\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3689 - mae: 1.4537 - val_loss: 3.8717 - val_mae: 1.5293\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6619 - mae: 1.5298 - val_loss: 3.9115 - val_mae: 1.5387\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4226 - mae: 1.4625 - val_loss: 3.7255 - val_mae: 1.4778\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5145 - mae: 1.5085 - val_loss: 3.7840 - val_mae: 1.4992\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3298 - mae: 1.4578 - val_loss: 3.8896 - val_mae: 1.5368\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6671 - mae: 1.5212 - val_loss: 3.8558 - val_mae: 1.5205\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6506 - mae: 1.5222 - val_loss: 3.9338 - val_mae: 1.5448\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6434 - mae: 1.4924 - val_loss: 3.8552 - val_mae: 1.5165\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4349 - mae: 1.4661 - val_loss: 3.9214 - val_mae: 1.5418\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4514 - mae: 1.4601 - val_loss: 3.8691 - val_mae: 1.5259\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5219 - mae: 1.4875 - val_loss: 3.8780 - val_mae: 1.5251\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2192 - mae: 1.6239 \n",
            "Test MAE (Mean Absolute Error): 1.66\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "   Predicted     Actual\n",
            "0   7.565808   7.494001\n",
            "1  11.246063  12.394215\n",
            "2  10.296832   9.997158\n",
            "3   7.545423   8.965073\n",
            "4   7.903582  11.882369\n",
            "5  10.923239   8.595982\n",
            "6  10.932322  13.475625\n",
            "7   8.071864  11.871617\n",
            "8   6.092185   4.827736\n",
            "9   8.381016   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Predicted total rebounds for the player's next game: 7.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#jalen duren"
      ],
      "metadata": {
        "id": "XwopQ658J3p7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "l0cAmYB-J5gK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [8.8], # Changed to list\n",
        "    'avg_min_last5': [24], # Changed to list\n",
        "    'opp_avg_reb_allowed': [44.9], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [6], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [1], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd45a3e2-04b4-4f56-84ff-74b0c0921f44",
        "id": "ysvWhYHSJ5x0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 87.2557 - mae: 8.8596 - val_loss: 80.9611 - val_mae: 8.5733\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 66.9110 - mae: 7.6354 - val_loss: 59.0791 - val_mae: 7.1582\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 46.1286 - mae: 6.0202 - val_loss: 34.1053 - val_mae: 5.3003\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.9994 - mae: 4.3800 - val_loss: 15.2603 - val_mae: 3.4250\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.3601 - mae: 2.7158 - val_loss: 7.3294 - val_mae: 2.1886\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.9458 - mae: 2.1129 - val_loss: 5.4958 - val_mae: 1.8440\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.7293 - mae: 1.9062 - val_loss: 4.9429 - val_mae: 1.7159\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0798 - mae: 1.7892 - val_loss: 4.8188 - val_mae: 1.6958\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3366 - mae: 1.8182 - val_loss: 4.6329 - val_mae: 1.6484\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6999 - mae: 1.7304 - val_loss: 4.5857 - val_mae: 1.6496\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1657 - mae: 1.7909 - val_loss: 4.4702 - val_mae: 1.6129\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2680 - mae: 1.8270 - val_loss: 4.4298 - val_mae: 1.6133\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7034 - mae: 1.7145 - val_loss: 4.3883 - val_mae: 1.6123\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5079 - mae: 1.6771 - val_loss: 4.2935 - val_mae: 1.5888\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8168 - mae: 1.7529 - val_loss: 4.3012 - val_mae: 1.6058\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7045 - mae: 1.6894 - val_loss: 4.2315 - val_mae: 1.5873\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7156 - mae: 1.7576 - val_loss: 4.2490 - val_mae: 1.5976\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4460 - mae: 1.6440 - val_loss: 4.1355 - val_mae: 1.5550\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9048 - mae: 1.7724 - val_loss: 4.1561 - val_mae: 1.5766\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4609 - mae: 1.6906 - val_loss: 4.1871 - val_mae: 1.5948\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4476 - mae: 1.6541 - val_loss: 4.0619 - val_mae: 1.5549\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2542 - mae: 1.6422 - val_loss: 4.0667 - val_mae: 1.5621\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5402 - mae: 1.6855 - val_loss: 4.0745 - val_mae: 1.5705\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3458 - mae: 1.6442 - val_loss: 3.9967 - val_mae: 1.5428\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1901 - mae: 1.6596 - val_loss: 4.0408 - val_mae: 1.5664\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0117 - mae: 1.5662 - val_loss: 3.9719 - val_mae: 1.5489\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5335 - mae: 1.6877 - val_loss: 3.9143 - val_mae: 1.5304\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9647 - mae: 1.5913 - val_loss: 3.9834 - val_mae: 1.5483\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8635 - mae: 1.5575 - val_loss: 3.9119 - val_mae: 1.5253\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9369 - mae: 1.5724 - val_loss: 3.8766 - val_mae: 1.5197\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0611 - mae: 1.6001 - val_loss: 3.8827 - val_mae: 1.5259\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9862 - mae: 1.5821 - val_loss: 3.9311 - val_mae: 1.5352\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4098 - mae: 1.6645 - val_loss: 3.8347 - val_mae: 1.5086\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5182 - mae: 1.6758 - val_loss: 3.9076 - val_mae: 1.5410\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6152 - mae: 1.6926 - val_loss: 3.8412 - val_mae: 1.5171\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9019 - mae: 1.5555 - val_loss: 3.8488 - val_mae: 1.5212\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1065 - mae: 1.6135 - val_loss: 3.7985 - val_mae: 1.5003\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0670 - mae: 1.5961 - val_loss: 3.8940 - val_mae: 1.5515\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0256 - mae: 1.6017 - val_loss: 3.7794 - val_mae: 1.5000\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0264 - mae: 1.5882 - val_loss: 3.7249 - val_mae: 1.4800\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8494 - mae: 1.5391 - val_loss: 3.8145 - val_mae: 1.5236\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8169 - mae: 1.5433 - val_loss: 3.8197 - val_mae: 1.5221\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7568 - mae: 1.5316 - val_loss: 3.7882 - val_mae: 1.5084\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8530 - mae: 1.5597 - val_loss: 3.7248 - val_mae: 1.4781\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4949 - mae: 1.4957 - val_loss: 3.7436 - val_mae: 1.4954\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0596 - mae: 1.6066 - val_loss: 3.6931 - val_mae: 1.4872\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9098 - mae: 1.5627 - val_loss: 3.8672 - val_mae: 1.5424\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0088 - mae: 1.6000 - val_loss: 3.6999 - val_mae: 1.4711\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8157 - mae: 1.5384 - val_loss: 3.6799 - val_mae: 1.4764\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6931 - mae: 1.5033 - val_loss: 3.7112 - val_mae: 1.4905\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0864 - mae: 1.6012 - val_loss: 3.6885 - val_mae: 1.4746\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9477 - mae: 1.5530 - val_loss: 3.7007 - val_mae: 1.4731\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9674 - mae: 1.5765 - val_loss: 3.7111 - val_mae: 1.4927\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9203 - mae: 1.5795 - val_loss: 3.6626 - val_mae: 1.4822\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6804 - mae: 1.5290 - val_loss: 3.6438 - val_mae: 1.4613\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9933 - mae: 1.5911 - val_loss: 3.7095 - val_mae: 1.4915\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6597 - mae: 1.5165 - val_loss: 3.6476 - val_mae: 1.4818\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3207 - mae: 1.4383 - val_loss: 3.6357 - val_mae: 1.4565\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9252 - mae: 1.5642 - val_loss: 3.6385 - val_mae: 1.4699\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5426 - mae: 1.4886 - val_loss: 3.7882 - val_mae: 1.5216\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8090 - mae: 1.5483 - val_loss: 3.6822 - val_mae: 1.4834\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6556 - mae: 1.5099 - val_loss: 3.5572 - val_mae: 1.4520\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9743 - mae: 1.5898 - val_loss: 3.7230 - val_mae: 1.5020\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9278 - mae: 1.5600 - val_loss: 3.6488 - val_mae: 1.4736\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2794 - mae: 1.4333 - val_loss: 3.6548 - val_mae: 1.4885\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7041 - mae: 1.5374 - val_loss: 3.6625 - val_mae: 1.4814\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0619 - mae: 1.5816 - val_loss: 3.6795 - val_mae: 1.4936\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0156 - mae: 1.6016 - val_loss: 3.6643 - val_mae: 1.4865\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9350 - mae: 1.5741 - val_loss: 3.6466 - val_mae: 1.4644\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4860 - mae: 1.4750 - val_loss: 3.6786 - val_mae: 1.5007\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5912 - mae: 1.4871 - val_loss: 3.6105 - val_mae: 1.4588\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5677 - mae: 1.5163 - val_loss: 3.6338 - val_mae: 1.4732\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7896 - mae: 1.5352 - val_loss: 3.6785 - val_mae: 1.4858\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5282 - mae: 1.4731 - val_loss: 3.6793 - val_mae: 1.4904\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5512 - mae: 1.5083 - val_loss: 3.7157 - val_mae: 1.5040\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8038 - mae: 1.5451 - val_loss: 3.6643 - val_mae: 1.4818\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6139 - mae: 1.5118 - val_loss: 3.6478 - val_mae: 1.4778\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6736 - mae: 1.5176 - val_loss: 3.6758 - val_mae: 1.4905\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4976 - mae: 1.5001 - val_loss: 3.6290 - val_mae: 1.4763\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7692 - mae: 1.5539 - val_loss: 3.8501 - val_mae: 1.5516\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9299 - mae: 1.5757 - val_loss: 3.6219 - val_mae: 1.4698\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6186 - mae: 1.5393 - val_loss: 3.7257 - val_mae: 1.5059\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2893 - mae: 1.4269 - val_loss: 3.6313 - val_mae: 1.4765\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7661 - mae: 1.5263 - val_loss: 3.8622 - val_mae: 1.5562\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5606 - mae: 1.5107 - val_loss: 3.6937 - val_mae: 1.4998\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5513 - mae: 1.4984 - val_loss: 3.6843 - val_mae: 1.4864\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5663 - mae: 1.4955 - val_loss: 3.6462 - val_mae: 1.4752\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6482 - mae: 1.5427 - val_loss: 3.7345 - val_mae: 1.5034\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1940 - mae: 1.3973 - val_loss: 3.7060 - val_mae: 1.4990\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1950 - mae: 1.3985 - val_loss: 3.7475 - val_mae: 1.5098\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6559 - mae: 1.5272 - val_loss: 3.8218 - val_mae: 1.5399\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8599 - mae: 1.5593 - val_loss: 3.6817 - val_mae: 1.4897\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5812 - mae: 1.5015 - val_loss: 3.6896 - val_mae: 1.4914\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4231 - mae: 1.4503 - val_loss: 3.7033 - val_mae: 1.4894\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5593 - mae: 1.4979 - val_loss: 3.7546 - val_mae: 1.5232\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7534 - mae: 1.5130 - val_loss: 3.7310 - val_mae: 1.5057\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2591 - mae: 1.4440 - val_loss: 3.7112 - val_mae: 1.5015\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8142 - mae: 1.5391 - val_loss: 3.6897 - val_mae: 1.4932\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5532 - mae: 1.4921 - val_loss: 3.7944 - val_mae: 1.5198\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3642 - mae: 1.4624 - val_loss: 3.7595 - val_mae: 1.5249\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2608 - mae: 1.6473 \n",
            "Test MAE (Mean Absolute Error): 1.67\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "   Predicted     Actual\n",
            "0   7.097188   7.494001\n",
            "1  11.527998  12.394215\n",
            "2  10.336732   9.997158\n",
            "3   7.431815   8.965073\n",
            "4   8.247466  11.882369\n",
            "5  11.456519   8.595982\n",
            "6  11.160748  13.475625\n",
            "7   7.973653  11.871617\n",
            "8   6.613057   4.827736\n",
            "9   8.380004   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Predicted total rebounds for the player's next game: 8.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#tobias harris"
      ],
      "metadata": {
        "id": "o2QkijlDKwwm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kzh7WHXTKybI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [5.3], # Changed to list\n",
        "    'avg_min_last5': [31.8], # Changed to list\n",
        "    'opp_avg_reb_allowed': [44.9], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [14], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [1], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6326a5ce-74c2-426c-f7c1-eaf0d110659f",
        "id": "nF5q-J6GKyor"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 85.5978 - mae: 8.7554 - val_loss: 77.8507 - val_mae: 8.4237\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 64.9178 - mae: 7.5043 - val_loss: 53.8703 - val_mae: 6.8670\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.2807 - mae: 5.7572 - val_loss: 27.2864 - val_mae: 4.6788\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.7875 - mae: 3.7573 - val_loss: 9.1247 - val_mae: 2.5204\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.5570 - mae: 2.2190 - val_loss: 4.5154 - val_mae: 1.6811\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.6470 - mae: 1.8789 - val_loss: 4.1566 - val_mae: 1.5788\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2376 - mae: 1.8171 - val_loss: 4.2298 - val_mae: 1.5969\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2431 - mae: 1.7905 - val_loss: 4.1907 - val_mae: 1.5861\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3020 - mae: 1.8167 - val_loss: 4.1244 - val_mae: 1.5700\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9996 - mae: 1.7488 - val_loss: 4.1383 - val_mae: 1.5772\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9586 - mae: 1.7416 - val_loss: 4.0260 - val_mae: 1.5511\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1346 - mae: 1.7743 - val_loss: 4.0294 - val_mae: 1.5533\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9056 - mae: 1.7379 - val_loss: 3.9812 - val_mae: 1.5401\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6308 - mae: 1.7013 - val_loss: 3.9701 - val_mae: 1.5422\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4694 - mae: 1.6673 - val_loss: 3.9755 - val_mae: 1.5483\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6938 - mae: 1.6824 - val_loss: 3.9414 - val_mae: 1.5399\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2070 - mae: 1.6010 - val_loss: 3.9569 - val_mae: 1.5457\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4691 - mae: 1.6747 - val_loss: 3.9436 - val_mae: 1.5432\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1582 - mae: 1.5955 - val_loss: 3.9385 - val_mae: 1.5458\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3841 - mae: 1.6670 - val_loss: 3.8848 - val_mae: 1.5260\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4485 - mae: 1.6562 - val_loss: 3.9110 - val_mae: 1.5425\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3805 - mae: 1.6272 - val_loss: 3.8440 - val_mae: 1.5184\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3657 - mae: 1.6669 - val_loss: 3.8764 - val_mae: 1.5321\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3614 - mae: 1.6424 - val_loss: 3.8051 - val_mae: 1.5069\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5377 - mae: 1.6932 - val_loss: 3.8701 - val_mae: 1.5360\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1695 - mae: 1.6413 - val_loss: 3.8333 - val_mae: 1.5254\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3325 - mae: 1.6469 - val_loss: 3.8246 - val_mae: 1.5189\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4603 - mae: 1.6418 - val_loss: 3.8123 - val_mae: 1.5136\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9754 - mae: 1.5692 - val_loss: 3.8030 - val_mae: 1.5107\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3106 - mae: 1.6576 - val_loss: 3.7420 - val_mae: 1.4947\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3247 - mae: 1.6651 - val_loss: 3.7549 - val_mae: 1.4997\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0021 - mae: 1.5931 - val_loss: 3.7764 - val_mae: 1.4968\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2475 - mae: 1.6285 - val_loss: 3.7578 - val_mae: 1.4953\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0776 - mae: 1.6079 - val_loss: 3.7632 - val_mae: 1.5010\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9801 - mae: 1.5754 - val_loss: 3.7369 - val_mae: 1.4898\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8226 - mae: 1.5557 - val_loss: 3.8297 - val_mae: 1.5242\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9618 - mae: 1.5741 - val_loss: 3.7015 - val_mae: 1.4700\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0374 - mae: 1.6077 - val_loss: 3.7019 - val_mae: 1.4752\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4619 - mae: 1.6894 - val_loss: 3.7183 - val_mae: 1.4964\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8720 - mae: 1.5386 - val_loss: 3.7481 - val_mae: 1.4976\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1190 - mae: 1.6083 - val_loss: 3.7451 - val_mae: 1.5001\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0753 - mae: 1.5929 - val_loss: 3.6945 - val_mae: 1.4718\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1144 - mae: 1.5930 - val_loss: 3.7852 - val_mae: 1.5162\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9547 - mae: 1.5728 - val_loss: 3.6838 - val_mae: 1.4709\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8153 - mae: 1.5148 - val_loss: 3.7317 - val_mae: 1.4888\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0808 - mae: 1.6250 - val_loss: 3.7581 - val_mae: 1.4990\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0365 - mae: 1.5868 - val_loss: 3.6791 - val_mae: 1.4684\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6578 - mae: 1.5217 - val_loss: 3.7352 - val_mae: 1.4999\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7157 - mae: 1.5339 - val_loss: 3.7147 - val_mae: 1.4824\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1602 - mae: 1.6187 - val_loss: 3.7211 - val_mae: 1.4864\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0400 - mae: 1.5927 - val_loss: 3.8173 - val_mae: 1.5248\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0833 - mae: 1.5938 - val_loss: 3.8263 - val_mae: 1.5258\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9497 - mae: 1.5703 - val_loss: 3.7180 - val_mae: 1.4903\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0572 - mae: 1.5942 - val_loss: 3.6927 - val_mae: 1.4770\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6509 - mae: 1.5339 - val_loss: 3.8150 - val_mae: 1.5270\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9839 - mae: 1.5807 - val_loss: 3.7067 - val_mae: 1.4779\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0609 - mae: 1.6115 - val_loss: 3.7432 - val_mae: 1.4948\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7167 - mae: 1.5485 - val_loss: 3.6990 - val_mae: 1.4795\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7149 - mae: 1.5169 - val_loss: 3.7729 - val_mae: 1.5038\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0034 - mae: 1.5811 - val_loss: 3.7287 - val_mae: 1.4899\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5530 - mae: 1.4912 - val_loss: 3.7767 - val_mae: 1.5050\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9749 - mae: 1.5768 - val_loss: 3.6754 - val_mae: 1.4718\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7608 - mae: 1.5633 - val_loss: 3.7362 - val_mae: 1.4957\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6739 - mae: 1.5177 - val_loss: 3.8085 - val_mae: 1.5154\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7205 - mae: 1.5112 - val_loss: 3.7630 - val_mae: 1.4997\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6890 - mae: 1.5147 - val_loss: 3.7921 - val_mae: 1.5067\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6533 - mae: 1.5275 - val_loss: 3.8017 - val_mae: 1.5200\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9228 - mae: 1.5824 - val_loss: 3.7598 - val_mae: 1.5087\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6253 - mae: 1.5132 - val_loss: 3.7355 - val_mae: 1.4890\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5604 - mae: 1.4886 - val_loss: 3.8619 - val_mae: 1.5345\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9845 - mae: 1.5886 - val_loss: 3.6851 - val_mae: 1.4878\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5827 - mae: 1.5107 - val_loss: 3.8716 - val_mae: 1.5320\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7461 - mae: 1.5333 - val_loss: 3.7400 - val_mae: 1.5014\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3812 - mae: 1.4540 - val_loss: 3.7523 - val_mae: 1.5073\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7124 - mae: 1.5187 - val_loss: 3.7350 - val_mae: 1.4941\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7021 - mae: 1.5414 - val_loss: 3.8107 - val_mae: 1.5174\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5517 - mae: 1.4913 - val_loss: 3.7698 - val_mae: 1.5156\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7531 - mae: 1.5082 - val_loss: 3.7257 - val_mae: 1.4946\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8605 - mae: 1.5494 - val_loss: 3.8209 - val_mae: 1.5218\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6230 - mae: 1.5351 - val_loss: 3.7169 - val_mae: 1.4950\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6433 - mae: 1.5013 - val_loss: 3.8769 - val_mae: 1.5411\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9141 - mae: 1.5511 - val_loss: 3.7370 - val_mae: 1.5022\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6453 - mae: 1.4998 - val_loss: 3.7424 - val_mae: 1.5106\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6745 - mae: 1.4985 - val_loss: 3.9524 - val_mae: 1.5624\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6882 - mae: 1.5156 - val_loss: 3.6751 - val_mae: 1.4915\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5193 - mae: 1.4968 - val_loss: 3.8485 - val_mae: 1.5312\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5809 - mae: 1.5002 - val_loss: 3.8852 - val_mae: 1.5515\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5697 - mae: 1.4932 - val_loss: 3.7367 - val_mae: 1.5085\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5072 - mae: 1.4924 - val_loss: 3.8287 - val_mae: 1.5364\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5062 - mae: 1.4691 - val_loss: 3.8427 - val_mae: 1.5383\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3671 - mae: 1.4315 - val_loss: 3.8060 - val_mae: 1.5250\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7751 - mae: 1.5503 - val_loss: 3.7946 - val_mae: 1.5253\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6593 - mae: 1.5155 - val_loss: 3.8778 - val_mae: 1.5460\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6518 - mae: 1.5293 - val_loss: 3.8215 - val_mae: 1.5257\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6455 - mae: 1.5185 - val_loss: 3.8222 - val_mae: 1.5378\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5244 - mae: 1.4850 - val_loss: 3.9249 - val_mae: 1.5612\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6887 - mae: 1.5217 - val_loss: 3.8227 - val_mae: 1.5339\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5576 - mae: 1.4899 - val_loss: 3.8027 - val_mae: 1.5238\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4329 - mae: 1.4578 - val_loss: 3.7776 - val_mae: 1.5322\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5555 - mae: 1.4808 - val_loss: 3.8683 - val_mae: 1.5422\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2998 - mae: 1.6493 \n",
            "Test MAE (Mean Absolute Error): 1.68\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "   Predicted     Actual\n",
            "0   7.153654   7.494001\n",
            "1  11.380447  12.394215\n",
            "2  10.001759   9.997158\n",
            "3   7.440893   8.965073\n",
            "4   8.150486  11.882369\n",
            "5  11.696890   8.595982\n",
            "6  10.977875  13.475625\n",
            "7   8.144357  11.871617\n",
            "8   6.131755   4.827736\n",
            "9   8.324245   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Predicted total rebounds for the player's next game: 8.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#cade Cunnunhan"
      ],
      "metadata": {
        "id": "1V28gjtRLSy3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hT3F3jB_LU6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [6.5], # Changed to list\n",
        "    'avg_min_last5': [34.9], # Changed to list\n",
        "    'opp_avg_reb_allowed': [44.9], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [5], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [1], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3872481a-dd68-470b-ec16-4b7fdd3d48bc",
        "id": "gvo5w1UbLVWZ"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 83.5778 - mae: 8.6099 - val_loss: 76.9018 - val_mae: 8.3534\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 61.1782 - mae: 7.2849 - val_loss: 53.2815 - val_mae: 6.8090\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.3944 - mae: 5.6955 - val_loss: 26.1373 - val_mae: 4.5092\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.6317 - mae: 3.5837 - val_loss: 8.7148 - val_mae: 2.4231\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7040 - mae: 2.2353 - val_loss: 4.6933 - val_mae: 1.7126\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.6614 - mae: 1.9074 - val_loss: 4.1765 - val_mae: 1.5958\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3995 - mae: 1.8661 - val_loss: 4.1713 - val_mae: 1.6054\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7261 - mae: 1.7408 - val_loss: 4.1359 - val_mae: 1.5960\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5733 - mae: 1.6812 - val_loss: 4.1199 - val_mae: 1.5917\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1322 - mae: 1.8026 - val_loss: 4.0994 - val_mae: 1.5891\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4402 - mae: 1.6930 - val_loss: 4.1027 - val_mae: 1.5945\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3178 - mae: 1.6424 - val_loss: 4.0462 - val_mae: 1.5727\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4250 - mae: 1.6830 - val_loss: 4.0882 - val_mae: 1.5879\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4797 - mae: 1.6687 - val_loss: 4.0911 - val_mae: 1.5931\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2708 - mae: 1.6498 - val_loss: 4.0362 - val_mae: 1.5726\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7868 - mae: 1.7413 - val_loss: 4.0654 - val_mae: 1.5876\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4428 - mae: 1.6575 - val_loss: 4.0287 - val_mae: 1.5731\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3734 - mae: 1.6449 - val_loss: 4.0012 - val_mae: 1.5598\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1724 - mae: 1.6142 - val_loss: 3.9948 - val_mae: 1.5596\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3370 - mae: 1.6536 - val_loss: 3.9814 - val_mae: 1.5566\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5887 - mae: 1.6876 - val_loss: 3.9939 - val_mae: 1.5578\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1139 - mae: 1.6329 - val_loss: 3.9162 - val_mae: 1.5260\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2789 - mae: 1.6424 - val_loss: 3.9832 - val_mae: 1.5564\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0483 - mae: 1.5725 - val_loss: 3.9947 - val_mae: 1.5554\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9468 - mae: 1.5446 - val_loss: 3.9302 - val_mae: 1.5359\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2162 - mae: 1.6323 - val_loss: 3.9369 - val_mae: 1.5429\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0426 - mae: 1.5968 - val_loss: 3.9897 - val_mae: 1.5578\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2682 - mae: 1.6303 - val_loss: 3.9587 - val_mae: 1.5412\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7013 - mae: 1.7307 - val_loss: 3.9028 - val_mae: 1.5205\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2585 - mae: 1.6234 - val_loss: 3.9596 - val_mae: 1.5500\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1922 - mae: 1.6406 - val_loss: 3.8866 - val_mae: 1.5184\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0612 - mae: 1.6102 - val_loss: 3.9700 - val_mae: 1.5558\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9324 - mae: 1.5762 - val_loss: 3.9300 - val_mae: 1.5351\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0159 - mae: 1.5850 - val_loss: 3.9778 - val_mae: 1.5593\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4029 - mae: 1.6674 - val_loss: 3.8897 - val_mae: 1.5232\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2270 - mae: 1.6394 - val_loss: 3.8818 - val_mae: 1.5238\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0419 - mae: 1.5997 - val_loss: 3.9497 - val_mae: 1.5437\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7722 - mae: 1.5152 - val_loss: 3.8829 - val_mae: 1.5208\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7425 - mae: 1.5422 - val_loss: 3.8912 - val_mae: 1.5264\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9651 - mae: 1.5656 - val_loss: 3.9217 - val_mae: 1.5246\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0416 - mae: 1.5874 - val_loss: 3.9134 - val_mae: 1.5326\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3667 - mae: 1.6526 - val_loss: 3.8594 - val_mae: 1.5153\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9146 - mae: 1.5523 - val_loss: 3.8657 - val_mae: 1.5167\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8881 - mae: 1.5499 - val_loss: 3.8573 - val_mae: 1.5150\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6774 - mae: 1.5329 - val_loss: 3.8793 - val_mae: 1.5248\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5900 - mae: 1.5109 - val_loss: 3.8616 - val_mae: 1.5085\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8010 - mae: 1.5392 - val_loss: 3.9017 - val_mae: 1.5366\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7405 - mae: 1.5212 - val_loss: 3.8615 - val_mae: 1.5183\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6552 - mae: 1.5254 - val_loss: 3.9092 - val_mae: 1.5358\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0449 - mae: 1.5955 - val_loss: 3.8169 - val_mae: 1.4990\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0022 - mae: 1.5812 - val_loss: 3.7877 - val_mae: 1.4953\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9832 - mae: 1.5872 - val_loss: 3.8665 - val_mae: 1.5228\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8454 - mae: 1.5447 - val_loss: 3.8213 - val_mae: 1.5108\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7676 - mae: 1.5441 - val_loss: 3.7668 - val_mae: 1.4837\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9239 - mae: 1.5572 - val_loss: 3.8416 - val_mae: 1.5230\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0370 - mae: 1.5907 - val_loss: 3.7586 - val_mae: 1.4893\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8095 - mae: 1.5583 - val_loss: 3.7869 - val_mae: 1.4960\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7051 - mae: 1.5370 - val_loss: 3.8372 - val_mae: 1.5150\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0536 - mae: 1.5998 - val_loss: 3.7797 - val_mae: 1.4959\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8630 - mae: 1.5373 - val_loss: 3.7921 - val_mae: 1.5068\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7800 - mae: 1.5138 - val_loss: 3.7831 - val_mae: 1.4997\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6429 - mae: 1.5057 - val_loss: 3.7590 - val_mae: 1.4945\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0016 - mae: 1.5926 - val_loss: 3.7928 - val_mae: 1.5097\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7675 - mae: 1.5494 - val_loss: 3.8548 - val_mae: 1.5260\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1069 - mae: 1.6104 - val_loss: 3.6989 - val_mae: 1.4796\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9997 - mae: 1.5572 - val_loss: 3.8498 - val_mae: 1.5215\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0139 - mae: 1.5876 - val_loss: 3.7572 - val_mae: 1.5051\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8959 - mae: 1.5383 - val_loss: 3.7913 - val_mae: 1.5051\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5213 - mae: 1.4901 - val_loss: 3.8076 - val_mae: 1.5245\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7216 - mae: 1.5112 - val_loss: 3.7682 - val_mae: 1.4955\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7707 - mae: 1.5396 - val_loss: 3.7689 - val_mae: 1.5022\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9582 - mae: 1.5411 - val_loss: 3.7957 - val_mae: 1.5120\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8146 - mae: 1.5411 - val_loss: 3.7613 - val_mae: 1.4944\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9090 - mae: 1.5460 - val_loss: 3.7221 - val_mae: 1.4899\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8651 - mae: 1.5405 - val_loss: 3.8491 - val_mae: 1.5283\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4975 - mae: 1.4775 - val_loss: 3.7091 - val_mae: 1.4808\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7892 - mae: 1.5339 - val_loss: 3.7899 - val_mae: 1.5081\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8087 - mae: 1.5485 - val_loss: 3.8034 - val_mae: 1.5191\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9154 - mae: 1.5673 - val_loss: 3.8041 - val_mae: 1.5158\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7272 - mae: 1.5075 - val_loss: 3.7535 - val_mae: 1.4981\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4572 - mae: 1.4927 - val_loss: 3.8240 - val_mae: 1.5258\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7093 - mae: 1.5265 - val_loss: 3.7227 - val_mae: 1.4932\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6625 - mae: 1.4843 - val_loss: 3.8678 - val_mae: 1.5379\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6963 - mae: 1.5303 - val_loss: 3.8232 - val_mae: 1.5233\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9120 - mae: 1.5717 - val_loss: 3.7513 - val_mae: 1.4977\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7896 - mae: 1.5435 - val_loss: 3.8640 - val_mae: 1.5357\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6428 - mae: 1.4794 - val_loss: 3.7885 - val_mae: 1.5106\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7441 - mae: 1.5579 - val_loss: 3.7220 - val_mae: 1.4984\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5935 - mae: 1.4890 - val_loss: 3.8764 - val_mae: 1.5408\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4469 - mae: 1.4641 - val_loss: 3.7921 - val_mae: 1.5193\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6004 - mae: 1.5015 - val_loss: 3.7708 - val_mae: 1.5067\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5333 - mae: 1.4830 - val_loss: 3.7803 - val_mae: 1.5169\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5754 - mae: 1.4891 - val_loss: 3.8376 - val_mae: 1.5211\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6190 - mae: 1.4918 - val_loss: 3.8544 - val_mae: 1.5303\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8871 - mae: 1.5577 - val_loss: 3.7727 - val_mae: 1.5030\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9364 - mae: 1.5774 - val_loss: 3.9155 - val_mae: 1.5458\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5046 - mae: 1.4819 - val_loss: 3.8981 - val_mae: 1.5398\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7144 - mae: 1.5297 - val_loss: 3.8077 - val_mae: 1.5162\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5229 - mae: 1.4790 - val_loss: 3.9891 - val_mae: 1.5730\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8624 - mae: 1.5353 - val_loss: 3.8032 - val_mae: 1.5118\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2058 - mae: 1.6237 \n",
            "Test MAE (Mean Absolute Error): 1.64\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "   Predicted     Actual\n",
            "0   7.144767   7.494001\n",
            "1  11.690665  12.394215\n",
            "2  10.096183   9.997158\n",
            "3   7.796928   8.965073\n",
            "4   8.357061  11.882369\n",
            "5  11.353087   8.595982\n",
            "6  11.317827  13.475625\n",
            "7   8.132300  11.871617\n",
            "8   6.798461   4.827736\n",
            "9   8.099347   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Predicted total rebounds for the player's next game: 9.31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#giannis ante"
      ],
      "metadata": {
        "id": "j8zlTMEsL_k4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oaUwK6LMMB0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [10.8], # Changed to list\n",
        "    'avg_min_last5': [34.3], # Changed to list\n",
        "    'opp_avg_reb_allowed': [48.3], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [12.3], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e3ade50-9a25-4517-f86a-8d14343ad558",
        "id": "gccS2-cOMDZv"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 86.5546 - mae: 8.8840 - val_loss: 83.4389 - val_mae: 8.7638\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 68.3739 - mae: 7.7785 - val_loss: 64.7070 - val_mae: 7.6405\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 50.0453 - mae: 6.5389 - val_loss: 41.1645 - val_mae: 5.9396\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.6377 - mae: 4.7216 - val_loss: 18.3301 - val_mae: 3.7442\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.6249 - mae: 2.8594 - val_loss: 6.5333 - val_mae: 2.1248\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0992 - mae: 2.0022 - val_loss: 4.3254 - val_mae: 1.6405\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3678 - mae: 1.8781 - val_loss: 4.2039 - val_mae: 1.6206\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9617 - mae: 1.8088 - val_loss: 4.2437 - val_mae: 1.6333\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2307 - mae: 1.8253 - val_loss: 4.2248 - val_mae: 1.6301\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6790 - mae: 1.7316 - val_loss: 4.0876 - val_mae: 1.5783\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9176 - mae: 1.7649 - val_loss: 4.0809 - val_mae: 1.5786\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8258 - mae: 1.7779 - val_loss: 4.0861 - val_mae: 1.5801\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6654 - mae: 1.7125 - val_loss: 4.0246 - val_mae: 1.5668\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4651 - mae: 1.8821 - val_loss: 4.0283 - val_mae: 1.5643\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5694 - mae: 1.7045 - val_loss: 3.9324 - val_mae: 1.5265\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4363 - mae: 1.6914 - val_loss: 4.0536 - val_mae: 1.5757\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4610 - mae: 1.7160 - val_loss: 3.9275 - val_mae: 1.5299\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3773 - mae: 1.6702 - val_loss: 3.9728 - val_mae: 1.5472\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6832 - mae: 1.7129 - val_loss: 3.9371 - val_mae: 1.5364\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4640 - mae: 1.6540 - val_loss: 3.9751 - val_mae: 1.5531\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1600 - mae: 1.6158 - val_loss: 3.9229 - val_mae: 1.5297\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1886 - mae: 1.6257 - val_loss: 3.9341 - val_mae: 1.5380\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8166 - mae: 1.7549 - val_loss: 3.9572 - val_mae: 1.5479\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3778 - mae: 1.6616 - val_loss: 3.8618 - val_mae: 1.5101\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5268 - mae: 1.6730 - val_loss: 3.8842 - val_mae: 1.5244\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4533 - mae: 1.6896 - val_loss: 3.9351 - val_mae: 1.5483\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3400 - mae: 1.6745 - val_loss: 3.8464 - val_mae: 1.5033\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2192 - mae: 1.6522 - val_loss: 3.8696 - val_mae: 1.5198\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1025 - mae: 1.6221 - val_loss: 3.9191 - val_mae: 1.5433\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2541 - mae: 1.6420 - val_loss: 3.8891 - val_mae: 1.5243\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1023 - mae: 1.6092 - val_loss: 3.8468 - val_mae: 1.5117\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3362 - mae: 1.6531 - val_loss: 3.8302 - val_mae: 1.5040\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3766 - mae: 1.6756 - val_loss: 3.8364 - val_mae: 1.4986\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3577 - mae: 1.6579 - val_loss: 3.8461 - val_mae: 1.5104\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0410 - mae: 1.5978 - val_loss: 3.8297 - val_mae: 1.5039\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2163 - mae: 1.6511 - val_loss: 3.8476 - val_mae: 1.5129\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0352 - mae: 1.5894 - val_loss: 3.8147 - val_mae: 1.4973\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3079 - mae: 1.6192 - val_loss: 3.8269 - val_mae: 1.5072\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8159 - mae: 1.5592 - val_loss: 3.8073 - val_mae: 1.5006\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3694 - mae: 1.6417 - val_loss: 3.8436 - val_mae: 1.5147\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1468 - mae: 1.5853 - val_loss: 3.7822 - val_mae: 1.4936\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8171 - mae: 1.5649 - val_loss: 3.7893 - val_mae: 1.4925\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9650 - mae: 1.5878 - val_loss: 3.7933 - val_mae: 1.5039\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4930 - mae: 1.6936 - val_loss: 3.7590 - val_mae: 1.4833\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1379 - mae: 1.5979 - val_loss: 3.8125 - val_mae: 1.5087\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7275 - mae: 1.5186 - val_loss: 3.8327 - val_mae: 1.5128\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1140 - mae: 1.6308 - val_loss: 3.7689 - val_mae: 1.4906\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8021 - mae: 1.5383 - val_loss: 3.7970 - val_mae: 1.4998\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3561 - mae: 1.6435 - val_loss: 3.7668 - val_mae: 1.4953\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9713 - mae: 1.5665 - val_loss: 3.7471 - val_mae: 1.4808\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9437 - mae: 1.5793 - val_loss: 3.7761 - val_mae: 1.4998\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9059 - mae: 1.5837 - val_loss: 3.7728 - val_mae: 1.5006\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4117 - mae: 1.6645 - val_loss: 3.8258 - val_mae: 1.5111\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8805 - mae: 1.5634 - val_loss: 3.7130 - val_mae: 1.4690\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9839 - mae: 1.5499 - val_loss: 3.7758 - val_mae: 1.4984\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8945 - mae: 1.5660 - val_loss: 3.8616 - val_mae: 1.5367\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8229 - mae: 1.5504 - val_loss: 3.7600 - val_mae: 1.4901\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8797 - mae: 1.5627 - val_loss: 3.8500 - val_mae: 1.5226\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9524 - mae: 1.5900 - val_loss: 3.7504 - val_mae: 1.4914\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9302 - mae: 1.5477 - val_loss: 3.7785 - val_mae: 1.4924\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9478 - mae: 1.5681 - val_loss: 3.7715 - val_mae: 1.4997\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7870 - mae: 1.5682 - val_loss: 3.7914 - val_mae: 1.5114\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6978 - mae: 1.5456 - val_loss: 3.7388 - val_mae: 1.4847\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5359 - mae: 1.4905 - val_loss: 3.7804 - val_mae: 1.4964\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0375 - mae: 1.6016 - val_loss: 3.7944 - val_mae: 1.5039\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8228 - mae: 1.5512 - val_loss: 3.7719 - val_mae: 1.4977\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9274 - mae: 1.5614 - val_loss: 3.8334 - val_mae: 1.5235\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6963 - mae: 1.5217 - val_loss: 3.7230 - val_mae: 1.4807\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8355 - mae: 1.5574 - val_loss: 3.7913 - val_mae: 1.5065\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7882 - mae: 1.5359 - val_loss: 3.7865 - val_mae: 1.5087\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4031 - mae: 1.4694 - val_loss: 3.7649 - val_mae: 1.5125\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7170 - mae: 1.5176 - val_loss: 3.7782 - val_mae: 1.5006\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4704 - mae: 1.4773 - val_loss: 3.7741 - val_mae: 1.4982\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7740 - mae: 1.5337 - val_loss: 3.7012 - val_mae: 1.4800\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7090 - mae: 1.5194 - val_loss: 3.7993 - val_mae: 1.5091\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5202 - mae: 1.4962 - val_loss: 3.7842 - val_mae: 1.4966\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7356 - mae: 1.5309 - val_loss: 3.8038 - val_mae: 1.5183\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5863 - mae: 1.5028 - val_loss: 3.7116 - val_mae: 1.4736\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5429 - mae: 1.4752 - val_loss: 3.7989 - val_mae: 1.4967\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7049 - mae: 1.5121 - val_loss: 3.7932 - val_mae: 1.5075\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.4701 - mae: 1.4685 - val_loss: 3.7707 - val_mae: 1.4987\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.7105 - mae: 1.5282 - val_loss: 3.7536 - val_mae: 1.4836\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 3.6122 - mae: 1.5048 - val_loss: 3.9366 - val_mae: 1.5565\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.8313 - mae: 1.5575 - val_loss: 3.7077 - val_mae: 1.4736\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.5152 - mae: 1.4830 - val_loss: 3.8459 - val_mae: 1.5302\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.6860 - mae: 1.5289 - val_loss: 3.7335 - val_mae: 1.4747\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6803 - mae: 1.5133 - val_loss: 3.8035 - val_mae: 1.5087\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.9201 - mae: 1.5415 - val_loss: 3.7995 - val_mae: 1.5072\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.5693 - mae: 1.4950 - val_loss: 3.7884 - val_mae: 1.5014\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.3247 - mae: 1.4463 - val_loss: 3.7806 - val_mae: 1.5034\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.9182 - mae: 1.5613 - val_loss: 3.7554 - val_mae: 1.4966\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.7129 - mae: 1.5213 - val_loss: 3.7376 - val_mae: 1.4784\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.3705 - mae: 1.4510 - val_loss: 3.8865 - val_mae: 1.5360\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3.7703 - mae: 1.5330 - val_loss: 3.7049 - val_mae: 1.4727\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.1650 - mae: 1.4038 - val_loss: 3.9187 - val_mae: 1.5367\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4813 - mae: 1.4718 - val_loss: 3.7849 - val_mae: 1.5068\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6237 - mae: 1.4856 - val_loss: 3.7732 - val_mae: 1.4990\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9374 - mae: 1.5652 - val_loss: 3.8102 - val_mae: 1.5108\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5354 - mae: 1.4726 - val_loss: 3.8648 - val_mae: 1.5282\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3057 - mae: 1.4359 - val_loss: 3.7632 - val_mae: 1.4987\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1934 - mae: 1.6404 \n",
            "Test MAE (Mean Absolute Error): 1.65\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "   Predicted     Actual\n",
            "0   7.560656   7.494001\n",
            "1  11.507575  12.394215\n",
            "2  10.794418   9.997158\n",
            "3   7.589371   8.965073\n",
            "4   7.983606  11.882369\n",
            "5  11.245653   8.595982\n",
            "6  11.071581  13.475625\n",
            "7   8.058401  11.871617\n",
            "8   6.770154   4.827736\n",
            "9   8.295549   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Predicted total rebounds for the player's next game: 11.54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#alexandre Sarr"
      ],
      "metadata": {
        "id": "1WoEQbk2NBCo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bXCMZme2NDPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [7.8], # Changed to list\n",
        "    'avg_min_last5': [27.5], # Changed to list\n",
        "    'opp_avg_reb_allowed': [45.5], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [0], # Changed to list\n",
        "    'home_indicator': [0], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbc9d4ec-ffac-406d-9803-5739a35189c9",
        "id": "AHAgykdfNDgs"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 74.8924 - mae: 8.0929 - val_loss: 66.1414 - val_mae: 7.6132\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 52.5324 - mae: 6.5456 - val_loss: 39.8968 - val_mae: 5.6370\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.6175 - mae: 4.6157 - val_loss: 17.3766 - val_mae: 3.6462\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13.1803 - mae: 2.9571 - val_loss: 7.6241 - val_mae: 2.2219\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.1781 - mae: 2.2678 - val_loss: 5.2622 - val_mae: 1.8050\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8200 - mae: 1.9578 - val_loss: 4.9168 - val_mae: 1.7259\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.7100 - mae: 1.9055 - val_loss: 4.7572 - val_mae: 1.6953\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8500 - mae: 1.7801 - val_loss: 4.6717 - val_mae: 1.6738\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2903 - mae: 1.8069 - val_loss: 4.5338 - val_mae: 1.6423\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2967 - mae: 1.8450 - val_loss: 4.5062 - val_mae: 1.6451\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2090 - mae: 1.7915 - val_loss: 4.4057 - val_mae: 1.6228\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0505 - mae: 1.7789 - val_loss: 4.3107 - val_mae: 1.5985\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.7328 - mae: 1.7494 - val_loss: 4.3106 - val_mae: 1.6051\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9124 - mae: 1.7835 - val_loss: 4.1983 - val_mae: 1.5738\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7927 - mae: 1.7347 - val_loss: 4.1682 - val_mae: 1.5693\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9828 - mae: 1.7660 - val_loss: 4.1649 - val_mae: 1.5839\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5852 - mae: 1.6940 - val_loss: 4.1157 - val_mae: 1.5703\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2545 - mae: 1.6252 - val_loss: 4.0791 - val_mae: 1.5650\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2922 - mae: 1.6608 - val_loss: 4.0197 - val_mae: 1.5460\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3607 - mae: 1.6629 - val_loss: 4.0133 - val_mae: 1.5492\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1327 - mae: 1.5955 - val_loss: 4.0407 - val_mae: 1.5632\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3955 - mae: 1.6503 - val_loss: 4.0272 - val_mae: 1.5672\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2637 - mae: 1.6445 - val_loss: 3.9365 - val_mae: 1.5457\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2626 - mae: 1.6540 - val_loss: 3.8637 - val_mae: 1.5245\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8845 - mae: 1.5750 - val_loss: 3.9438 - val_mae: 1.5413\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1937 - mae: 1.6187 - val_loss: 3.8453 - val_mae: 1.5212\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3740 - mae: 1.6395 - val_loss: 3.8732 - val_mae: 1.5347\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1666 - mae: 1.5901 - val_loss: 3.8574 - val_mae: 1.5335\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0442 - mae: 1.5921 - val_loss: 3.8246 - val_mae: 1.5223\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0720 - mae: 1.5745 - val_loss: 3.8234 - val_mae: 1.5361\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9182 - mae: 1.5618 - val_loss: 3.7904 - val_mae: 1.5177\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3828 - mae: 1.6539 - val_loss: 3.8199 - val_mae: 1.5353\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7722 - mae: 1.5393 - val_loss: 3.6651 - val_mae: 1.4736\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9659 - mae: 1.5580 - val_loss: 3.7025 - val_mae: 1.5001\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6270 - mae: 1.5128 - val_loss: 3.8108 - val_mae: 1.5359\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2035 - mae: 1.6160 - val_loss: 3.7737 - val_mae: 1.5339\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7300 - mae: 1.5490 - val_loss: 3.6411 - val_mae: 1.4899\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2211 - mae: 1.5876 - val_loss: 3.8082 - val_mae: 1.5410\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2970 - mae: 1.6495 - val_loss: 3.7215 - val_mae: 1.5197\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7363 - mae: 1.5243 - val_loss: 3.5941 - val_mae: 1.4659\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8641 - mae: 1.5456 - val_loss: 3.7353 - val_mae: 1.5253\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8628 - mae: 1.5390 - val_loss: 3.7581 - val_mae: 1.5419\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8429 - mae: 1.5618 - val_loss: 3.6209 - val_mae: 1.4786\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9712 - mae: 1.5865 - val_loss: 3.7719 - val_mae: 1.5425\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9530 - mae: 1.5849 - val_loss: 3.5739 - val_mae: 1.4664\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1249 - mae: 1.6142 - val_loss: 3.7015 - val_mae: 1.5238\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6881 - mae: 1.5120 - val_loss: 3.6425 - val_mae: 1.5004\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6102 - mae: 1.4960 - val_loss: 3.6342 - val_mae: 1.4996\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8788 - mae: 1.5698 - val_loss: 3.5891 - val_mae: 1.4753\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9680 - mae: 1.5638 - val_loss: 3.7349 - val_mae: 1.5327\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7361 - mae: 1.5582 - val_loss: 3.6769 - val_mae: 1.5128\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9586 - mae: 1.5622 - val_loss: 3.5723 - val_mae: 1.4848\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9999 - mae: 1.5868 - val_loss: 3.6297 - val_mae: 1.5039\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8315 - mae: 1.5594 - val_loss: 3.7542 - val_mae: 1.5407\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7027 - mae: 1.5506 - val_loss: 3.5776 - val_mae: 1.4747\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8942 - mae: 1.5662 - val_loss: 3.7406 - val_mae: 1.5334\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8653 - mae: 1.5617 - val_loss: 3.4817 - val_mae: 1.4448\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7582 - mae: 1.5487 - val_loss: 3.6859 - val_mae: 1.5140\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0283 - mae: 1.5837 - val_loss: 3.7533 - val_mae: 1.5443\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6904 - mae: 1.5293 - val_loss: 3.8029 - val_mae: 1.5613\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7425 - mae: 1.5299 - val_loss: 3.4859 - val_mae: 1.4445\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5944 - mae: 1.5036 - val_loss: 3.6555 - val_mae: 1.5122\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7682 - mae: 1.5292 - val_loss: 3.6546 - val_mae: 1.5074\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8828 - mae: 1.5806 - val_loss: 3.5260 - val_mae: 1.4666\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8249 - mae: 1.5559 - val_loss: 3.9380 - val_mae: 1.5926\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6442 - mae: 1.5281 - val_loss: 3.6017 - val_mae: 1.4923\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7551 - mae: 1.5485 - val_loss: 3.6174 - val_mae: 1.4947\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7305 - mae: 1.5362 - val_loss: 3.5142 - val_mae: 1.4669\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7084 - mae: 1.5124 - val_loss: 3.9335 - val_mae: 1.5881\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9928 - mae: 1.5731 - val_loss: 3.5413 - val_mae: 1.4790\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5504 - mae: 1.4916 - val_loss: 3.5884 - val_mae: 1.4919\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7449 - mae: 1.5280 - val_loss: 3.4773 - val_mae: 1.4581\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0282 - mae: 1.5859 - val_loss: 3.5832 - val_mae: 1.4927\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8748 - mae: 1.5315 - val_loss: 3.6367 - val_mae: 1.5113\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6179 - mae: 1.4855 - val_loss: 3.7077 - val_mae: 1.5282\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9020 - mae: 1.5690 - val_loss: 3.4689 - val_mae: 1.4572\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5550 - mae: 1.4936 - val_loss: 3.9185 - val_mae: 1.5809\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6239 - mae: 1.5331 - val_loss: 3.5114 - val_mae: 1.4622\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7705 - mae: 1.5580 - val_loss: 3.5534 - val_mae: 1.4847\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1047 - mae: 1.5748 - val_loss: 3.6367 - val_mae: 1.5013\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9084 - mae: 1.5611 - val_loss: 3.7351 - val_mae: 1.5333\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9114 - mae: 1.5729 - val_loss: 3.6430 - val_mae: 1.5053\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4167 - mae: 1.4605 - val_loss: 3.6175 - val_mae: 1.5015\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4912 - mae: 1.4795 - val_loss: 3.5569 - val_mae: 1.4822\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8093 - mae: 1.5621 - val_loss: 3.6590 - val_mae: 1.5136\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7617 - mae: 1.5149 - val_loss: 3.7518 - val_mae: 1.5433\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6167 - mae: 1.4674 - val_loss: 3.6624 - val_mae: 1.5085\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6066 - mae: 1.4975 - val_loss: 3.5036 - val_mae: 1.4670\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3419 - mae: 1.4370 - val_loss: 3.6919 - val_mae: 1.5236\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5612 - mae: 1.5117 - val_loss: 3.5064 - val_mae: 1.4668\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8113 - mae: 1.5697 - val_loss: 3.5184 - val_mae: 1.4668\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6430 - mae: 1.5083 - val_loss: 3.6381 - val_mae: 1.5057\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6335 - mae: 1.5181 - val_loss: 3.6515 - val_mae: 1.5075\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9131 - mae: 1.5516 - val_loss: 3.7221 - val_mae: 1.5292\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6072 - mae: 1.5040 - val_loss: 3.5879 - val_mae: 1.4904\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6182 - mae: 1.5068 - val_loss: 3.5573 - val_mae: 1.4799\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5443 - mae: 1.4895 - val_loss: 3.5747 - val_mae: 1.4905\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4913 - mae: 1.4672 - val_loss: 3.5306 - val_mae: 1.4784\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7518 - mae: 1.5145 - val_loss: 3.6529 - val_mae: 1.5122\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6656 - mae: 1.5235 - val_loss: 3.6632 - val_mae: 1.5090\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2195 - mae: 1.6424 \n",
            "Test MAE (Mean Absolute Error): 1.65\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
            "   Predicted     Actual\n",
            "0   6.741409   7.494001\n",
            "1  11.214893  12.394215\n",
            "2  10.016333   9.997158\n",
            "3   7.246336   8.965073\n",
            "4   8.123615  11.882369\n",
            "5  11.643132   8.595982\n",
            "6  10.881339  13.475625\n",
            "7   8.027280  11.871617\n",
            "8   5.935843   4.827736\n",
            "9   7.932054   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Predicted total rebounds for the player's next game: 7.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#j valaciunas"
      ],
      "metadata": {
        "id": "7_4McfgeNuwK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZAFFQ0yTNyB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [7.2], # Changed to list\n",
        "    'avg_min_last5': [17.1], # Changed to list\n",
        "    'opp_avg_reb_allowed': [45.5], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [11.5], # Changed to list\n",
        "    'home_indicator': [0], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2961dc4d-7b1b-41fe-be50-985239499531",
        "id": "WiDSEFwnNyYh"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 79.8118 - mae: 8.4874 - val_loss: 75.1283 - val_mae: 8.2969\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 59.2016 - mae: 7.2069 - val_loss: 51.8878 - val_mae: 6.7783\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 39.7509 - mae: 5.7583 - val_loss: 24.9361 - val_mae: 4.5125\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17.1272 - mae: 3.5489 - val_loss: 8.2862 - val_mae: 2.4722\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7643 - mae: 2.0682 - val_loss: 5.1910 - val_mae: 1.8098\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.4442 - mae: 1.8629 - val_loss: 4.9008 - val_mae: 1.7374\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7653 - mae: 1.9188 - val_loss: 4.8507 - val_mae: 1.7338\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0785 - mae: 1.8105 - val_loss: 4.7524 - val_mae: 1.7165\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6975 - mae: 1.7394 - val_loss: 4.6413 - val_mae: 1.6964\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9804 - mae: 1.7900 - val_loss: 4.6160 - val_mae: 1.6947\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8930 - mae: 1.7523 - val_loss: 4.4420 - val_mae: 1.6522\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3381 - mae: 1.8510 - val_loss: 4.4645 - val_mae: 1.6605\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8997 - mae: 1.7340 - val_loss: 4.3231 - val_mae: 1.6214\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2719 - mae: 1.8176 - val_loss: 4.3079 - val_mae: 1.6237\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6348 - mae: 1.7182 - val_loss: 4.2400 - val_mae: 1.6055\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6843 - mae: 1.7245 - val_loss: 4.2522 - val_mae: 1.6084\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5058 - mae: 1.6858 - val_loss: 4.2600 - val_mae: 1.6290\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4516 - mae: 1.6808 - val_loss: 4.1692 - val_mae: 1.5973\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3885 - mae: 1.6699 - val_loss: 4.1768 - val_mae: 1.6086\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8475 - mae: 1.7871 - val_loss: 4.1082 - val_mae: 1.5924\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1824 - mae: 1.6468 - val_loss: 4.0751 - val_mae: 1.5793\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5777 - mae: 1.6726 - val_loss: 4.0654 - val_mae: 1.5776\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3082 - mae: 1.6606 - val_loss: 3.9751 - val_mae: 1.5494\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4567 - mae: 1.6899 - val_loss: 4.0286 - val_mae: 1.5781\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1533 - mae: 1.6307 - val_loss: 4.0755 - val_mae: 1.5902\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5319 - mae: 1.6818 - val_loss: 3.9599 - val_mae: 1.5552\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1247 - mae: 1.6305 - val_loss: 3.9694 - val_mae: 1.5627\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2258 - mae: 1.6567 - val_loss: 3.9528 - val_mae: 1.5594\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0675 - mae: 1.6165 - val_loss: 3.9428 - val_mae: 1.5580\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8921 - mae: 1.5614 - val_loss: 3.9376 - val_mae: 1.5571\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1560 - mae: 1.6225 - val_loss: 3.9282 - val_mae: 1.5466\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4664 - mae: 1.6828 - val_loss: 3.8917 - val_mae: 1.5453\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8270 - mae: 1.5553 - val_loss: 3.8943 - val_mae: 1.5468\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0433 - mae: 1.5944 - val_loss: 3.8836 - val_mae: 1.5434\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2348 - mae: 1.6449 - val_loss: 3.9099 - val_mae: 1.5586\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0953 - mae: 1.5986 - val_loss: 3.7850 - val_mae: 1.5160\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9853 - mae: 1.5724 - val_loss: 3.8373 - val_mae: 1.5279\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1820 - mae: 1.5929 - val_loss: 3.8778 - val_mae: 1.5448\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5796 - mae: 1.6979 - val_loss: 3.7900 - val_mae: 1.5112\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8249 - mae: 1.5447 - val_loss: 3.8173 - val_mae: 1.5352\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4207 - mae: 1.6788 - val_loss: 3.7964 - val_mae: 1.5199\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7496 - mae: 1.5168 - val_loss: 3.7790 - val_mae: 1.5187\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0672 - mae: 1.5992 - val_loss: 3.7753 - val_mae: 1.5252\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6311 - mae: 1.5091 - val_loss: 3.7676 - val_mae: 1.5135\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7951 - mae: 1.5369 - val_loss: 3.7533 - val_mae: 1.5093\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9321 - mae: 1.5843 - val_loss: 3.8103 - val_mae: 1.5337\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7747 - mae: 1.5511 - val_loss: 3.6602 - val_mae: 1.4817\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3628 - mae: 1.6241 - val_loss: 3.7535 - val_mae: 1.5100\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9247 - mae: 1.5826 - val_loss: 3.8033 - val_mae: 1.5280\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9912 - mae: 1.5728 - val_loss: 3.7139 - val_mae: 1.4947\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8918 - mae: 1.5716 - val_loss: 3.8076 - val_mae: 1.5311\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7140 - mae: 1.5434 - val_loss: 3.6642 - val_mae: 1.4892\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7395 - mae: 1.5078 - val_loss: 3.7684 - val_mae: 1.5206\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2856 - mae: 1.6601 - val_loss: 3.6898 - val_mae: 1.4983\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6747 - mae: 1.5161 - val_loss: 3.6397 - val_mae: 1.4860\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9252 - mae: 1.5731 - val_loss: 3.7680 - val_mae: 1.5222\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8242 - mae: 1.5547 - val_loss: 3.7010 - val_mae: 1.4948\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5549 - mae: 1.4770 - val_loss: 3.7134 - val_mae: 1.5061\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9552 - mae: 1.5681 - val_loss: 3.7045 - val_mae: 1.5019\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6923 - mae: 1.5349 - val_loss: 3.6317 - val_mae: 1.4815\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2294 - mae: 1.5907 - val_loss: 3.7083 - val_mae: 1.5029\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6934 - mae: 1.5216 - val_loss: 3.6438 - val_mae: 1.4855\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5522 - mae: 1.4744 - val_loss: 3.7060 - val_mae: 1.5084\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6732 - mae: 1.5241 - val_loss: 3.7709 - val_mae: 1.5240\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9635 - mae: 1.5764 - val_loss: 3.6774 - val_mae: 1.4950\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9721 - mae: 1.5812 - val_loss: 3.6703 - val_mae: 1.4918\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5800 - mae: 1.5044 - val_loss: 3.7411 - val_mae: 1.5223\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6092 - mae: 1.5065 - val_loss: 3.5830 - val_mae: 1.4617\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7658 - mae: 1.5075 - val_loss: 3.6568 - val_mae: 1.4918\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5634 - mae: 1.4938 - val_loss: 3.7270 - val_mae: 1.5112\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6468 - mae: 1.4998 - val_loss: 3.6776 - val_mae: 1.5013\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4872 - mae: 1.4593 - val_loss: 3.6285 - val_mae: 1.4884\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6001 - mae: 1.5009 - val_loss: 3.6698 - val_mae: 1.4904\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4939 - mae: 1.4814 - val_loss: 3.7002 - val_mae: 1.5058\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5208 - mae: 1.4965 - val_loss: 3.7077 - val_mae: 1.5056\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4491 - mae: 1.4570 - val_loss: 3.6908 - val_mae: 1.5070\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6912 - mae: 1.5394 - val_loss: 3.6695 - val_mae: 1.5012\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5757 - mae: 1.5062 - val_loss: 3.7398 - val_mae: 1.5078\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6344 - mae: 1.5231 - val_loss: 3.7852 - val_mae: 1.5375\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3664 - mae: 1.4518 - val_loss: 3.6738 - val_mae: 1.4949\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5056 - mae: 1.4680 - val_loss: 3.7387 - val_mae: 1.5162\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8129 - mae: 1.5545 - val_loss: 3.6429 - val_mae: 1.4809\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5887 - mae: 1.5023 - val_loss: 3.8315 - val_mae: 1.5501\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5605 - mae: 1.4953 - val_loss: 3.7161 - val_mae: 1.5081\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4887 - mae: 1.4725 - val_loss: 3.8296 - val_mae: 1.5496\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6103 - mae: 1.4982 - val_loss: 3.8707 - val_mae: 1.5522\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3441 - mae: 1.4525 - val_loss: 3.6964 - val_mae: 1.5005\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5091 - mae: 1.4570 - val_loss: 3.7110 - val_mae: 1.5106\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3361 - mae: 1.4299 - val_loss: 3.8685 - val_mae: 1.5648\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4562 - mae: 1.4897 - val_loss: 3.6582 - val_mae: 1.4862\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6766 - mae: 1.5191 - val_loss: 3.7765 - val_mae: 1.5350\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5215 - mae: 1.4730 - val_loss: 3.7888 - val_mae: 1.5316\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3653 - mae: 1.4508 - val_loss: 3.7367 - val_mae: 1.5167\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1759 - mae: 1.4024 - val_loss: 3.6338 - val_mae: 1.4758\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6884 - mae: 1.5133 - val_loss: 3.7665 - val_mae: 1.5134\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2382 - mae: 1.4231 - val_loss: 3.9983 - val_mae: 1.5962\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7695 - mae: 1.5361 - val_loss: 3.7049 - val_mae: 1.5046\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4282 - mae: 1.4361 - val_loss: 3.7084 - val_mae: 1.5013\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2591 - mae: 1.4242 - val_loss: 3.8220 - val_mae: 1.5424\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4903 - mae: 1.4765 - val_loss: 3.6797 - val_mae: 1.4928\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2030 - mae: 1.6424 \n",
            "Test MAE (Mean Absolute Error): 1.64\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
            "   Predicted     Actual\n",
            "0   6.408607   7.494001\n",
            "1  11.577689  12.394215\n",
            "2  10.290957   9.997158\n",
            "3   7.980162   8.965073\n",
            "4   8.245744  11.882369\n",
            "5  11.607515   8.595982\n",
            "6  11.159907  13.475625\n",
            "7   8.032093  11.871617\n",
            "8   6.428122   4.827736\n",
            "9   8.488528   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Predicted total rebounds for the player's next game: 7.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#jussuf nurki"
      ],
      "metadata": {
        "id": "pJUzkEPUPRMs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S4GyCfB0PWwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [9.5], # Changed to list\n",
        "    'avg_min_last5': [22.7], # Changed to list\n",
        "    'opp_avg_reb_allowed': [46.6], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [9.5], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0c80533-9da6-48cf-ce5b-17412e2c552b",
        "id": "uBjZgKjnPW77"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 78.2273 - mae: 8.3656 - val_loss: 71.8095 - val_mae: 8.0661\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.9686 - mae: 7.0401 - val_loss: 46.0260 - val_mae: 6.2892\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.5043 - mae: 4.9566 - val_loss: 19.8352 - val_mae: 3.8619\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12.1995 - mae: 2.8813 - val_loss: 6.6094 - val_mae: 2.1563\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.8252 - mae: 2.1308 - val_loss: 4.5767 - val_mae: 1.6998\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5730 - mae: 1.9248 - val_loss: 4.4138 - val_mae: 1.6671\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2113 - mae: 1.8145 - val_loss: 4.3794 - val_mae: 1.6613\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1993 - mae: 1.8384 - val_loss: 4.2937 - val_mae: 1.6319\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0312 - mae: 1.7987 - val_loss: 4.2719 - val_mae: 1.6290\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5380 - mae: 1.7226 - val_loss: 4.2468 - val_mae: 1.6203\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4586 - mae: 1.6870 - val_loss: 4.1421 - val_mae: 1.5838\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5515 - mae: 1.7197 - val_loss: 4.2363 - val_mae: 1.6214\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7167 - mae: 1.7472 - val_loss: 4.0842 - val_mae: 1.5713\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2114 - mae: 1.6311 - val_loss: 4.1412 - val_mae: 1.5953\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3698 - mae: 1.6648 - val_loss: 4.0540 - val_mae: 1.5734\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3648 - mae: 1.6837 - val_loss: 4.0293 - val_mae: 1.5618\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6052 - mae: 1.7206 - val_loss: 4.0015 - val_mae: 1.5526\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3693 - mae: 1.6659 - val_loss: 4.0224 - val_mae: 1.5708\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.9399 - mae: 1.7900 - val_loss: 3.9954 - val_mae: 1.5591\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1086 - mae: 1.6261 - val_loss: 3.9653 - val_mae: 1.5442\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3651 - mae: 1.6555 - val_loss: 3.9589 - val_mae: 1.5446\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4120 - mae: 1.6953 - val_loss: 3.9316 - val_mae: 1.5394\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9753 - mae: 1.5754 - val_loss: 3.9567 - val_mae: 1.5550\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2366 - mae: 1.6489 - val_loss: 3.9327 - val_mae: 1.5467\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3821 - mae: 1.6958 - val_loss: 3.8433 - val_mae: 1.5069\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1580 - mae: 1.6211 - val_loss: 3.8860 - val_mae: 1.5297\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0704 - mae: 1.5921 - val_loss: 3.9199 - val_mae: 1.5443\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1535 - mae: 1.6031 - val_loss: 3.9113 - val_mae: 1.5451\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9952 - mae: 1.5816 - val_loss: 3.8825 - val_mae: 1.5341\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0148 - mae: 1.5911 - val_loss: 3.9363 - val_mae: 1.5513\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0791 - mae: 1.6278 - val_loss: 3.8247 - val_mae: 1.5141\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1091 - mae: 1.6022 - val_loss: 3.9231 - val_mae: 1.5541\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4236 - mae: 1.6813 - val_loss: 3.7877 - val_mae: 1.5033\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9363 - mae: 1.5844 - val_loss: 3.9436 - val_mae: 1.5668\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1410 - mae: 1.6279 - val_loss: 3.7917 - val_mae: 1.4951\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8862 - mae: 1.5689 - val_loss: 3.9511 - val_mae: 1.5659\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0940 - mae: 1.6230 - val_loss: 3.8305 - val_mae: 1.5170\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9033 - mae: 1.5580 - val_loss: 3.7806 - val_mae: 1.5002\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9107 - mae: 1.5714 - val_loss: 3.8783 - val_mae: 1.5423\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0152 - mae: 1.6035 - val_loss: 3.7933 - val_mae: 1.5074\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2974 - mae: 1.6319 - val_loss: 3.8063 - val_mae: 1.5190\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0579 - mae: 1.5773 - val_loss: 3.8141 - val_mae: 1.5198\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1234 - mae: 1.6177 - val_loss: 3.8465 - val_mae: 1.5292\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0915 - mae: 1.6069 - val_loss: 3.7682 - val_mae: 1.5090\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1935 - mae: 1.6064 - val_loss: 3.8232 - val_mae: 1.5273\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9019 - mae: 1.5604 - val_loss: 3.8681 - val_mae: 1.5499\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0995 - mae: 1.6125 - val_loss: 3.7584 - val_mae: 1.5088\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8403 - mae: 1.5422 - val_loss: 3.7836 - val_mae: 1.5243\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0004 - mae: 1.5900 - val_loss: 3.8169 - val_mae: 1.5310\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8649 - mae: 1.5585 - val_loss: 3.7476 - val_mae: 1.5057\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1118 - mae: 1.5898 - val_loss: 3.7314 - val_mae: 1.4965\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7239 - mae: 1.5358 - val_loss: 3.7066 - val_mae: 1.5023\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0438 - mae: 1.5701 - val_loss: 3.6907 - val_mae: 1.4914\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9705 - mae: 1.5444 - val_loss: 3.7895 - val_mae: 1.5234\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8643 - mae: 1.5669 - val_loss: 3.7075 - val_mae: 1.5057\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8227 - mae: 1.5469 - val_loss: 3.7234 - val_mae: 1.5070\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6383 - mae: 1.5168 - val_loss: 3.7521 - val_mae: 1.5116\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8303 - mae: 1.5288 - val_loss: 3.6910 - val_mae: 1.5011\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0259 - mae: 1.5650 - val_loss: 3.8300 - val_mae: 1.5426\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8401 - mae: 1.5670 - val_loss: 3.6573 - val_mae: 1.4830\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9406 - mae: 1.5868 - val_loss: 3.7341 - val_mae: 1.5152\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9533 - mae: 1.5671 - val_loss: 3.6561 - val_mae: 1.4952\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5743 - mae: 1.4545 - val_loss: 3.8276 - val_mae: 1.5519\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6687 - mae: 1.5092 - val_loss: 3.6007 - val_mae: 1.4790\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0060 - mae: 1.5815 - val_loss: 3.8239 - val_mae: 1.5539\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7777 - mae: 1.5604 - val_loss: 3.6732 - val_mae: 1.5014\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5311 - mae: 1.4964 - val_loss: 3.6642 - val_mae: 1.5007\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6510 - mae: 1.5154 - val_loss: 3.8000 - val_mae: 1.5532\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5814 - mae: 1.5139 - val_loss: 3.7231 - val_mae: 1.5275\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5723 - mae: 1.4979 - val_loss: 3.7175 - val_mae: 1.5169\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6144 - mae: 1.5074 - val_loss: 3.6891 - val_mae: 1.5169\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6759 - mae: 1.4942 - val_loss: 3.7293 - val_mae: 1.5186\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6233 - mae: 1.5069 - val_loss: 3.6493 - val_mae: 1.5077\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8311 - mae: 1.5567 - val_loss: 3.7764 - val_mae: 1.5395\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6100 - mae: 1.5129 - val_loss: 3.6862 - val_mae: 1.5192\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8067 - mae: 1.5521 - val_loss: 3.7050 - val_mae: 1.5219\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8609 - mae: 1.5472 - val_loss: 3.6161 - val_mae: 1.4957\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7796 - mae: 1.5375 - val_loss: 3.7194 - val_mae: 1.5283\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9351 - mae: 1.5898 - val_loss: 3.6477 - val_mae: 1.4997\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9735 - mae: 1.5968 - val_loss: 3.7404 - val_mae: 1.5273\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5837 - mae: 1.4975 - val_loss: 3.6655 - val_mae: 1.5065\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6345 - mae: 1.5276 - val_loss: 3.7514 - val_mae: 1.5372\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6078 - mae: 1.5077 - val_loss: 3.7992 - val_mae: 1.5388\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4900 - mae: 1.4661 - val_loss: 3.6362 - val_mae: 1.5078\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6954 - mae: 1.5351 - val_loss: 3.7698 - val_mae: 1.5437\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5016 - mae: 1.4927 - val_loss: 3.8253 - val_mae: 1.5718\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6609 - mae: 1.5280 - val_loss: 3.6691 - val_mae: 1.5194\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5841 - mae: 1.5020 - val_loss: 3.7865 - val_mae: 1.5521\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3398 - mae: 1.4423 - val_loss: 3.7408 - val_mae: 1.5371\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4791 - mae: 1.4850 - val_loss: 3.7668 - val_mae: 1.5402\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6991 - mae: 1.5226 - val_loss: 3.9275 - val_mae: 1.5843\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5504 - mae: 1.5059 - val_loss: 3.6865 - val_mae: 1.5191\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6268 - mae: 1.4962 - val_loss: 3.7052 - val_mae: 1.5240\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4622 - mae: 1.4826 - val_loss: 3.7586 - val_mae: 1.5420\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4809 - mae: 1.4922 - val_loss: 3.6628 - val_mae: 1.5064\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3388 - mae: 1.4282 - val_loss: 3.8984 - val_mae: 1.5817\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4518 - mae: 1.4999 - val_loss: 3.7352 - val_mae: 1.5299\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5231 - mae: 1.4978 - val_loss: 3.7893 - val_mae: 1.5417\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8142 - mae: 1.5498 - val_loss: 3.6675 - val_mae: 1.5144\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5268 - mae: 1.4820 - val_loss: 3.9220 - val_mae: 1.5779\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3201 - mae: 1.6610 \n",
            "Test MAE (Mean Absolute Error): 1.67\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "   Predicted     Actual\n",
            "0   6.552611   7.494001\n",
            "1  11.355431  12.394215\n",
            "2  10.650913   9.997158\n",
            "3   7.085546   8.965073\n",
            "4   8.253777  11.882369\n",
            "5  11.720911   8.595982\n",
            "6  10.980830  13.475625\n",
            "7   7.951998  11.871617\n",
            "8   6.110618   4.827736\n",
            "9   8.249905   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Predicted total rebounds for the player's next game: 8.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DEVIN BOOKER"
      ],
      "metadata": {
        "id": "XUSGSsXPP0KM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KsMMdCGgP3bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [3.2], # Changed to list\n",
        "    'avg_min_last5': [37.7], # Changed to list\n",
        "    'opp_avg_reb_allowed': [46.6], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [5.5], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c12660e0-095f-43bd-d6e0-a2fec0506f81",
        "id": "OOzdQhcwP3jV"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 83.2189 - mae: 8.6368 - val_loss: 76.4748 - val_mae: 8.3364\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 63.8955 - mae: 7.4402 - val_loss: 52.0804 - val_mae: 6.6713\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40.8252 - mae: 5.7225 - val_loss: 25.7285 - val_mae: 4.3887\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15.7011 - mae: 3.2420 - val_loss: 10.1572 - val_mae: 2.7028\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.6885 - mae: 2.2523 - val_loss: 6.0130 - val_mae: 2.0043\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.6051 - mae: 1.9083 - val_loss: 5.2554 - val_mae: 1.8427\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.6259 - mae: 1.9063 - val_loss: 5.0086 - val_mae: 1.7831\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0807 - mae: 1.8009 - val_loss: 4.8642 - val_mae: 1.7385\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0995 - mae: 1.8060 - val_loss: 4.7938 - val_mae: 1.7223\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.9077 - mae: 1.7743 - val_loss: 4.8065 - val_mae: 1.7285\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7008 - mae: 1.7015 - val_loss: 4.5918 - val_mae: 1.6546\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0382 - mae: 1.8001 - val_loss: 4.6151 - val_mae: 1.6741\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7512 - mae: 1.7593 - val_loss: 4.5319 - val_mae: 1.6483\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5843 - mae: 1.7123 - val_loss: 4.4504 - val_mae: 1.6261\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4971 - mae: 1.6699 - val_loss: 4.4468 - val_mae: 1.6288\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4841 - mae: 1.7281 - val_loss: 4.4239 - val_mae: 1.6282\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1780 - mae: 1.6400 - val_loss: 4.3274 - val_mae: 1.5996\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2805 - mae: 1.6322 - val_loss: 4.3334 - val_mae: 1.6107\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6966 - mae: 1.7130 - val_loss: 4.2521 - val_mae: 1.5827\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6220 - mae: 1.7283 - val_loss: 4.2317 - val_mae: 1.5849\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0804 - mae: 1.6006 - val_loss: 4.1755 - val_mae: 1.5755\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5724 - mae: 1.6918 - val_loss: 4.1771 - val_mae: 1.5770\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5131 - mae: 1.6853 - val_loss: 4.1325 - val_mae: 1.5643\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3815 - mae: 1.6473 - val_loss: 4.1364 - val_mae: 1.5668\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8049 - mae: 1.7376 - val_loss: 4.1230 - val_mae: 1.5653\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2183 - mae: 1.6248 - val_loss: 4.0363 - val_mae: 1.5391\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6703 - mae: 1.7347 - val_loss: 4.0876 - val_mae: 1.5601\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8107 - mae: 1.5477 - val_loss: 4.0773 - val_mae: 1.5666\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1432 - mae: 1.6099 - val_loss: 4.0100 - val_mae: 1.5422\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0891 - mae: 1.6067 - val_loss: 4.0537 - val_mae: 1.5648\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3582 - mae: 1.6604 - val_loss: 3.9625 - val_mae: 1.5281\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1591 - mae: 1.6223 - val_loss: 3.9391 - val_mae: 1.5333\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3767 - mae: 1.6446 - val_loss: 3.9346 - val_mae: 1.5248\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0502 - mae: 1.6003 - val_loss: 3.9650 - val_mae: 1.5379\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9709 - mae: 1.6012 - val_loss: 3.9515 - val_mae: 1.5405\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9837 - mae: 1.5797 - val_loss: 3.9198 - val_mae: 1.5305\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8448 - mae: 1.5711 - val_loss: 3.9473 - val_mae: 1.5431\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1034 - mae: 1.5890 - val_loss: 3.8944 - val_mae: 1.5219\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3993 - mae: 1.6582 - val_loss: 3.8871 - val_mae: 1.5228\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9054 - mae: 1.5755 - val_loss: 3.9788 - val_mae: 1.5545\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0465 - mae: 1.6069 - val_loss: 3.8411 - val_mae: 1.5094\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4540 - mae: 1.6468 - val_loss: 3.7905 - val_mae: 1.4983\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7269 - mae: 1.5100 - val_loss: 3.8963 - val_mae: 1.5260\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4801 - mae: 1.4723 - val_loss: 3.8974 - val_mae: 1.5371\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7869 - mae: 1.5506 - val_loss: 3.8447 - val_mae: 1.5280\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9611 - mae: 1.5602 - val_loss: 3.8937 - val_mae: 1.5323\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7616 - mae: 1.5378 - val_loss: 3.8371 - val_mae: 1.5209\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8371 - mae: 1.5479 - val_loss: 3.8053 - val_mae: 1.5147\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8452 - mae: 1.5459 - val_loss: 3.8588 - val_mae: 1.5199\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9116 - mae: 1.5620 - val_loss: 3.7713 - val_mae: 1.5038\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1782 - mae: 1.6055 - val_loss: 3.7832 - val_mae: 1.5161\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0027 - mae: 1.5716 - val_loss: 3.8078 - val_mae: 1.5114\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0897 - mae: 1.6001 - val_loss: 3.8257 - val_mae: 1.5241\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8255 - mae: 1.5600 - val_loss: 3.7579 - val_mae: 1.5030\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9217 - mae: 1.5569 - val_loss: 3.7682 - val_mae: 1.5102\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9422 - mae: 1.5506 - val_loss: 3.7947 - val_mae: 1.5189\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7480 - mae: 1.5284 - val_loss: 3.7978 - val_mae: 1.5144\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9598 - mae: 1.5950 - val_loss: 3.7323 - val_mae: 1.5022\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6728 - mae: 1.4949 - val_loss: 3.7420 - val_mae: 1.4982\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7312 - mae: 1.5325 - val_loss: 3.7794 - val_mae: 1.5055\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6781 - mae: 1.5027 - val_loss: 3.7933 - val_mae: 1.5236\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.7726 - mae: 1.5364 - val_loss: 3.7274 - val_mae: 1.4911\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.5913 - mae: 1.4938 - val_loss: 3.7736 - val_mae: 1.5187\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7058 - mae: 1.5109 - val_loss: 3.7937 - val_mae: 1.5143\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6957 - mae: 1.5158 - val_loss: 3.6971 - val_mae: 1.4870\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.9816 - mae: 1.5778 - val_loss: 3.7339 - val_mae: 1.5003\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.0221 - mae: 1.5978 - val_loss: 3.7985 - val_mae: 1.5175\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.8542 - mae: 1.5356 - val_loss: 3.8199 - val_mae: 1.5241\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 3.9312 - mae: 1.5640 - val_loss: 3.6828 - val_mae: 1.4897\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.3435 - mae: 1.4432 - val_loss: 3.8702 - val_mae: 1.5425\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.5263 - mae: 1.4861 - val_loss: 3.7106 - val_mae: 1.4878\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.7967 - mae: 1.5446 - val_loss: 3.7327 - val_mae: 1.5010\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.3852 - mae: 1.4722 - val_loss: 3.7725 - val_mae: 1.5083\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3.7484 - mae: 1.5138 - val_loss: 3.7148 - val_mae: 1.4866\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.9673 - mae: 1.5587 - val_loss: 3.8342 - val_mae: 1.5261\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6577 - mae: 1.5331 - val_loss: 3.7354 - val_mae: 1.4993\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8220 - mae: 1.5198 - val_loss: 3.7869 - val_mae: 1.5165\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.4630 - mae: 1.5017 - val_loss: 3.6384 - val_mae: 1.4784\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.6554 - mae: 1.5265 - val_loss: 3.7920 - val_mae: 1.5232\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.7414 - mae: 1.5444 - val_loss: 3.7750 - val_mae: 1.5071\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.6204 - mae: 1.4957 - val_loss: 3.7556 - val_mae: 1.5075\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5354 - mae: 1.5124 - val_loss: 3.7740 - val_mae: 1.5120\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5188 - mae: 1.4943 - val_loss: 3.6832 - val_mae: 1.4853\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7184 - mae: 1.5341 - val_loss: 3.7020 - val_mae: 1.4934\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6779 - mae: 1.5285 - val_loss: 3.7984 - val_mae: 1.5226\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5172 - mae: 1.4954 - val_loss: 3.7649 - val_mae: 1.5166\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4662 - mae: 1.4763 - val_loss: 3.7227 - val_mae: 1.4898\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2991 - mae: 1.4345 - val_loss: 3.7688 - val_mae: 1.5046\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6026 - mae: 1.5099 - val_loss: 3.7399 - val_mae: 1.5003\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7447 - mae: 1.5224 - val_loss: 3.8968 - val_mae: 1.5569\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2756 - mae: 1.4430 - val_loss: 3.7220 - val_mae: 1.4989\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4857 - mae: 1.4922 - val_loss: 3.8688 - val_mae: 1.5354\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7696 - mae: 1.5568 - val_loss: 3.8174 - val_mae: 1.5301\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4516 - mae: 1.4690 - val_loss: 3.8762 - val_mae: 1.5382\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6893 - mae: 1.5358 - val_loss: 3.8898 - val_mae: 1.5467\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4509 - mae: 1.4528 - val_loss: 3.7643 - val_mae: 1.5054\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3246 - mae: 1.4428 - val_loss: 3.7150 - val_mae: 1.4893\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4748 - mae: 1.4683 - val_loss: 3.8426 - val_mae: 1.5347\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5292 - mae: 1.4970 - val_loss: 3.8391 - val_mae: 1.5325\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4713 - mae: 1.4640 - val_loss: 3.7300 - val_mae: 1.4978\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1565 - mae: 1.6347 \n",
            "Test MAE (Mean Absolute Error): 1.64\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "   Predicted     Actual\n",
            "0   7.056229   7.494001\n",
            "1  11.517491  12.394215\n",
            "2  10.553116   9.997158\n",
            "3   7.642803   8.965073\n",
            "4   8.413592  11.882369\n",
            "5  11.661397   8.595982\n",
            "6  11.128993  13.475625\n",
            "7   8.688706  11.871617\n",
            "8   6.654901   4.827736\n",
            "9   8.343045   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Predicted total rebounds for the player's next game: 7.09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#jonh Collins"
      ],
      "metadata": {
        "id": "rU8myVgPRChT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AoO-nmxhREx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples in the synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Generate synthetic features\n",
        "avg_reb_last5 = np.random.uniform(3, 15, num_samples)         # Player's avg rebounds in last 5 games\n",
        "avg_min_last5 = np.random.uniform(10, 40, num_samples)        # Player's avg minutes in last 5 games\n",
        "opp_avg_reb_allowed = np.random.uniform(40, 60, num_samples)  # Opponent's avg rebounds allowed\n",
        "player_avg_reb_vs_opp = np.random.uniform(3, 15, num_samples) # Player's avg rebounds vs opponent\n",
        "home_indicator = np.random.randint(0, 2, num_samples)         # 1 if home game, 0 if away\n",
        "back_to_back = np.random.randint(0, 2, num_samples)           # 1 if back-to-back game, 0 otherwise\n",
        "\n",
        "# Create a synthetic target variable (rebounds in the next game)\n",
        "rebounds_next_game = (\n",
        "    0.5 * avg_reb_last5 +\n",
        "    0.3 * (avg_min_last5 / 40) * 15 +  # Scale minutes to rebounds\n",
        "    0.2 * player_avg_reb_vs_opp +\n",
        "    np.random.normal(0, 2, num_samples)  # Add some noise\n",
        ")\n",
        "\n",
        "# Ensure rebounds are within a realistic range\n",
        "rebounds_next_game = np.clip(rebounds_next_game, 0, 20)\n",
        "\n",
        "# Assemble the dataset into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'avg_reb_last5': avg_reb_last5,\n",
        "    'avg_min_last5': avg_min_last5,\n",
        "    'opp_avg_reb_allowed': opp_avg_reb_allowed,\n",
        "    'player_avg_reb_vs_opp': player_avg_reb_vs_opp,\n",
        "    'home_indicator': home_indicator,\n",
        "    'back_to_back': back_to_back,\n",
        "    'rebounds_next_game': rebounds_next_game\n",
        "})\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('rebounds_next_game', axis=1)\n",
        "y = data['rebounds_next_game']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Feature scaling for better neural network performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer and loss function\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model on the training data\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model's performance on the test data\n",
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE (Mean Absolute Error): {mae:.2f}\")\n",
        "\n",
        "# Predict rebounds for the next game using the test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "\n",
        "# Display the first 10 predictions alongside actual values\n",
        "results = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test.values})\n",
        "print(results.head(10))\n",
        "\n",
        "# ... (previous code) ...\n",
        "\n",
        "# Now, let's predict the total rebounds for a specific player's next game\n",
        "\n",
        "# Define the player's stats\n",
        "player_data = {\n",
        "    'avg_reb_last5': [11.2], # Changed to list\n",
        "    'avg_min_last5': [31.7], # Changed to list\n",
        "    'opp_avg_reb_allowed': [43.9], # Changed to list\n",
        "    'player_avg_reb_vs_opp': [8], # Changed to list\n",
        "    'home_indicator': [1], # Changed to list\n",
        "    'back_to_back': [0], # Changed to list\n",
        "}\n",
        "\n",
        "player_df = pd.DataFrame(player_data)  # Now this should work correctly\n",
        "\n",
        "# ... (rest of the code) ...\n",
        "\n",
        "# Scale the player's features using the same scaler\n",
        "player_scaled = scaler.transform(player_df)\n",
        "\n",
        "# Predict the rebounds for the player's next game\n",
        "player_prediction = model.predict(player_scaled)\n",
        "\n",
        "# Output the predicted total rebounds\n",
        "print(f\"Predicted total rebounds for the player's next game: {player_prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aba7977-525e-4917-8726-1d569eea1765",
        "id": "oiuss2gXRFDs"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - loss: 83.7911 - mae: 8.6819 - val_loss: 73.7025 - val_mae: 8.1881\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 58.3048 - mae: 7.1136 - val_loss: 49.2552 - val_mae: 6.5391\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 37.8223 - mae: 5.5068 - val_loss: 22.9193 - val_mae: 4.1953\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 15.2585 - mae: 3.2590 - val_loss: 8.1046 - val_mae: 2.3608\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.5030 - mae: 2.0653 - val_loss: 5.0451 - val_mae: 1.8000\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 5.8971 - mae: 1.9278 - val_loss: 4.6864 - val_mae: 1.6971\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.2942 - mae: 1.8513 - val_loss: 4.6084 - val_mae: 1.6668\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9521 - mae: 1.7821 - val_loss: 4.5302 - val_mae: 1.6508\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.0720 - mae: 1.8219 - val_loss: 4.4502 - val_mae: 1.6277\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.6941 - mae: 1.7133 - val_loss: 4.3669 - val_mae: 1.6034\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.9535 - mae: 1.7663 - val_loss: 4.4499 - val_mae: 1.6384\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.0453 - mae: 1.7608 - val_loss: 4.3148 - val_mae: 1.5969\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.4656 - mae: 1.6704 - val_loss: 4.3710 - val_mae: 1.6191\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.1366 - mae: 1.8249 - val_loss: 4.2298 - val_mae: 1.5758\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7045 - mae: 1.7100 - val_loss: 4.2368 - val_mae: 1.5816\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7552 - mae: 1.7429 - val_loss: 4.2886 - val_mae: 1.6114\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3763 - mae: 1.6563 - val_loss: 4.2477 - val_mae: 1.6065\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2309 - mae: 1.6260 - val_loss: 4.1393 - val_mae: 1.5638\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3742 - mae: 1.6447 - val_loss: 4.1528 - val_mae: 1.5701\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5423 - mae: 1.6871 - val_loss: 4.1466 - val_mae: 1.5718\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3669 - mae: 1.6430 - val_loss: 4.1522 - val_mae: 1.5761\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.5848 - mae: 1.7092 - val_loss: 4.0840 - val_mae: 1.5569\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.6726 - mae: 1.7417 - val_loss: 4.0652 - val_mae: 1.5523\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4235 - mae: 1.6544 - val_loss: 4.0791 - val_mae: 1.5539\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3506 - mae: 1.6422 - val_loss: 4.0567 - val_mae: 1.5600\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2977 - mae: 1.6462 - val_loss: 4.0122 - val_mae: 1.5436\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1786 - mae: 1.6351 - val_loss: 4.0380 - val_mae: 1.5471\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3183 - mae: 1.6430 - val_loss: 3.9966 - val_mae: 1.5469\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1025 - mae: 1.6072 - val_loss: 4.0195 - val_mae: 1.5501\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.0415 - mae: 1.6213 - val_loss: 3.9408 - val_mae: 1.5208\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.1509 - mae: 1.6311 - val_loss: 4.0040 - val_mae: 1.5489\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2754 - mae: 1.6394 - val_loss: 3.9201 - val_mae: 1.5183\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1550 - mae: 1.6017 - val_loss: 3.9379 - val_mae: 1.5312\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7869 - mae: 1.5350 - val_loss: 3.9189 - val_mae: 1.5216\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2073 - mae: 1.6343 - val_loss: 3.9500 - val_mae: 1.5404\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4484 - mae: 1.7091 - val_loss: 3.8975 - val_mae: 1.5273\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0214 - mae: 1.6011 - val_loss: 3.9564 - val_mae: 1.5526\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3143 - mae: 1.6616 - val_loss: 3.9260 - val_mae: 1.5426\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0216 - mae: 1.6022 - val_loss: 3.8325 - val_mae: 1.5016\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1125 - mae: 1.6219 - val_loss: 3.8847 - val_mae: 1.5160\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2059 - mae: 1.6401 - val_loss: 3.8583 - val_mae: 1.5199\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8816 - mae: 1.5466 - val_loss: 3.8059 - val_mae: 1.4867\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0468 - mae: 1.5886 - val_loss: 3.7713 - val_mae: 1.4920\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0876 - mae: 1.6103 - val_loss: 3.8478 - val_mae: 1.5172\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2620 - mae: 1.6674 - val_loss: 3.9295 - val_mae: 1.5461\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0719 - mae: 1.5952 - val_loss: 3.7829 - val_mae: 1.4926\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1911 - mae: 1.5899 - val_loss: 3.7600 - val_mae: 1.4739\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1437 - mae: 1.6007 - val_loss: 3.7064 - val_mae: 1.4701\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9563 - mae: 1.5469 - val_loss: 3.8545 - val_mae: 1.5238\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1790 - mae: 1.6347 - val_loss: 3.7558 - val_mae: 1.4827\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9737 - mae: 1.5729 - val_loss: 3.7708 - val_mae: 1.4976\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0100 - mae: 1.6097 - val_loss: 3.7226 - val_mae: 1.4767\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0241 - mae: 1.5744 - val_loss: 3.8296 - val_mae: 1.5072\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6565 - mae: 1.5238 - val_loss: 3.7369 - val_mae: 1.4868\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8547 - mae: 1.5427 - val_loss: 3.7654 - val_mae: 1.4916\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6186 - mae: 1.5045 - val_loss: 3.7425 - val_mae: 1.4827\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9903 - mae: 1.5688 - val_loss: 3.7674 - val_mae: 1.4969\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1150 - mae: 1.6013 - val_loss: 3.7652 - val_mae: 1.4948\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8196 - mae: 1.5529 - val_loss: 3.6870 - val_mae: 1.4638\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0733 - mae: 1.5962 - val_loss: 3.7935 - val_mae: 1.5107\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1579 - mae: 1.6204 - val_loss: 3.6340 - val_mae: 1.4459\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8307 - mae: 1.5345 - val_loss: 3.8016 - val_mae: 1.5135\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8945 - mae: 1.5884 - val_loss: 3.6915 - val_mae: 1.4721\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9538 - mae: 1.5832 - val_loss: 3.8041 - val_mae: 1.5096\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6421 - mae: 1.5116 - val_loss: 3.7345 - val_mae: 1.4843\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7268 - mae: 1.5499 - val_loss: 3.6777 - val_mae: 1.4649\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9435 - mae: 1.5629 - val_loss: 3.7076 - val_mae: 1.4811\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9809 - mae: 1.5902 - val_loss: 3.6883 - val_mae: 1.4691\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0428 - mae: 1.6069 - val_loss: 3.6262 - val_mae: 1.4542\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8258 - mae: 1.5448 - val_loss: 3.7520 - val_mae: 1.4831\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8300 - mae: 1.5481 - val_loss: 3.7661 - val_mae: 1.5079\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1168 - mae: 1.6328 - val_loss: 3.6632 - val_mae: 1.4569\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9183 - mae: 1.5734 - val_loss: 3.8143 - val_mae: 1.5262\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5742 - mae: 1.5022 - val_loss: 3.7638 - val_mae: 1.5105\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6321 - mae: 1.5083 - val_loss: 3.7517 - val_mae: 1.4901\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6909 - mae: 1.5305 - val_loss: 3.9024 - val_mae: 1.5436\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6791 - mae: 1.5269 - val_loss: 3.6282 - val_mae: 1.4567\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6419 - mae: 1.5203 - val_loss: 3.8189 - val_mae: 1.5198\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4758 - mae: 1.4886 - val_loss: 3.7015 - val_mae: 1.4812\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8245 - mae: 1.5491 - val_loss: 3.6579 - val_mae: 1.4679\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0561 - mae: 1.5837 - val_loss: 3.6983 - val_mae: 1.4809\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9442 - mae: 1.5677 - val_loss: 3.7232 - val_mae: 1.4827\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4451 - mae: 1.4604 - val_loss: 3.7058 - val_mae: 1.4824\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7093 - mae: 1.5297 - val_loss: 3.7174 - val_mae: 1.4893\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6459 - mae: 1.5296 - val_loss: 3.7699 - val_mae: 1.4985\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5209 - mae: 1.5139 - val_loss: 3.6851 - val_mae: 1.4909\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8407 - mae: 1.5633 - val_loss: 3.8067 - val_mae: 1.5128\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7763 - mae: 1.5467 - val_loss: 3.7196 - val_mae: 1.4881\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6109 - mae: 1.4961 - val_loss: 3.8557 - val_mae: 1.5416\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6995 - mae: 1.5178 - val_loss: 3.7476 - val_mae: 1.4943\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5504 - mae: 1.5053 - val_loss: 3.7526 - val_mae: 1.4996\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5592 - mae: 1.4990 - val_loss: 3.6440 - val_mae: 1.4660\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7499 - mae: 1.5483 - val_loss: 3.7916 - val_mae: 1.5141\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9000 - mae: 1.5284 - val_loss: 3.6272 - val_mae: 1.4765\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6760 - mae: 1.5109 - val_loss: 3.7802 - val_mae: 1.5119\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5325 - mae: 1.5083 - val_loss: 3.7862 - val_mae: 1.5067\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6774 - mae: 1.5285 - val_loss: 3.7657 - val_mae: 1.5129\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7960 - mae: 1.5693 - val_loss: 3.6326 - val_mae: 1.4627\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8371 - mae: 1.5459 - val_loss: 3.7579 - val_mae: 1.5094\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3756 - mae: 1.4433 - val_loss: 3.7661 - val_mae: 1.5126\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0983 - mae: 1.6031 \n",
            "Test MAE (Mean Absolute Error): 1.62\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "   Predicted     Actual\n",
            "0   7.153444   7.494001\n",
            "1  11.401856  12.394215\n",
            "2  10.667045   9.997158\n",
            "3   8.130992   8.965073\n",
            "4   8.061289  11.882369\n",
            "5  11.278972   8.595982\n",
            "6  11.085305  13.475625\n",
            "7   7.930708  11.871617\n",
            "8   6.623343   4.827736\n",
            "9   8.029249   9.330706\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Predicted total rebounds for the player's next game: 10.26\n"
          ]
        }
      ]
    }
  ]
}